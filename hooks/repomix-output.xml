This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
_ast_utils.py
_beads.py
_cache.py
_config.py
_cooldown.py
_hook_registry.py
_hook_result.py
_hooks_cache.py
_hooks_quality.py
_hooks_state.py
_hooks_tracking.py
_intent_classifier.py
_lib_path.py
_logging.py
_pal_mandates.py
_patterns.py
_prompt_context.py
_prompt_gating.py
_prompt_registry.py
_prompt_suggestions.py
_quality_scanner.py
dependency_check.py
post_tool_use_runner.py
pre_compact.py
pre_tool_use_runner.py
py
session_cleanup.py
session_init.py
statusline.py
stop_runner.py
subagent_stop.py
user_prompt_submit_runner.py
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="_ast_utils.py">
"""
Cached AST utilities for hook pattern matching.

Provides AST-based extraction for patterns where regex is fragile.
Falls back gracefully on parse errors.
"""

import ast
from functools import lru_cache

# Standard library modules (Python 3.12) - skip these in dependency checks
STDLIB_MODULES = frozenset(
    {
        "abc",
        "aifc",
        "argparse",
        "array",
        "ast",
        "asyncio",
        "atexit",
        "base64",
        "bdb",
        "binascii",
        "bisect",
        "builtins",
        "bz2",
        "calendar",
        "cgi",
        "cgitb",
        "chunk",
        "cmath",
        "cmd",
        "code",
        "codecs",
        "codeop",
        "collections",
        "colorsys",
        "compileall",
        "concurrent",
        "configparser",
        "contextlib",
        "contextvars",
        "copy",
        "copyreg",
        "cProfile",
        "crypt",
        "csv",
        "ctypes",
        "curses",
        "dataclasses",
        "datetime",
        "dbm",
        "decimal",
        "difflib",
        "dis",
        "doctest",
        "email",
        "encodings",
        "enum",
        "errno",
        "faulthandler",
        "fcntl",
        "filecmp",
        "fileinput",
        "fnmatch",
        "fractions",
        "ftplib",
        "functools",
        "gc",
        "getopt",
        "getpass",
        "gettext",
        "glob",
        "graphlib",
        "grp",
        "gzip",
        "hashlib",
        "heapq",
        "hmac",
        "html",
        "http",
        "idlelib",
        "imaplib",
        "imghdr",
        "importlib",
        "inspect",
        "io",
        "ipaddress",
        "itertools",
        "json",
        "keyword",
        "lib2to3",
        "linecache",
        "locale",
        "logging",
        "lzma",
        "mailbox",
        "mailcap",
        "marshal",
        "math",
        "mimetypes",
        "mmap",
        "modulefinder",
        "multiprocessing",
        "netrc",
        "nis",
        "nntplib",
        "numbers",
        "operator",
        "optparse",
        "os",
        "pathlib",
        "pdb",
        "pickle",
        "pickletools",
        "pipes",
        "pkgutil",
        "platform",
        "plistlib",
        "poplib",
        "posix",
        "posixpath",
        "pprint",
        "profile",
        "pstats",
        "pty",
        "pwd",
        "py_compile",
        "pyclbr",
        "pydoc",
        "queue",
        "quopri",
        "random",
        "re",
        "readline",
        "reprlib",
        "resource",
        "rlcompleter",
        "runpy",
        "sched",
        "secrets",
        "select",
        "selectors",
        "shelve",
        "shlex",
        "shutil",
        "signal",
        "site",
        "smtpd",
        "smtplib",
        "sndhdr",
        "socket",
        "socketserver",
        "spwd",
        "sqlite3",
        "ssl",
        "stat",
        "statistics",
        "string",
        "stringprep",
        "struct",
        "subprocess",
        "sunau",
        "symtable",
        "sys",
        "sysconfig",
        "syslog",
        "tabnanny",
        "tarfile",
        "telnetlib",
        "tempfile",
        "termios",
        "test",
        "textwrap",
        "threading",
        "time",
        "timeit",
        "tkinter",
        "token",
        "tokenize",
        "tomllib",
        "trace",
        "traceback",
        "tracemalloc",
        "tty",
        "turtle",
        "turtledemo",
        "types",
        "typing",
        "unicodedata",
        "unittest",
        "urllib",
        "uu",
        "uuid",
        "venv",
        "warnings",
        "wave",
        "weakref",
        "webbrowser",
        "winreg",
        "winsound",
        "wsgiref",
        "xdrlib",
        "xml",
        "xmlrpc",
        "zipapp",
        "zipfile",
        "zipimport",
        "zlib",
        # typing extensions often bundled
        "typing_extensions",
    }
)


@lru_cache(maxsize=32)
def _parse_python(content: str) -> ast.Module | None:
    """Parse Python with caching. Returns None on syntax error."""
    try:
        return ast.parse(content)
    except SyntaxError:
        return None


def extract_imports(content: str) -> set[str]:
    """
    Extract all imported module names via AST.

    Returns top-level module names only (e.g., 'requests' not 'requests.auth').
    Falls back to empty set on parse error.

    Handles all import forms:
    - import foo
    - import foo, bar
    - import foo.bar.baz  -> 'foo'
    - from foo import bar
    - from foo.bar import baz  -> 'foo'
    - from . import foo  -> skipped (relative)
    """
    tree = _parse_python(content)
    if not tree:
        return set()

    imports = set()
    for node in ast.walk(tree):
        if isinstance(node, ast.Import):
            for alias in node.names:
                # Get top-level module (before first dot)
                imports.add(alias.name.split(".")[0])
        elif isinstance(node, ast.ImportFrom):
            # Skip relative imports (module is None or level > 0)
            if node.module and node.level == 0:
                imports.add(node.module.split(".")[0])

    return imports


def extract_non_stdlib_imports(content: str) -> set[str]:
    """Extract imports that are not in the standard library."""
    all_imports = extract_imports(content)
    return all_imports - STDLIB_MODULES


def extract_calls(content: str) -> tuple[set[str], set[str]]:
    """
    Extract function and method calls via AST.

    Returns (class_calls, method_calls):
    - class_calls: PascalCase names like MyClass(), Exception(), etc.
    - method_calls: Method/function names like .append(), print(), etc.

    More accurate than regex - ignores strings, comments, and variable names.
    """
    tree = _parse_python(content)
    if not tree:
        return set(), set()

    class_calls = set()
    method_calls = set()

    for node in ast.walk(tree):
        if isinstance(node, ast.Call):
            if isinstance(node.func, ast.Name):
                name = node.func.id
                # PascalCase heuristic: starts with uppercase
                if name[0].isupper():
                    class_calls.add(name)
                else:
                    method_calls.add(name)
            elif isinstance(node.func, ast.Attribute):
                # Method call like obj.method()
                method_calls.add(node.func.attr)

    return class_calls, method_calls


def extract_all_calls(content: str) -> set[str]:
    """Extract all function/method call names (combined set)."""
    class_calls, method_calls = extract_calls(content)
    return class_calls | method_calls


# Common builtins to filter from epistemic checks
BUILTIN_CALLS = frozenset(
    {
        "True",
        "False",
        "None",
        "Exception",
        "BaseException",
        "Error",
        "print",
        "len",
        "str",
        "int",
        "float",
        "bool",
        "list",
        "dict",
        "set",
        "tuple",
        "range",
        "enumerate",
        "zip",
        "map",
        "filter",
        "sorted",
        "reversed",
        "open",
        "input",
        "type",
        "isinstance",
        "issubclass",
        "hasattr",
        "getattr",
        "setattr",
        "sum",
        "min",
        "max",
        "abs",
        "round",
        "pow",
        "divmod",
        "any",
        "all",
        "iter",
        "next",
        "repr",
        "hash",
        "id",
        "hex",
        "bin",
        "oct",
        "ord",
        "chr",
        "format",
        "vars",
        "dir",
        "help",
        "callable",
        "eval",
        "exec",
        "compile",
        "globals",
        "locals",
        "super",
        "object",
        "classmethod",
        "staticmethod",
        "property",
        "slice",
        "complex",
        "bytes",
        "bytearray",
        "memoryview",
        "frozenset",
    }
)


def extract_non_builtin_calls(content: str) -> set[str]:
    """Extract calls that aren't Python builtins."""
    all_calls = extract_all_calls(content)
    return {c for c in all_calls if c not in BUILTIN_CALLS and len(c) > 2}


def find_mutable_defaults(content: str) -> list[tuple[str, int, str]]:
    """
    Find functions with mutable default arguments via AST.

    Returns list of (function_name, line_number, mutable_type) tuples.
    Detects: [], {}, set(), list(), dict()

    More accurate than regex - handles multiline signatures, nested defaults.
    """
    tree = _parse_python(content)
    if not tree:
        return []

    issues = []
    for node in ast.walk(tree):
        if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
            # Check positional defaults
            for default in node.args.defaults:
                mutable_type = _get_mutable_type(default)
                if mutable_type:
                    issues.append((node.name, node.lineno, mutable_type))
                    break  # One warning per function

            # Check keyword-only defaults
            if not any(node.name == i[0] for i in issues):  # Skip if already flagged
                for default in node.args.kw_defaults:
                    if default is not None:
                        mutable_type = _get_mutable_type(default)
                        if mutable_type:
                            issues.append((node.name, node.lineno, mutable_type))
                            break

    return issues


def _get_mutable_type(node: ast.expr) -> str | None:
    """Check if an AST node represents a mutable default value."""
    if isinstance(node, ast.List):
        return "[]"
    elif isinstance(node, ast.Dict):
        return "{}"
    elif isinstance(node, ast.Set):
        return "set literal"
    elif isinstance(node, ast.Call):
        # Check for list(), dict(), set() calls
        if isinstance(node.func, ast.Name):
            if node.func.id in ("list", "dict", "set"):
                return f"{node.func.id}()"
    return None


def has_mutable_defaults(content: str) -> bool:
    """Quick check if code has any mutable defaults."""
    return len(find_mutable_defaults(content)) > 0


def clear_cache():
    """Clear the AST parse cache."""
    _parse_python.cache_clear()
</file>

<file path="_beads.py">
"""
Bead (task tracking) helpers for hook runners.

Provides caching and utility functions for interacting with the `bd` CLI.
Extracted from pre_tool_use_runner.py to reduce file size and improve reusability.
"""

import json
import os
import tempfile
from datetime import datetime
from typing import TYPE_CHECKING
from _logging import log_debug

if TYPE_CHECKING:
    from session_state import SessionState

# Simple per-process cache (hooks run as subprocesses, so this resets each call)
_BD_CACHE: list | None = None


def get_open_beads(state: "SessionState") -> list:
    """Get open beads. Caches within single hook invocation.

    Note: Uses temp file + os.system instead of subprocess.run due to bd pipe issues.
    """
    global _BD_CACHE

    # Use cached result if already queried this invocation
    if _BD_CACHE is not None:
        return _BD_CACHE

    # Query bd for both open and in_progress beads
    # Using temp file approach because bd has issues with subprocess pipes
    all_beads = []
    try:
        with tempfile.NamedTemporaryFile(mode="w", suffix=".json", delete=False) as f:
            tmp_path = f.name

        for status in ["open", "in_progress"]:
            exit_code = os.system(
                f'bd list --status={status} --json > "{tmp_path}" 2>/dev/null'
            )
            if exit_code == 0:
                try:
                    with open(tmp_path) as f:
                        content = f.read().strip()
                    if content:
                        all_beads.extend(json.loads(content))
                except (json.JSONDecodeError, OSError):
                    pass

        _BD_CACHE = all_beads
    except Exception as e:
        log_debug("_beads", f"bd list parsing failed: {e}")
    finally:
        # Clean up temp file
        try:
            os.unlink(tmp_path)
        except Exception as e:
            log_debug("_beads", f"temp file cleanup failed: {e}")

    return all_beads


def get_in_progress_beads(state: "SessionState") -> list:
    """Get beads currently being worked on."""
    beads = get_open_beads(state)
    return [b for b in beads if b.get("status") == "in_progress"]


def get_independent_beads(state: "SessionState") -> list:
    """
    Get beads that can be worked in parallel (no blockers).

    FILTERS:
    - Status: open or in_progress only
    - Dependencies: No unresolved blockers
    - Recency: Updated in last 24 hours preferred
    - Limit: Max 4 for parallel work
    """
    beads = get_open_beads(state)
    if not beads:
        return []

    # Get blocked beads to exclude (using temp file due to bd pipe issues)
    blocked_ids = set()
    try:
        with tempfile.NamedTemporaryFile(mode="w", suffix=".json", delete=False) as f:
            tmp_path = f.name
        exit_code = os.system(f'bd blocked --json > "{tmp_path}" 2>/dev/null')
        if exit_code == 0:
            with open(tmp_path) as f:
                content = f.read().strip()
            if content:
                blocked = json.loads(content)
                blocked_ids = {b.get("id") for b in blocked}
        os.unlink(tmp_path)
    except Exception as e:
        log_debug("_beads", f"bd blocked parsing failed: {e}")

    # Filter to independent beads
    independent = [b for b in beads if b.get("id") not in blocked_ids]

    # Sort by recency (updated_at or created_at)
    def get_timestamp(b):
        ts = b.get("updated_at") or b.get("created_at") or ""
        try:
            return datetime.fromisoformat(ts.replace("Z", "+00:00"))
        except Exception:
            return datetime.min

    independent.sort(key=get_timestamp, reverse=True)

    # Cap at 4 for parallel work
    return independent[:4]


def generate_parallel_task_calls(beads: list) -> str:
    """Generate copy-pasteable parallel Task invocation structure."""
    if not beads:
        return ""

    lines = ["**Suggested parallel Task calls** (spawn ALL in one message):"]
    lines.append("```")

    for i, b in enumerate(beads, 1):
        bead_id = b.get("id", "???")[:16]
        title = b.get("title", "untitled")[:50]
        bead_type = b.get("type", "task")

        lines.append(f"# Task {i}: {title}")
        lines.append("Task(")
        lines.append('    subagent_type="general-purpose",')
        lines.append(f'    description="Work on {bead_type}: {title[:30]}",')
        lines.append(f'    prompt="Work on bead `{bead_id}`: {title}. ')
        lines.append(
            f"            First run `bd update {bead_id} --status=in_progress`, "
        )
        lines.append(
            f'            then complete the work, then `bd close {bead_id}`.",'
        )
        lines.append(")")
        if i < len(beads):
            lines.append("")

    lines.append("```")
    return "\n".join(lines)
</file>

<file path="_cache.py">
"""
Caching utilities for hook runners.

Performance: Reduces repeated file I/O and subprocess calls.

Features:
- LRU cache with TTL for file reads
- Git command cache with configurable TTL
- JSON parse cache with mtime invalidation
"""

import json
import subprocess
import time
from pathlib import Path
from typing import Any, Optional


# =============================================================================
# TTL CACHE DECORATOR
# =============================================================================


class TTLCache:
    """Simple TTL cache for expensive operations."""

    def __init__(self, ttl_seconds: float = 5.0):
        self.ttl = ttl_seconds
        self._cache: dict[str, tuple[float, Any]] = {}

    def get(self, key: str) -> Optional[Any]:
        """Get cached value if not expired."""
        if key in self._cache:
            timestamp, value = self._cache[key]
            if time.time() - timestamp < self.ttl:
                return value
            del self._cache[key]
        return None

    def set(self, key: str, value: Any) -> None:
        """Set cached value with timestamp."""
        self._cache[key] = (time.time(), value)

    def invalidate(self, key: str) -> None:
        """Remove key from cache."""
        self._cache.pop(key, None)

    def clear(self) -> None:
        """Clear entire cache."""
        self._cache.clear()


# =============================================================================
# FILE CACHE WITH MTIME INVALIDATION
# =============================================================================


class FileCache:
    """Cache file contents with mtime-based invalidation."""

    def __init__(self, max_size: int = 50):
        self.max_size = max_size
        self._cache: dict[str, tuple[float, str]] = {}  # path -> (mtime, content)
        self._access_order: list[str] = []  # LRU tracking

    def read(self, path: str, encoding: str = "utf-8") -> Optional[str]:
        """Read file with caching, returns None if file doesn't exist."""
        try:
            p = Path(path)
            if not p.exists():
                return None

            current_mtime = p.stat().st_mtime

            # Check cache
            if path in self._cache:
                cached_mtime, content = self._cache[path]
                if cached_mtime == current_mtime:
                    # Update access order
                    if path in self._access_order:
                        self._access_order.remove(path)
                    self._access_order.append(path)
                    return content

            # Cache miss or stale - read file
            content = p.read_text(encoding=encoding)

            # Evict LRU if at capacity
            while len(self._cache) >= self.max_size:
                if self._access_order:
                    oldest = self._access_order.pop(0)
                    self._cache.pop(oldest, None)
                else:
                    break

            # Store in cache
            self._cache[path] = (current_mtime, content)
            self._access_order.append(path)

            return content
        except (OSError, IOError, UnicodeDecodeError):
            return None

    def read_json(self, path: str) -> Optional[dict]:
        """Read and parse JSON file with caching."""
        content = self.read(path)
        if content is None:
            return None
        try:
            return json.loads(content)
        except json.JSONDecodeError:
            return None

    def invalidate(self, path: str) -> None:
        """Invalidate cache for a specific path."""
        self._cache.pop(path, None)
        if path in self._access_order:
            self._access_order.remove(path)

    def clear(self) -> None:
        """Clear entire cache."""
        self._cache.clear()
        self._access_order.clear()


# =============================================================================
# GIT CACHE
# =============================================================================


class GitCache:
    """Cache git command results with TTL."""

    def __init__(self, ttl_seconds: float = 5.0):
        self.ttl = ttl_seconds
        self._cache: dict[str, tuple[float, str]] = {}

    def _run_git(self, *args: str, cwd: Optional[str] = None) -> Optional[str]:
        """Run git command and return output or None on error."""
        try:
            result = subprocess.run(
                ["git", *args],
                capture_output=True,
                text=True,
                timeout=5,
                cwd=cwd,
            )
            if result.returncode == 0:
                return result.stdout.strip()
            return None
        except (subprocess.TimeoutExpired, FileNotFoundError, OSError):
            return None

    def current_branch(self, cwd: Optional[str] = None) -> Optional[str]:
        """Get current git branch (cached)."""
        cache_key = f"branch:{cwd or '.'}"

        # Check cache
        if cache_key in self._cache:
            timestamp, value = self._cache[cache_key]
            if time.time() - timestamp < self.ttl:
                return value

        # Cache miss - run command
        result = self._run_git("branch", "--show-current", cwd=cwd)
        if result is not None:
            self._cache[cache_key] = (time.time(), result)
        return result

    def status_porcelain(self, cwd: Optional[str] = None) -> Optional[str]:
        """Get git status in porcelain format (cached)."""
        cache_key = f"status:{cwd or '.'}"

        # Check cache
        if cache_key in self._cache:
            timestamp, value = self._cache[cache_key]
            if time.time() - timestamp < self.ttl:
                return value

        # Cache miss - run command
        result = self._run_git("status", "--porcelain", cwd=cwd)
        if result is not None:
            self._cache[cache_key] = (time.time(), result)
        return result

    def has_changes(self, cwd: Optional[str] = None) -> bool:
        """Check if repo has uncommitted changes (cached)."""
        status = self.status_porcelain(cwd)
        return bool(status)

    def invalidate(self) -> None:
        """Invalidate all git cache."""
        self._cache.clear()


# =============================================================================
# SINGLETON INSTANCES
# =============================================================================

# Global cache instances for use across hooks
file_cache = FileCache(max_size=50)
git_cache = GitCache(ttl_seconds=5.0)
ttl_cache = TTLCache(ttl_seconds=10.0)


# =============================================================================
# CONVENIENCE FUNCTIONS
# =============================================================================


def cached_file_read(path: str) -> Optional[str]:
    """Read file with caching (convenience wrapper)."""
    return file_cache.read(path)


def cached_json_read(path: str) -> Optional[dict]:
    """Read JSON file with caching (convenience wrapper)."""
    return file_cache.read_json(path)


def cached_git_branch(cwd: Optional[str] = None) -> Optional[str]:
    """Get current git branch (convenience wrapper)."""
    return git_cache.current_branch(cwd)


def cached_git_status(cwd: Optional[str] = None) -> Optional[str]:
    """Get git status (convenience wrapper)."""
    return git_cache.status_porcelain(cwd)
</file>

<file path="_config.py">
"""
Centralized configuration for hook runners.

Loads settings from ~/.claude/config/hook_settings.json with sensible defaults.
Supports hot-reload on file change via mtime checking.
"""

import json
import time
from pathlib import Path
from typing import Any

# =============================================================================
# CONFIG PATHS
# =============================================================================

CONFIG_DIR = Path.home() / ".claude" / "config"
HOOK_SETTINGS_FILE = CONFIG_DIR / "hook_settings.json"

# =============================================================================
# DEFAULT VALUES (used when config file missing or key not found)
# =============================================================================

# =============================================================================
# TOOL NAMES (avoid magic strings scattered across codebase)
# =============================================================================

TOOL_NAMES = {
    "bash": "Bash",
    "edit": "Edit",
    "write": "Write",
    "read": "Read",
    "grep": "Grep",
    "glob": "Glob",
    "task": "Task",
    "web_fetch": "WebFetch",
    "web_search": "WebSearch",
    "notebook_edit": "NotebookEdit",
}

# =============================================================================
# MAGIC NUMBERS (centralized for easy tuning)
# =============================================================================

MAGIC_NUMBERS = {
    "default_context_window": 200000,
    "large_file_threshold": 500,
    "repetition_window_seconds": 300,
    "reads_before_warn": 5,
    "reads_before_crystallize": 8,
}

# =============================================================================
# DEFAULT VALUES (used when config file missing or key not found)
# =============================================================================

DEFAULTS = {
    "cooldowns": {
        "assumption": 120,
        "mutation": 120,
        "toolchain": 300,
        "tool_awareness": 300,
        "large_file": 600,
        "modularization": 10,
        "ops_nudge": 180,
        "ops_audit_reminder": 10800,  # 3 hours (v3.9)
    },
    "thresholds": {
        "stale_session_seconds": 3600,
        "max_method_lines": 60,
        "max_conditionals": 12,
        "large_file_lines": 500,
        "min_code_length": 50,
        "min_prompt_length": 10,
        "pipe_threshold": 3,
        "error_ttl_seconds": 300,
        "context_decay_warn_turns": 15,
        "context_decay_critical_turns": 30,
        "tech_risk_months_threshold": 6,
    },
    "limits": {
        "context_items": 8,
        "reads_before_warn": 5,
        "max_lessons_results": 3,
        "max_warnings": 3,
        "max_ops_suggestions": 3,
        "max_tool_suggestions": 5,
        "lru_cache_size": 50,
    },
    "ttl": {
        "git_cache_seconds": 5.0,
        "file_cache_seconds": 30.0,
    },
    "patterns": {
        "protected_paths": [".claude/ops/", ".claude/lib/"],
        "scratch_paths": [".claude/tmp/", ".claude/memory/"],
        "skip_extensions": [".md", ".txt", ".json", ".yaml", ".yml", ".sh", ".env"],
    },
}

# =============================================================================
# CONFIG LOADER WITH HOT-RELOAD
# =============================================================================


class HookConfig:
    """Configuration loader with mtime-based hot-reload."""

    def __init__(self):
        self._config: dict = {}
        self._mtime: float = 0
        self._last_check: float = 0
        self._check_interval: float = 5.0  # Check for changes every 5 seconds

    def _should_reload(self) -> bool:
        """Check if config file has changed since last load."""
        now = time.time()
        if now - self._last_check < self._check_interval:
            return False
        self._last_check = now

        if not HOOK_SETTINGS_FILE.exists():
            return False

        current_mtime = HOOK_SETTINGS_FILE.stat().st_mtime
        return current_mtime != self._mtime

    def _load(self) -> None:
        """Load config from file."""
        if HOOK_SETTINGS_FILE.exists():
            try:
                self._config = json.loads(HOOK_SETTINGS_FILE.read_text())
                self._mtime = HOOK_SETTINGS_FILE.stat().st_mtime
            except (json.JSONDecodeError, OSError):
                self._config = {}
        else:
            self._config = {}

    def get(self, section: str, key: str, default: Any = None) -> Any:
        """Get a config value with fallback to defaults."""
        if self._should_reload():
            self._load()

        # Try loaded config first
        if section in self._config and key in self._config[section]:
            return self._config[section][key]

        # Fall back to defaults
        if section in DEFAULTS and key in DEFAULTS[section]:
            return DEFAULTS[section][key]

        return default

    def get_section(self, section: str) -> dict:
        """Get an entire config section."""
        if self._should_reload():
            self._load()

        result = dict(DEFAULTS.get(section, {}))
        result.update(self._config.get(section, {}))
        return result

    def reload(self) -> None:
        """Force reload config from disk."""
        self._load()


# =============================================================================
# SINGLETON INSTANCE
# =============================================================================

config = HookConfig()


# =============================================================================
# CONVENIENCE FUNCTIONS
# =============================================================================


def get_cooldown(name: str) -> int:
    """Get cooldown duration in seconds."""
    return config.get("cooldowns", name, 120)


def get_threshold(name: str) -> int:
    """Get threshold value."""
    return config.get("thresholds", name, 0)


def get_limit(name: str) -> int:
    """Get limit value."""
    return config.get("limits", name, 10)


def get_ttl(name: str) -> float:
    """Get TTL value in seconds."""
    return config.get("ttl", name, 5.0)


def get_patterns(name: str) -> list:
    """Get pattern list."""
    return config.get("patterns", name, [])


def is_protected_path(path: str) -> bool:
    """Check if path is in protected locations."""
    protected = get_patterns("protected_paths")
    return any(p in path for p in protected)


# NOTE: is_scratch_path moved to _patterns.py (single source of truth)
# Use: from _patterns import is_scratch_path


def get_tool_name(key: str) -> str:
    """Get canonical tool name (avoids magic strings)."""
    return TOOL_NAMES.get(key, key.title())


def get_magic_number(key: str, default: int = 0) -> int:
    """Get magic number constant."""
    return MAGIC_NUMBERS.get(key, default)
</file>

<file path="_cooldown.py">
"""
Cooldown management utilities for hook runners.

Replaces 8+ duplicate cooldown implementations with a single, file-locked manager.
"""

import fcntl
import json
import time
from pathlib import Path
from typing import Optional

from _config import get_cooldown

# =============================================================================
# COOLDOWN MANAGER
# =============================================================================

MEMORY_DIR = Path.home() / ".claude" / "memory"


class CooldownManager:
    """Manage cooldowns with file-based persistence and locking."""

    def __init__(self, name: str, ttl: Optional[int] = None):
        """
        Initialize cooldown manager.

        Args:
            name: Cooldown identifier (e.g., "assumption", "mutation")
            ttl: Time-to-live in seconds. If None, uses centralized config.
        """
        self.name = name
        self.ttl = ttl if ttl is not None else get_cooldown(name)
        self.file = MEMORY_DIR / f"{name}_cooldown.json"

    def is_active(self) -> bool:
        """Check if cooldown is currently active (should skip)."""
        try:
            if not self.file.exists():
                return False
            data = json.loads(self.file.read_text())
            last = data.get("last", 0)
            return time.time() - last < self.ttl
        except (json.JSONDecodeError, OSError, IOError):
            return False

    def reset(self) -> None:
        """Reset cooldown (mark as triggered now) with file locking."""
        try:
            self.file.parent.mkdir(parents=True, exist_ok=True)

            # Use file locking to prevent race conditions
            with open(self.file, "w") as f:
                try:
                    fcntl.flock(f.fileno(), fcntl.LOCK_EX | fcntl.LOCK_NB)
                    json.dump({"last": time.time()}, f)
                    fcntl.flock(f.fileno(), fcntl.LOCK_UN)
                except BlockingIOError:
                    # Another process has the lock, write anyway
                    json.dump({"last": time.time()}, f)
        except (OSError, IOError):
            pass

    def clear(self) -> None:
        """Clear cooldown (allow immediate trigger)."""
        try:
            if self.file.exists():
                self.file.unlink()
        except OSError:
            pass

    def time_remaining(self) -> float:
        """Get seconds remaining in cooldown, or 0 if not active."""
        try:
            if not self.file.exists():
                return 0
            data = json.loads(self.file.read_text())
            last = data.get("last", 0)
            remaining = self.ttl - (time.time() - last)
            return max(0, remaining)
        except (json.JSONDecodeError, OSError, IOError):
            return 0

    def check_and_reset(self) -> bool:
        """
        Check if cooldown allows action and reset if so.

        Returns:
            True if action is allowed (cooldown was inactive), False otherwise.
        """
        if self.is_active():
            return False
        self.reset()
        return True


# =============================================================================
# SINGLETON INSTANCES FOR COMMON COOLDOWNS
# =============================================================================

assumption_cooldown = CooldownManager("assumption")
mutation_cooldown = CooldownManager("mutation")
toolchain_cooldown = CooldownManager("toolchain")
tool_awareness_cooldown = CooldownManager("tool_awareness")
large_file_cooldown = CooldownManager("large_file")


# =============================================================================
# CONVENIENCE FUNCTIONS
# =============================================================================


def is_on_cooldown(name: str) -> bool:
    """Check if a named cooldown is active."""
    return CooldownManager(name).is_active()


def reset_cooldown(name: str) -> None:
    """Reset a named cooldown."""
    CooldownManager(name).reset()


def check_and_reset_cooldown(name: str) -> bool:
    """Check if cooldown allows action and reset if so."""
    return CooldownManager(name).check_and_reset()


# =============================================================================
# KEYED COOLDOWN MANAGER (for per-file, per-extension cooldowns)
# =============================================================================


class KeyedCooldownManager:
    """Manage cooldowns with multiple keys (e.g., per-file, per-extension).

    Stores all keys in a single JSON file with automatic LRU eviction.
    """

    def __init__(self, name: str, ttl: Optional[int] = None, max_keys: int = 50):
        """
        Initialize keyed cooldown manager.

        Args:
            name: Cooldown identifier (e.g., "toolchain", "large_file")
            ttl: Time-to-live in seconds. If None, uses centralized config.
            max_keys: Maximum keys to track (LRU eviction when exceeded).
        """
        self.name = name
        self.ttl = ttl if ttl is not None else get_cooldown(name)
        self.max_keys = max_keys
        self.file = MEMORY_DIR / f"{name}_keyed_cooldown.json"
        self._cache: Optional[dict] = None
        self._cache_mtime: float = 0

    def _load(self) -> dict:
        """Load cooldowns from file with caching."""
        try:
            if not self.file.exists():
                return {}
            mtime = self.file.stat().st_mtime
            if self._cache is not None and mtime == self._cache_mtime:
                return self._cache
            self._cache = json.loads(self.file.read_text())
            self._cache_mtime = mtime
            return self._cache
        except (json.JSONDecodeError, OSError, IOError):
            return {}

    def _save(self, data: dict) -> None:
        """Save cooldowns to file with locking and LRU eviction."""
        try:
            # LRU eviction if over capacity
            if len(data) > self.max_keys:
                sorted_items = sorted(data.items(), key=lambda x: x[1], reverse=True)
                data = dict(sorted_items[: self.max_keys])

            self.file.parent.mkdir(parents=True, exist_ok=True)
            with open(self.file, "w") as f:
                try:
                    fcntl.flock(f.fileno(), fcntl.LOCK_EX | fcntl.LOCK_NB)
                    json.dump(data, f)
                    fcntl.flock(f.fileno(), fcntl.LOCK_UN)
                except BlockingIOError:
                    json.dump(data, f)
            self._cache = data
            self._cache_mtime = self.file.stat().st_mtime
        except (OSError, IOError):
            pass

    def is_active(self, key: str) -> bool:
        """Check if cooldown is active for a specific key."""
        data = self._load()
        last = data.get(key, 0)
        return time.time() - last < self.ttl

    def reset(self, key: str) -> None:
        """Reset cooldown for a specific key."""
        data = self._load()
        data[key] = time.time()
        self._save(data)

    def check_and_reset(self, key: str) -> bool:
        """Check if cooldown allows action and reset if so.

        Returns:
            True if action is allowed (cooldown was inactive), False otherwise.
        """
        if self.is_active(key):
            return False
        self.reset(key)
        return True

    def clear(self, key: Optional[str] = None) -> None:
        """Clear cooldown for a key, or all keys if key is None."""
        if key is None:
            try:
                if self.file.exists():
                    self.file.unlink()
                self._cache = None
            except OSError:
                pass
        else:
            data = self._load()
            data.pop(key, None)
            self._save(data)


# =============================================================================
# SINGLETON INSTANCES FOR KEYED COOLDOWNS
# =============================================================================

toolchain_keyed = KeyedCooldownManager("toolchain", ttl=300, max_keys=20)
large_file_keyed = KeyedCooldownManager("large_file", ttl=600, max_keys=20)
tool_awareness_keyed = KeyedCooldownManager("tool_awareness", ttl=300, max_keys=10)
crawl4ai_promo_keyed = KeyedCooldownManager("crawl4ai_promo", ttl=600, max_keys=20)
beads_sync_cooldown = CooldownManager("beads_sync", ttl=300)
</file>

<file path="_hook_registry.py">
"""
Shared hook registry for PostToolUse hooks.

Allows hooks to be split across multiple modules while sharing a single registry.
Hook modules import `register_hook` and `HOOKS` from here.
"""

import os
import re
from typing import Optional, Callable

# Format: (name, matcher_pattern, check_function, priority)
# Lower priority = runs first
# matcher_pattern: None = all tools, str = regex pattern
HOOKS: list[tuple[str, Optional[str], Callable, int]] = []


def register_hook(name: str, matcher: Optional[str], priority: int = 50):
    """Decorator to register a PostToolUse hook check function.

    Args:
        name: Hook identifier (used for disable env var)
        matcher: Regex pattern for tool names, None = all tools
        priority: Lower = runs first (0-100)

    Hooks can be disabled via environment variable:
        CLAUDE_HOOK_DISABLE_<NAME>=1

    Example:
        @register_hook("my_hook", "Bash|Edit", priority=50)
        def check_my_hook(data: dict, state: SessionState, runner_state: dict) -> HookResult:
            ...
    """

    def decorator(func: Callable):
        # Check if hook is disabled via environment variable
        env_key = f"CLAUDE_HOOK_DISABLE_{name.upper()}"
        if os.environ.get(env_key, "0") == "1":
            return func  # Skip registration
        HOOKS.append((name, matcher, func, priority))
        return func

    return decorator


def matches_tool(matcher: Optional[str], tool_name: str) -> bool:
    """Check if tool matches the hook's matcher pattern."""
    if matcher is None:
        return True
    return bool(re.match(f"^({matcher})$", tool_name))


def sort_hooks() -> None:
    """Sort hooks by priority. Call after all hook modules are imported."""
    HOOKS.sort(key=lambda x: x[3])
</file>

<file path="_hook_result.py">
"""
Unified HookResult class for all hook runners.

Provides consistent API across pre_tool_use, post_tool_use, and user_prompt_submit runners.
"""

from dataclasses import dataclass


@dataclass
class HookResult:
    """Result from a hook check.

    Attributes:
        decision: "approve" or "deny" - whether the tool call should proceed
        reason: Explanation for deny decisions
        context: Additional context to inject into the conversation
    """

    decision: str = "approve"
    reason: str = ""
    context: str = ""

    @staticmethod
    def approve(context: str = "") -> "HookResult":
        """Approve the action, optionally with context to inject."""
        return HookResult(decision="approve", context=context)

    @staticmethod
    def deny(reason: str) -> "HookResult":
        """Deny the action with an explanation."""
        return HookResult(decision="deny", reason=reason)

    # Aliases for backward compatibility and convenience
    @staticmethod
    def allow(context: str = "") -> "HookResult":
        """Alias for approve() - for consistency with user_prompt_submit patterns."""
        return HookResult(decision="approve", context=context)

    @staticmethod
    def none() -> "HookResult":
        """Return empty result (no context, no denial) - alias for approve()."""
        return HookResult()

    @staticmethod
    def with_context(context: str) -> "HookResult":
        """Approve with context to inject - alias for approve(context)."""
        return HookResult(decision="approve", context=context)
</file>

<file path="_hooks_cache.py">
"""
Cache-related PostToolUse hooks.

Handles caching of exploration results and read file contents.
Priority range: 5-6
"""

import _lib_path  # noqa: F401
from pathlib import Path

from _hook_registry import register_hook
from _hook_result import HookResult
from _logging import log_debug
from session_state import SessionState


@register_hook("exploration_cacher", "Task", priority=5)
def check_exploration_cacher(
    data: dict, state: SessionState, runner_state: dict
) -> HookResult:
    """Cache exploration results after Task(Explore) completes."""
    tool_input = data.get("tool_input", {})
    subagent_type = tool_input.get("subagent_type", "")

    if subagent_type.lower() != "explore":
        return HookResult.allow()

    prompt = tool_input.get("prompt", "")
    result = data.get("tool_result", {})

    # Get the agent's response
    agent_output = ""
    if isinstance(result, dict):
        agent_output = (
            result.get("content", "") or result.get("output", "") or str(result)
        )
    elif isinstance(result, str):
        agent_output = result

    # Don't cache empty or error results
    if not agent_output or len(agent_output) < 50:
        return HookResult.allow()
    if "error" in agent_output.lower()[:100]:
        return HookResult.allow()

    # Detect project path
    try:
        from project_detector import detect_project

        project_info = detect_project()
        if not project_info or not project_info.get("path"):
            return HookResult.allow()
        project_path = project_info["path"]
    except Exception:
        return HookResult.allow()

    # Cache the result
    try:
        from cache.exploration_cache import cache_exploration

        cache_exploration(
            project_path=Path(project_path),
            query=prompt,
            result=agent_output[:5000],
            directory_path="",
            touched_files=[],
        )
    except Exception as e:
        log_debug("_hooks_cache", f"exploration cache write failed: {e}")

    return HookResult.allow()


@register_hook("read_cacher", "Read", priority=6)
def check_read_cacher(
    data: dict, state: SessionState, runner_state: dict
) -> HookResult:
    """Cache successful Read results for memoization."""
    tool_input = data.get("tool_input", {})
    file_path = tool_input.get("file_path", "")

    if not file_path:
        return HookResult.allow()

    # Don't cache partial reads
    if tool_input.get("offset") or tool_input.get("limit"):
        return HookResult.allow()

    result = data.get("tool_result", {})

    # Get the file content from result
    content = ""
    if isinstance(result, dict):
        content = result.get("content", "") or result.get("output", "") or ""
    elif isinstance(result, str):
        content = result

    # Don't cache errors or empty results
    if not content or "error" in content.lower()[:50]:
        return HookResult.allow()

    try:
        from cache.read_cache import cache_read_result

        cache_read_result(file_path, content)
    except Exception as e:
        log_debug("_hooks_cache", f"read cache write failed: {e}")

    return HookResult.allow()


@register_hook("read_cache_invalidator", "Write|Edit", priority=6)
def check_read_cache_invalidator(
    data: dict, state: SessionState, runner_state: dict
) -> HookResult:
    """Invalidate read cache when files are written or edited."""
    tool_input = data.get("tool_input", {})
    file_path = tool_input.get("file_path", "")

    if not file_path:
        return HookResult.allow()

    try:
        from cache.read_cache import invalidate_read_cache

        invalidate_read_cache(file_path)
    except Exception as e:
        log_debug("_hooks_cache", f"read cache invalidation failed: {e}")

    return HookResult.allow()
</file>

<file path="_hooks_quality.py">
"""
Quality gate PostToolUse hooks.

Code quality checks, UI verification, toolchain suggestions.
Priority range: 22-50
"""

import _lib_path  # noqa: F401
import re
from pathlib import Path

from _hook_registry import register_hook
from _hook_result import HookResult
from _cooldown import (
    assumption_cooldown,
    mutation_cooldown,
    toolchain_keyed,
    large_file_keyed,
    tool_awareness_keyed,
    crawl4ai_promo_keyed,
)
from _patterns import is_scratch_path
from _config import get_magic_number

from session_state import SessionState, get_adaptive_threshold, record_threshold_trigger

# Quality scanner (ruff + radon)
try:
    from _quality_scanner import scan_file as quality_scan_file, format_report

    QUALITY_SCANNER_AVAILABLE = True
except ImportError:
    QUALITY_SCANNER_AVAILABLE = False
    quality_scan_file = None
    format_report = None


# Assumption detection patterns
_ASSUMPTION_PATTERNS = [
    (re.compile(r"\bNone\b"), "Assuming value is not None - verify nullability"),
    (re.compile(r"\[0\]|\[-1\]"), "Assuming collection is non-empty - check edge case"),
    (
        re.compile(r"\.get\([^,)]+\)"),
        "Using .get() - verify default behavior is correct",
    ),
    (re.compile(r"try:\s*\n\s*\w"), "Assuming exception handling covers all cases"),
    (re.compile(r"await\s+\w+"), "Assuming async operation succeeds - handle failures"),
    (re.compile(r"open\(|Path\(.*\)\.read"), "Assuming file exists and is readable"),
    (re.compile(r"json\.loads|JSON\.parse"), "Assuming valid JSON input"),
    (re.compile(r'\[\s*["\'][^"\']+["\']\s*\]'), "Assuming key exists in dict/object"),
]

# UI file detection patterns
_UI_FILE_PATTERNS = [
    re.compile(r"\.css$", re.IGNORECASE),
    re.compile(r"\.scss$", re.IGNORECASE),
    re.compile(r"\.less$", re.IGNORECASE),
    re.compile(r"\.sass$", re.IGNORECASE),
    re.compile(r"style", re.IGNORECASE),
    re.compile(r"theme", re.IGNORECASE),
    re.compile(r"\.tsx$", re.IGNORECASE),
    re.compile(r"\.vue$", re.IGNORECASE),
    re.compile(r"\.svelte$", re.IGNORECASE),
]

# Style content patterns
_STYLE_CONTENT_PATTERNS = [
    re.compile(r"className\s*="),
    re.compile(r"style\s*=\s*\{"),
    re.compile(r"styled\."),
    re.compile(r"css`"),
    re.compile(r"@apply\s+"),
    re.compile(r"sx\s*=\s*\{"),
    re.compile(r'class\s*=\s*["\'][\w\s-]+["\']'),
    re.compile(r"(background|color|margin|padding|display|flex|grid|width|height)\s*:"),
]

# React/JS mutation patterns
_JS_MUTATION_PATTERNS = [
    (
        re.compile(r"\.(push|pop|shift|unshift|splice)\s*\("),
        "Array mutation ({0}) - use spread: [...arr, item]",
    ),
    (re.compile(r"\.sort\s*\(\s*\)"), "In-place sort - use [...arr].sort()"),
    (re.compile(r"\.reverse\s*\(\s*\)"), "In-place reverse - use [...arr].reverse()"),
    (
        re.compile(r"set[A-Z]\w*\(\s*\w+\s*\.\s*\w+\s*="),
        "State mutation in setter - use spread: setState({{...prev, key: val}})",
    ),
]

# Python mutation patterns - now AST-based in _ast_utils.find_mutable_defaults()

# Spread operator check for JS mutation guard
_SPREAD_CHECK = re.compile(r"\[\.\.\.\w+\]\s*$")


# -----------------------------------------------------------------------------
# ASSUMPTION CHECK (priority 22) - Heuristic-based, no Groq call
# -----------------------------------------------------------------------------


@register_hook("assumption_check", "Edit|Write", priority=22)
def check_assumptions(
    data: dict, state: SessionState, runner_state: dict
) -> HookResult:
    """Surface hidden assumptions in code changes (heuristic-based)."""
    tool_input = data.get("tool_input", {})
    file_path = tool_input.get("file_path", "")

    # Skip scratch/temp files
    if is_scratch_path(file_path):
        return HookResult.none()

    code = tool_input.get("new_string", "") or tool_input.get("content", "")
    if not code or len(code) < 100:
        return HookResult.none()

    # Check cooldown (don't spam)
    if assumption_cooldown.is_active():
        return HookResult.none()

    # Find assumptions (use pre-compiled patterns)
    found = []
    for pattern, assumption in _ASSUMPTION_PATTERNS:
        if pattern.search(code):
            found.append(assumption)
            if len(found) >= 2:
                break

    if found:
        assumption_cooldown.reset()
        return HookResult.with_context(
            " **ASSUMPTION CHECK**:\n" + "\n".join(f"   {a}" for a in found[:2])
        )

    return HookResult.none()


# -----------------------------------------------------------------------------
# VERIFICATION REMINDER (priority 25)
# -----------------------------------------------------------------------------


@register_hook("verification_reminder", "Edit|Write|MultiEdit", priority=25)
def check_verification_reminder(
    data: dict, state: SessionState, runner_state: dict
) -> HookResult:
    """Remind to verify after fix iterations."""
    tool_input = data.get("tool_input", {})
    file_path = tool_input.get("file_path", "")

    fix_indicators = []

    # File edited multiple times
    edit_count = sum(1 for f in state.files_edited if f == file_path)
    if edit_count >= 2:
        fix_indicators.append(f"edited {edit_count}x")

    # Recent errors exist
    if state.errors_unresolved:
        fix_indicators.append("unresolved errors exist")

    # "fix" in filename
    if "fix" in file_path.lower():
        fix_indicators.append("'fix' in filename")

    verify_run = getattr(state, "verify_run", False)

    if fix_indicators and not verify_run:
        return HookResult.with_context(
            f" VERIFY REMINDER: {', '.join(fix_indicators)}  run `verify` or tests before claiming fixed"
        )

    return HookResult.none()


# -----------------------------------------------------------------------------
# UI VERIFICATION GATE (priority 30)
# -----------------------------------------------------------------------------


@register_hook("ui_verification_gate", "Edit|Write|MultiEdit", priority=30)
def check_ui_verification(
    data: dict, state: SessionState, runner_state: dict
) -> HookResult:
    """Require browser screenshot after CSS/UI changes."""
    tool_name = data.get("tool_name", "")
    tool_input = data.get("tool_input", {})
    file_path = tool_input.get("file_path", "")

    content = ""
    if tool_name == "Write":
        content = tool_input.get("content", "")
    elif tool_name == "Edit":
        content = tool_input.get("new_string", "")

    # Use pre-compiled patterns from module level
    indicators = []
    for pattern in _UI_FILE_PATTERNS:
        if pattern.search(file_path):
            indicators.append(f"UI file: {pattern.pattern}")
            break

    for pattern in _STYLE_CONTENT_PATTERNS:
        if pattern.search(content):
            indicators.append("style pattern detected")
            break

    if not indicators:
        return HookResult.none()

    browser_used = getattr(state, "browser_screenshot_taken", False)
    if browser_used:
        return HookResult.none()

    return HookResult.with_context(
        f" UI VERIFY: {', '.join(indicators[:2])}  `browser page screenshot -o .claude/tmp/ui_check.png`"
    )


# -----------------------------------------------------------------------------
# CODE QUALITY GATE (priority 35)
# Uses adaptive thresholds from session_state (v3.7) - self-tuning based on usage
# Fallback defaults if adaptive system unavailable:
# -----------------------------------------------------------------------------

# Fallback defaults (overridden by adaptive thresholds when available)
MAX_METHOD_LINES = 60
MAX_CONDITIONALS = 12
MAX_DEBUG_STATEMENTS = 5
MAX_NESTING_DEPTH = 5

PATTERN_CONDITIONALS = re.compile(
    r"\b(if|elif|else|for|while|except|try|switch|case)\b"
)
PATTERN_TRY_BLOCK = re.compile(r"\b(try\s*:|try\s*\{)")
PATTERN_EXCEPT_BLOCK = re.compile(r"\b(except|catch)\b")
PATTERN_DEBUG_PY = re.compile(r"\bprint\s*\(", re.IGNORECASE)
PATTERN_DEBUG_JS = re.compile(r"\bconsole\.(log|debug|info|warn|error)\s*\(")
PATTERN_N_PLUS_ONE = re.compile(
    r"for\s+.*?\s+in\s+.*?:\s*\n?\s*.*?(query|fetch|load|select|find|get)\s*\(",
    re.MULTILINE | re.IGNORECASE,
)
# Nested loops: Match actual indented nesting (outer loop then indented inner loop)
PATTERN_NESTED_LOOPS = re.compile(
    r"^[ ]{0,8}(for|while)\s+[^\n]+:\s*\n"  # Outer loop
    r"(?:[ ]{4,}[^\n]*\n)*?"  # Skip lines until...
    r"[ ]{4,}(for|while)\s+[^\n]+:",  # Inner loop (more indented)
    re.MULTILINE,
)

# NEW: Additional performance anti-patterns from old system
PATTERN_STRING_CONCAT_LOOP = re.compile(
    r"for\s+.*?[:{]\s*\n?\s*.*?\+=\s*['\"]", re.MULTILINE
)
# Triple loop: Match actual indented nesting, not just 3 keywords anywhere
# Pattern: for/while at col 0-4, then indented for/while, then more indented for/while
PATTERN_TRIPLE_LOOP = re.compile(
    r"^[ ]{0,4}(for|while)\s+[^\n]+:\s*\n"  # Outer loop at indent 0-4
    r"(?:[ ]{4,}[^\n]*\n)*?"  # Skip lines until...
    r"[ ]{4,8}(for|while)\s+[^\n]+:\s*\n"  # Middle loop at indent 4-8
    r"(?:[ ]{8,}[^\n]*\n)*?"  # Skip lines until...
    r"[ ]{8,}(for|while)\s+[^\n]+:",  # Inner loop at indent 8+
    re.MULTILINE,
)
PATTERN_BLOCKING_IO_NODE = re.compile(
    r"\b(readFileSync|writeFileSync|existsSync|execSync)\s*\("
)
PATTERN_BLOCKING_IO_PY = re.compile(
    r"\bopen\s*\([^)]+\)\s*\.\s*read\s*\(\s*\)(?!\s*#.*async)"
)
PATTERN_MAGIC_NUMBERS = re.compile(
    r"(?<![.\w])(?:0x[a-fA-F0-9]+|\d{3,})(?![.\w])"
)  # Numbers >= 100 or hex
PATTERN_TODO_FIXME = re.compile(r"\b(TODO|FIXME|HACK|XXX)\b", re.IGNORECASE)


def _check_structure_patterns(
    code: str, file_path: str, state: SessionState
) -> tuple[list[str], list[tuple[str, int]]]:
    """Check structural code patterns (length, complexity, nesting)."""
    hints = []
    triggered = []

    threshold_lines = get_adaptive_threshold(state, "quality_long_method")
    threshold_complexity = get_adaptive_threshold(state, "quality_high_complexity")
    threshold_nesting = get_adaptive_threshold(state, "quality_deep_nesting")

    # Long method
    lines = code.count("\n") + 1
    if lines > threshold_lines:
        hints.append(f" **Long Code Block**: {lines} lines (<{int(threshold_lines)})")
        triggered.append(("quality_long_method", lines))

    # High complexity
    conditionals = len(PATTERN_CONDITIONALS.findall(code))
    if conditionals > threshold_complexity:
        hints.append(f" **High Complexity**: {conditionals} conditionals")
        triggered.append(("quality_high_complexity", conditionals))

    # Deep nesting
    max_indent = max(
        (len(ln) - len(ln.lstrip()) for ln in code.split("\n") if ln.strip()), default=0
    )
    nesting_levels = max_indent // 4
    if nesting_levels > threshold_nesting:
        hints.append(f" **Deep Nesting**: {nesting_levels} levels")
        triggered.append(("quality_deep_nesting", nesting_levels))

    return hints, triggered


def _check_perf_patterns(code: str, file_path: str) -> list[str]:
    """Check performance-related anti-patterns."""
    hints = []
    is_python = file_path.endswith(".py")
    is_js = file_path.endswith((".js", ".ts", ".jsx", ".tsx"))

    # N+1 query
    if PATTERN_N_PLUS_ONE.search(code):
        hints.append(" **Potential N+1**: DB/API call in loop")

    # Nested loops
    if PATTERN_TRIPLE_LOOP.search(code):
        hints.append(" **Triple Nested Loops**: O(n) complexity!")
    elif PATTERN_NESTED_LOOPS.search(code):
        hints.append(" **Nested Loops**: O(n) complexity")

    # String concat in loops
    if PATTERN_STRING_CONCAT_LOOP.search(code):
        hints.append(" **String Concat in Loop**: Use join() instead")

    # Blocking I/O
    if is_js and PATTERN_BLOCKING_IO_NODE.search(code):
        hints.append(" **Blocking I/O**: Use async fs methods")
    elif is_python and PATTERN_BLOCKING_IO_PY.search(code):
        hints.append(" **Blocking Read**: Use `with open()` pattern")

    return hints


def _check_quality_markers(
    code: str, file_path: str, state: SessionState
) -> tuple[list[str], list[tuple[str, int]]]:
    """Check code quality markers (debug, magic numbers, TODOs)."""
    hints = []
    triggered = []
    is_python = file_path.endswith(".py")
    is_js = file_path.endswith((".js", ".ts", ".jsx", ".tsx"))
    is_cli_tool = "/ops/" in file_path or "/.claude/hooks/" in file_path

    # Missing error handling
    if PATTERN_TRY_BLOCK.search(code) and not PATTERN_EXCEPT_BLOCK.search(code):
        hints.append(" **Missing Error Handler**: try without catch/except")

    # Debug statements (skip CLI tools)
    threshold_debug = get_adaptive_threshold(state, "quality_debug_statements")
    debug_count = (
        len(PATTERN_DEBUG_PY.findall(code))
        if is_python
        else (len(PATTERN_DEBUG_JS.findall(code)) if is_js else 0)
    )
    if debug_count > threshold_debug and not is_cli_tool:
        hints.append(f" **Debug Statements**: {debug_count} found")
        triggered.append(("quality_debug_statements", debug_count))

    # Magic numbers
    threshold_magic = get_adaptive_threshold(state, "quality_magic_numbers")
    magic_count = len(PATTERN_MAGIC_NUMBERS.findall(code))
    if magic_count > threshold_magic:
        hints.append(f" **Magic Numbers**: {magic_count} literals")
        triggered.append(("quality_magic_numbers", magic_count))

    # Tech debt markers
    threshold_debt = get_adaptive_threshold(state, "quality_tech_debt_markers")
    todo_count = len(PATTERN_TODO_FIXME.findall(code))
    if todo_count > threshold_debt:
        hints.append(f" **Tech Debt**: {todo_count} TODO/FIXME markers")
        triggered.append(("quality_tech_debt_markers", todo_count))

    return hints, triggered


@register_hook("code_quality_gate", "Edit|Write", priority=35)
def check_code_quality(
    data: dict, state: SessionState, runner_state: dict
) -> HookResult:
    """Detect code quality anti-patterns with adaptive thresholds."""
    tool_input = data.get("tool_input", {})
    file_path = tool_input.get("file_path", "")

    code_extensions = (
        ".py",
        ".js",
        ".ts",
        ".jsx",
        ".tsx",
        ".go",
        ".rs",
        ".java",
        ".rb",
        ".sh",
    )
    if not file_path.endswith(code_extensions):
        return HookResult.none()

    code = tool_input.get("content", "") or tool_input.get("new_string", "")
    if not code or len(code) < 50:
        return HookResult.none()

    # Collect hints from specialized checkers
    hints = []
    triggered_patterns = []

    struct_hints, struct_triggered = _check_structure_patterns(code, file_path, state)
    hints.extend(struct_hints)
    triggered_patterns.extend(struct_triggered)

    hints.extend(_check_perf_patterns(code, file_path))

    marker_hints, marker_triggered = _check_quality_markers(code, file_path, state)
    hints.extend(marker_hints)
    triggered_patterns.extend(marker_triggered)

    if hints:
        for pattern_name, value in triggered_patterns:
            record_threshold_trigger(state, pattern_name, value)
        return HookResult.with_context(
            " **Code Quality Check**:\n" + "\n".join(hints[:4])
        )

    return HookResult.none()


# -----------------------------------------------------------------------------
# QUALITY SCANNER (priority 36) - ruff + radon code quality
# -----------------------------------------------------------------------------


@register_hook("quality_scanner", "Edit|Write", priority=36)
def check_quality_scan(
    data: dict, state: SessionState, runner_state: dict
) -> HookResult:
    """Scan code for quality issues using ruff (lint) and radon (complexity).

    Fast rule-based analysis - no ML model required.
    Advisory only - warns but doesn't block.
    """
    if not QUALITY_SCANNER_AVAILABLE or quality_scan_file is None:
        return HookResult.none()

    tool_input = data.get("tool_input", {})
    file_path = tool_input.get("file_path", "")

    # Only scan Python files (ruff/radon are Python-focused)
    if not file_path.endswith(".py"):
        return HookResult.none()

    # Skip scratch/tmp files
    if is_scratch_path(file_path):
        return HookResult.none()

    # Scan file for quality issues
    result = quality_scan_file(file_path, complexity_threshold="C")

    if result is None:
        return HookResult.none()

    # Quality issues found - advisory warning
    report = format_report(result)
    if report:
        return HookResult.with_context(report)

    return HookResult.none()


# -----------------------------------------------------------------------------
# STATE MUTATION GUARD (priority 37) - React/JS + Python anti-patterns
# -----------------------------------------------------------------------------


def _check_js_mutations(code: str) -> list[str]:
    """Check JS/TS code for state mutation anti-patterns."""
    warnings = []
    for pattern, msg in _JS_MUTATION_PATTERNS:
        match = pattern.search(code)
        if not match:
            continue
        # Skip if clearly on spread [...arr].sort()
        if match.group(0) in (".sort()", ".reverse()"):
            context = code[max(0, match.start() - 10) : match.start()]
            if _SPREAD_CHECK.search(context):
                continue
        try:
            warnings.append(
                msg.format(match.group(1) if match.lastindex else match.group(0))
            )
        except (IndexError, AttributeError):
            warnings.append(msg.format("method"))
    return warnings


def _check_py_mutations(code: str) -> list[str]:
    """Check Python code for mutable default anti-patterns."""
    from _ast_utils import find_mutable_defaults

    warnings = []
    for func_name, line, mtype in find_mutable_defaults(code)[:2]:
        warnings.append(
            f"Mutable default {mtype} in {func_name}() - use None and set in body"
        )
    return warnings


@register_hook("state_mutation_guard", "Edit|Write", priority=37)
def check_state_mutations(
    data: dict, state: SessionState, runner_state: dict
) -> HookResult:
    """Detect state mutation anti-patterns in React/JS and Python."""
    tool_input = data.get("tool_input", {})
    file_path = tool_input.get("file_path", "")

    if is_scratch_path(file_path) or mutation_cooldown.is_active():
        return HookResult.none()

    code = tool_input.get("new_string", "") or tool_input.get("content", "")
    if not code or len(code) < 50:
        return HookResult.none()

    # Dispatch to language-specific checker
    if file_path.endswith((".js", ".ts", ".jsx", ".tsx")):
        warnings = _check_js_mutations(code)
    elif file_path.endswith(".py"):
        warnings = _check_py_mutations(code)
    else:
        return HookResult.none()

    if warnings:
        mutation_cooldown.reset()
        return HookResult.with_context(
            " **State Mutation Warning**:\n"
            + "\n".join(f"   {w}" for w in warnings[:2])
        )

    return HookResult.none()


# -----------------------------------------------------------------------------
# DEV TOOLCHAIN SUGGESTIONS (priority 40) - Language-specific lint/format/check
# -----------------------------------------------------------------------------

# Language -> (formatter, linter, typechecker)
DEV_TOOLCHAIN = {
    ".py": ("ruff format {file}", "ruff check --fix {file}", "mypy {file}"),
    ".ts": (
        "npx prettier --write {file}",
        "npx eslint --fix {file}",
        "npx tsc --noEmit",
    ),
    ".tsx": (
        "npx prettier --write {file}",
        "npx eslint --fix {file}",
        "npx tsc --noEmit",
    ),
    ".js": ("npx prettier --write {file}", "npx eslint --fix {file}", None),
    ".jsx": ("npx prettier --write {file}", "npx eslint --fix {file}", None),
    ".json": ("npx prettier --write {file}", None, None),
    ".css": ("npx prettier --write {file}", None, None),
    ".scss": ("npx prettier --write {file}", None, None),
    ".html": ("npx prettier --write {file}", None, None),
    ".md": ("npx prettier --write {file}", None, None),
    ".yaml": ("npx prettier --write {file}", None, None),
    ".yml": ("npx prettier --write {file}", None, None),
}


@register_hook("dev_toolchain_suggest", "Edit|Write", priority=40)
def check_dev_toolchain(
    data: dict, state: SessionState, runner_state: dict
) -> HookResult:
    """Suggest language-appropriate dev tools after edits."""
    tool_input = data.get("tool_input", {})
    file_path = tool_input.get("file_path", "")

    if is_scratch_path(file_path):
        return HookResult.none()

    # Find matching extension
    ext = None
    for e in DEV_TOOLCHAIN:
        if file_path.endswith(e):
            ext = e
            break

    if not ext:
        return HookResult.none()

    # Check cooldown per extension (5 min per language)
    if toolchain_keyed.is_active(ext):
        return HookResult.none()

    formatter, linter, typechecker = DEV_TOOLCHAIN[ext]
    suggestions = []

    if formatter:
        suggestions.append(f"Format: `{formatter.format(file=Path(file_path).name)}`")
    if linter:
        suggestions.append(f"Lint: `{linter.format(file=Path(file_path).name)}`")
    if typechecker:
        suggestions.append(f"Typecheck: `{typechecker}`")

    if suggestions:
        toolchain_keyed.reset(ext)
        return HookResult.with_context(
            f" **Dev Tools** ({ext}):\n  " + "\n  ".join(suggestions[:2])
        )

    return HookResult.none()


# -----------------------------------------------------------------------------
# LARGE FILE HELPER (priority 45) - Line range guidance for big files
# -----------------------------------------------------------------------------

LARGE_FILE_THRESHOLD = get_magic_number("large_file_threshold", 500)


@register_hook("large_file_helper", "Read", priority=45)
def check_large_file(data: dict, state: SessionState, runner_state: dict) -> HookResult:
    """Provide line range guidance for large files."""
    tool_input = data.get("tool_input", {})
    tool_result = data.get("tool_result", {})
    file_path = tool_input.get("file_path", "")

    if not file_path:
        return HookResult.none()

    # Guard against non-dict results
    if not isinstance(tool_result, dict):
        return HookResult.none()

    # Check if file is large (estimate from output)
    output = tool_result.get("output", "")
    line_count = output.count("\n")

    if line_count < LARGE_FILE_THRESHOLD:
        return HookResult.none()

    # Check cooldown per file (10 min)
    if large_file_keyed.is_active(file_path):
        return HookResult.none()

    large_file_keyed.reset(file_path)
    filename = Path(file_path).name
    return HookResult.with_context(
        f" **Large File** ({line_count}+ lines): `{filename}`\n"
        f"  For edits, use line-range reads: `Read {filename} lines X-Y`\n"
        f"  Look for section markers: `// === SECTION ===` or `# --- SECTION ---`"
    )


# -----------------------------------------------------------------------------
# CRAWL4AI PROMOTION (priority 48) - Suggest crawl4ai over WebFetch
# -----------------------------------------------------------------------------


@register_hook("crawl4ai_promo", "WebFetch", priority=48)
def promote_crawl4ai(data: dict, state: SessionState, runner_state: dict) -> HookResult:
    """Promote crawl4ai MCP when WebFetch is used - crawl4ai is superior for web content."""
    tool_input = data.get("tool_input", {})
    url = tool_input.get("url", "")

    if not url:
        return HookResult.none()

    # Extract domain for keyed cooldown
    domain_match = re.search(r"https?://([^/]+)", url)
    domain = domain_match.group(1) if domain_match else "unknown"

    # Skip if recently promoted for this domain
    if crawl4ai_promo_keyed.is_active(domain):
        return HookResult.none()

    crawl4ai_promo_keyed.reset(domain)

    return HookResult.with_context(
        " **Crawl4AI Available** - Superior to WebFetch:\n"
        "   Full JavaScript rendering (SPAs, dynamic content)\n"
        "   Bypasses Cloudflare, bot detection, CAPTCHAs\n"
        "   Returns clean LLM-friendly markdown\n"
        "   `mcp__crawl4ai__crawl` for this URL\n"
        "   `mcp__crawl4ai__search` to discover related URLs"
    )


# -----------------------------------------------------------------------------
# TOOL AWARENESS (priority 50) - Remind about available tools
# -----------------------------------------------------------------------------

TOOL_AWARENESS_PATTERNS = {
    "playwright": {
        "pattern": re.compile(
            r"\b(manual.*test|test.*manual|browser.*test|click|navigate|form|button|webpage|e2e|integration test|screenshot)\b",
            re.IGNORECASE,
        ),
        "reminder": " **Playwright Available**: Use `mcp__playwright__*` tools for browser automation instead of manual testing.",
        "threshold": 2,
    },
    "pal_mcp": {
        "pattern": re.compile(
            r"\b(uncertain|not sure|complex|difficult|stuck|investigate|how to|unsure|maybe)\b",
            re.IGNORECASE,
        ),
        "reminder": " **PAL MCP Available**: `mcp__pal__chat/thinkdeep/debug` for deep analysis when uncertain.",
        "threshold": 3,
    },
    "websearch": {
        "pattern": re.compile(
            r"\b(latest|recent|current|new version|updated|documentation|best practice|2024|2025)\b",
            re.IGNORECASE,
        ),
        "reminder": " **WebSearch Available**: Search for latest docs/patterns instead of relying on training data.",
        "threshold": 2,
    },
    "task_agent": {
        "pattern": re.compile(
            r"\b(then|and then|after that|next|also|first.*then)\b", re.IGNORECASE
        ),
        "reminder": " **Task Agent**: For 3+ sequential tasks, use parallel Task agents for speed.",
        "threshold": 4,
    },
}


@register_hook("tool_awareness", "Read|Bash|Task", priority=50)
def check_tool_awareness(
    data: dict, state: SessionState, runner_state: dict
) -> HookResult:
    """Remind about available tools when relevant patterns detected."""
    tool_result = data.get("tool_result", {})
    output = (
        tool_result.get("output", "")
        if isinstance(tool_result, dict)
        else str(tool_result)
    )

    if not output or len(output) < 50:
        return HookResult.none()

    for tool_name, config in TOOL_AWARENESS_PATTERNS.items():
        # Skip if recently reminded (keyed cooldown)
        if tool_awareness_keyed.is_active(tool_name):
            continue

        matches = len(config["pattern"].findall(output))
        if matches >= config["threshold"]:
            tool_awareness_keyed.reset(tool_name)
            return HookResult.with_context(config["reminder"])

    return HookResult.none()
</file>

<file path="_hooks_state.py">
"""
State management PostToolUse hooks.

Updates session state, manages confidence decay/reduction/increase.
Priority range: 10-16
"""

import _lib_path  # noqa: F401
import json
import re
from pathlib import Path

from _hook_registry import register_hook
from _hook_result import HookResult
from _config import get_magic_number

from session_state import (
    SessionState,
    track_file_read,
    track_file_edit,
    track_file_create,
    track_command,
    track_library_used,
    track_error,
    resolve_error,
    add_domain_signal,
    extract_libraries_from_code,
    track_failure,
    reset_failures,
    track_batch_tool,
    clear_pending_file,
    clear_pending_search,
    extract_function_def_lines,
    add_pending_integration_grep,
    clear_integration_grep,
    create_checkpoint,
    track_feature_file,
    complete_feature,
    add_work_item,
    track_ops_tool,
    mark_production_verified,
    set_confidence,
)

from confidence import (
    apply_reducers,
    apply_increasers,
    apply_rate_limit,
    format_confidence_change,
    get_tier_info,
    format_dispute_instructions,
    predict_trajectory,
    format_trajectory_warning,
    get_current_streak,
)


# -----------------------------------------------------------------------------
# STATE UPDATER (priority 10) - Must run first to update state for other hooks
# -----------------------------------------------------------------------------

_RE_PYTEST_FAIL = re.compile(r"FAILED\s+([\w./]+)::(\w+)")
_RE_JEST_FAIL = re.compile(r"FAIL\s+([\w./]+)\s*\n.*?\s+(.+?)(?:\n|$)", re.MULTILINE)
_RE_GENERIC_FAIL = re.compile(r"(?:Error|FAIL|FAILED):\s*(.+?)(?:\n|$)")

# Time saver signal patterns
_RE_CHAIN_SEMICOLON = re.compile(r";\s*\w+")
_RE_CHAIN_SPLIT = re.compile(r"\s*&&\s*|\s*;\s*")

_TODO_PATTERNS = [
    (re.compile(r"#\s*TODO[:\s]+(.+?)(?:\n|$)", re.IGNORECASE), "TODO"),
    (re.compile(r"//\s*TODO[:\s]+(.+?)(?:\n|$)", re.IGNORECASE), "TODO"),
    (re.compile(r"#\s*FIXME[:\s]+(.+?)(?:\n|$)", re.IGNORECASE), "FIXME"),
    (re.compile(r"//\s*FIXME[:\s]+(.+?)(?:\n|$)", re.IGNORECASE), "FIXME"),
]


def _extract_result_string(tool_result) -> str:
    """Extract string from tool_result (can be dict, list, str, or None)."""
    if isinstance(tool_result, dict):
        return (
            tool_result.get("output", "")
            or tool_result.get("content", "")
            or str(tool_result)
        )
    elif isinstance(tool_result, str):
        return tool_result
    else:
        return str(tool_result) if tool_result else ""


def extract_test_failures(output: str) -> list[dict]:
    """Extract test failure information from pytest/jest output."""
    failures = []
    for file, test in _RE_PYTEST_FAIL.findall(output):
        failures.append(
            {
                "test_name": test,
                "file": file,
                "description": f"Fix failing test: {test} in {file}",
                "priority": 80,
            }
        )
    for file, test in _RE_JEST_FAIL.findall(output):
        failures.append(
            {
                "test_name": test,
                "file": file,
                "description": f"Fix failing test: {test} in {file}",
                "priority": 80,
            }
        )
    for msg in _RE_GENERIC_FAIL.findall(output)[:3]:
        if msg not in [f.get("description", "") for f in failures]:
            failures.append(
                {
                    "test_name": "unknown",
                    "file": "unknown",
                    "description": f"Fix: {msg[:80]}",
                    "priority": 70,
                }
            )
    return failures[:5]


def _trigger_self_heal(state: SessionState, target: str, error: str) -> None:
    """Trigger self-heal mode for framework errors.

    Called when a tool fails on a .claude/ path. Sets state to require
    self-healing before continuing other work.
    """
    # Record the framework error
    if not hasattr(state, "framework_errors"):
        state.framework_errors = []
    state.framework_errors.append(
        {"path": target, "error": error[:200], "turn": state.turn_count}
    )
    # Keep only last 10
    state.framework_errors = state.framework_errors[-10:]
    state.framework_error_turn = state.turn_count

    # Only trigger self-heal if not already in progress
    if not getattr(state, "self_heal_required", False):
        state.self_heal_required = True
        state.self_heal_target = target
        state.self_heal_error = error[:200]
        state.self_heal_attempts = 0


def _clear_self_heal(state: SessionState) -> None:
    """Clear self-heal state after successful fix."""
    state.self_heal_required = False
    state.self_heal_target = ""
    state.self_heal_error = ""
    state.self_heal_attempts = 0


def _detect_error_in_result(
    result, keywords: tuple[str, ...] = ("error", "failed")
) -> str:
    """Detect errors in tool result.

    Args:
        result: Tool result dict with potential 'error' or 'output' fields,
                or a string (treated as output)
        keywords: Error keywords to search for in output (lowercase)

    Returns:
        Error string (truncated to 200 chars) or empty string if no error
    """
    # Handle string results (Claude sometimes returns plain strings)
    if isinstance(result, str):
        result_lower = result.lower()[:150]
        if any(kw in result_lower for kw in keywords):
            return result[:200]
        return ""

    if not isinstance(result, dict):
        return ""

    # Check explicit error field first
    error = result.get("error", "") or ""
    if error:
        return error[:200]

    # Check output for error keywords
    output = result.get("output", "")
    if isinstance(output, str):
        output_lower = output.lower()[:150]
        if any(kw in output_lower for kw in keywords):
            return output[:200]

    return ""


def extract_todos_from_content(content: str, filepath: str) -> list[dict]:
    """Extract TODO/FIXME items from code content."""
    todos = []
    filename = Path(filepath).name if filepath else "unknown"
    for pattern, todo_type in _TODO_PATTERNS:
        for match in pattern.findall(content)[:3]:
            todos.append(
                {
                    "description": f"{todo_type}: {match.strip()[:60]} ({filename})",
                    "file": filepath,
                    "priority": 60 if todo_type == "FIXME" else 50,
                }
            )
    return todos[:5]


def detect_stubs_in_content(content: str) -> list[str]:
    """Detect stub patterns in code content."""
    STUB_PATTERNS = [
        ("TODO", "TODO"),
        ("FIXME", "FIXME"),
        ("NotImplementedError", "NotImplementedError"),
        ("raise NotImplementedError", "NotImplementedError"),
        ("pass  #", "stub pass"),
        ("...  #", "ellipsis stub"),
    ]
    found = []
    for pattern, label in STUB_PATTERNS:
        if pattern in content:
            found.append(label)
    return list(set(found))[:3]


# NOTE: Cache hooks (exploration_cacher, read_cacher, read_cache_invalidator)
# moved to _hooks_cache.py


def _handle_read_tool(tool_input: dict, result: dict, state: SessionState) -> None:
    """Handle Read tool state updates."""
    # Guard against non-dict results
    if not isinstance(result, dict):
        result = {}
    filepath = tool_input.get("file_path", "")
    read_error = _detect_error_in_result(
        result, keywords=("no such file", "permission denied", "not found")
    )
    if read_error and filepath and ".claude/" in filepath:
        _trigger_self_heal(state, target=filepath, error=read_error)

    if filepath:
        track_file_read(state, filepath)
        add_domain_signal(state, filepath)
        clear_pending_file(state, filepath)
        content = result.get("output", "")
        if filepath.endswith((".py", ".js", ".ts")):
            for lib in extract_libraries_from_code(content):
                track_library_used(state, lib)
        if filepath.endswith((".py", ".js", ".ts", ".tsx", ".rs", ".go", ".java")):
            for todo in extract_todos_from_content(content, filepath):
                add_work_item(
                    state,
                    item_type="todo",
                    source=filepath,
                    description=todo.get("description", "TODO"),
                    priority=todo.get("priority", 50),
                )


def _handle_edit_tool(tool_input: dict, result: dict, state: SessionState) -> None:
    """Handle Edit tool state updates."""
    filepath = tool_input.get("file_path", "")
    edit_error = _detect_error_in_result(result)
    if edit_error and filepath and ".claude/" in filepath:
        _trigger_self_heal(state, target=filepath, error=edit_error)

    if filepath:
        old_code = tool_input.get("old_string", "")
        new_code = tool_input.get("new_string", "")
        track_file_edit(state, filepath, old_code, new_code)
        track_feature_file(state, filepath)
        if new_code:
            for lib in extract_libraries_from_code(new_code):
                track_library_used(state, lib)
            if filepath.endswith((".py", ".js", ".ts", ".tsx", ".rs", ".go")):
                old_func_lines = extract_function_def_lines(old_code)
                new_func_lines = extract_function_def_lines(new_code)
                for func_name, old_def in old_func_lines.items():
                    new_def = new_func_lines.get(func_name)
                    if new_def is not None and old_def != new_def:
                        add_pending_integration_grep(state, func_name, filepath)
        if (
            not edit_error
            and getattr(state, "self_heal_required", False)
            and ".claude/" in filepath
        ):
            _clear_self_heal(state)


def _handle_write_tool(
    tool_input: dict, result: dict, state: SessionState
) -> str | None:
    """Handle Write tool state updates. Returns warning message if any."""
    filepath = tool_input.get("file_path", "")
    warning = None
    write_error = _detect_error_in_result(result)
    if write_error and filepath and ".claude/" in filepath:
        _trigger_self_heal(state, target=filepath, error=write_error)

    if filepath:
        is_new_file = filepath not in state.files_read
        if is_new_file:
            track_file_create(state, filepath)
        else:
            track_file_edit(state, filepath)
        track_feature_file(state, filepath)
        content = tool_input.get("content", "")
        if content:
            for lib in extract_libraries_from_code(content):
                track_library_used(state, lib)
            if is_new_file:
                stubs = detect_stubs_in_content(content)
                if stubs:
                    fname = Path(filepath).name
                    warning = (
                        f" STUB DETECTED in new file `{fname}`: "
                        f"{', '.join(stubs)}\n   Remember to complete before session ends!"
                    )
        if (
            not write_error
            and getattr(state, "self_heal_required", False)
            and ".claude/" in filepath
        ):
            _clear_self_heal(state)
    return warning


def _track_bash_ops_usage(command: str, success: bool, state: SessionState) -> None:
    """Track ops tool usage and audit/void verification."""
    if ".claude/ops/" not in command:
        return
    ops_match = re.search(r"\.claude/ops/(\w+)\.py", command)
    if not ops_match:
        return
    tool_name_ops = ops_match.group(1)
    track_ops_tool(state, tool_name_ops, success)

    # Track audit/void verification for production files
    if success and tool_name_ops in ("audit", "void"):
        parts = command.split()
        for i, part in enumerate(parts):
            if part.endswith(f"{tool_name_ops}.py") and i + 1 < len(parts):
                target_file = parts[i + 1]
                if not target_file.startswith("-"):
                    mark_production_verified(state, target_file, tool_name_ops)
                break


def _track_bash_git_commit(command: str, output: str, state: SessionState) -> None:
    """Handle git commit checkpoints and feature completion."""
    if not re.search(r"\bgit\s+commit\b", command, re.IGNORECASE):
        return
    commit_hash = ""
    hash_match = re.search(r"\[[\w-]+\s+([a-f0-9]{7,})\]", output)
    if hash_match:
        commit_hash = hash_match.group(1)
    msg_match = re.search(r'-m\s+["\']([^"\']+)["\']', command)
    notes = msg_match.group(1)[:50] if msg_match else "commit"
    create_checkpoint(state, commit_hash=commit_hash, notes=notes)

    completion_keywords = [
        "fix",
        "complete",
        "done",
        "finish",
        "implement",
        "resolve",
        "close",
    ]
    if state.current_feature and any(kw in notes.lower() for kw in completion_keywords):
        complete_feature(state, status="completed")


_ERROR_PATTERNS = [
    (re.compile(r"(\d{3})\s*(Unauthorized|Forbidden|Not Found)", re.I), "HTTP error"),
    (re.compile(r"(ModuleNotFoundError|ImportError)", re.I), "Import error"),
    (re.compile(r"(SyntaxError|TypeError|ValueError)", re.I), "Python error"),
    (re.compile(r"(ENOENT|EACCES|EPERM)", re.I), "Filesystem error"),
    (re.compile(r"(connection refused|timeout)", re.I), "Network error"),
]


def _classify_error(output: str) -> str:
    """Classify error type from command output."""
    for pattern, error_type in _ERROR_PATTERNS:
        if pattern.search(output):
            return error_type
    return "Command error"


def _is_framework_command(command: str) -> bool:
    """Check if command operates on .claude/ framework files."""
    return ".claude/" in command or ".claude\\" in command


def _track_bash_failures(
    command: str, output: str, success: bool, state: SessionState
) -> None:
    """Track failures, errors, and self-heal triggers."""
    approach_sig = (
        f"Bash:{command.split()[0][:20]}" if command.split() else "Bash:unknown"
    )

    if not success:
        error_type = _classify_error(output)
        track_error(state, error_type, output[:500])
        track_failure(state, approach_sig)
        if _is_framework_command(command):
            _trigger_self_heal(
                state,
                target=command.split()[0] if command.split() else "bash",
                error=output[:200],
            )

    if (
        success
        and getattr(state, "self_heal_required", False)
        and _is_framework_command(command)
    ):
        _clear_self_heal(state)

    if success and state.errors_unresolved:
        reset_failures(state)
        for error in state.errors_unresolved[:]:
            if any(
                word in command.lower()
                for word in error.get("type", "").lower().split()
            ):
                resolve_error(state, error.get("type", ""))


def _track_bash_test_failures(command: str, output: str, state: SessionState) -> None:
    """Discover and track test failures from test runner output."""
    test_commands = ["pytest", "npm test", "jest", "cargo test"]
    if not any(tc in command for tc in test_commands):
        return
    for failure in extract_test_failures(output):
        add_work_item(
            state,
            item_type="test_failure",
            source=failure.get("file", "tests"),
            description=failure.get("description", "Fix test failure"),
            priority=failure.get("priority", 80),
        )


def _handle_bash_tool(tool_input: dict, result: dict, state: SessionState) -> None:
    """Handle Bash tool state updates. Delegates to specialized trackers."""
    command = tool_input.get("command", "")
    # Guard against non-dict results (e.g., list from some tool responses)
    if not isinstance(result, dict):
        result = {}
    output = result.get("output", "")
    exit_code = result.get("exit_code", 0)
    success = exit_code == 0
    track_command(state, command, success, output)

    # Delegate to specialized trackers
    _track_bash_ops_usage(command, success, state)

    # Track files read via cat/head/tail
    if success:
        read_cmds = ["cat ", "head ", "tail ", "less ", "more "]
        if any(command.startswith(cmd) or f" {cmd}" in command for cmd in read_cmds):
            for part in command.split()[1:]:
                if not part.startswith("-") and ("/" in part or "." in part):
                    track_file_read(state, part)

    if success:
        _track_bash_git_commit(command, output, state)

    _track_bash_failures(command, output, success, state)
    _track_bash_test_failures(command, output, state)

    # Clear pending items for bash grep/find
    if "grep " in command or command.startswith("grep") or "rg " in command:
        patterns = re.findall(r'grep[^\|]*?["\']([^"\']+)["\']', command)
        patterns += re.findall(r"grep\s+(?:-\w+\s+)*(\w+)", command)
        for pattern in patterns:
            if len(pattern) > 3:
                clear_integration_grep(state, pattern)
                clear_pending_search(state, pattern)


def _handle_search_tool(tool_name: str, tool_input: dict, state: SessionState) -> None:
    """Handle Grep/Glob search tools."""
    pattern = tool_input.get("pattern", "")
    add_domain_signal(state, pattern)
    if pattern:
        clear_pending_search(state, pattern)
        if tool_name == "Grep":
            clear_integration_grep(state, pattern)


def _normalize_result(result: any) -> dict:
    """Normalize tool result to dict."""
    if isinstance(result, str):
        return {"output": result}
    return result if isinstance(result, dict) else {}


@register_hook("state_updater", None, priority=10)
def check_state_updater(
    data: dict, state: SessionState, runner_state: dict
) -> HookResult:
    """Update session state based on tool usage."""
    tool_name = data.get("tool_name", "")
    tool_input = data.get("tool_input", {})
    result = _normalize_result(data.get("tool_result", {}))
    warning = None

    state.tool_counts[tool_name] = state.tool_counts.get(tool_name, 0) + 1
    track_batch_tool(state, tool_name, tools_in_message=1)

    if tool_name == "Read":
        _handle_read_tool(tool_input, result, state)
    elif tool_name == "Edit":
        _handle_edit_tool(tool_input, result, state)
    elif tool_name == "Write":
        warning = _handle_write_tool(tool_input, result, state)
    elif tool_name == "Bash":
        _handle_bash_tool(tool_input, result, state)
    elif tool_name in ("Grep", "Glob"):
        _handle_search_tool(tool_name, tool_input, state)
    elif tool_name == "Task":
        add_domain_signal(state, tool_input.get("prompt", "")[:200])

    state.last_tool_info = {
        "tool_name": tool_name,
        "turn": state.turn_count,
        "bash_cmd": tool_input.get("command", "")[:50] if tool_name == "Bash" else "",
    }

    return HookResult.with_context(warning) if warning else HookResult.none()


# -----------------------------------------------------------------------------
# CONFIDENCE REDUCER (priority 12) - Deterministic confidence reductions
# -----------------------------------------------------------------------------


def _get_penalty_multiplier(confidence: int) -> float:
    """Scale penalties based on confidence level.

    Higher confidence = harder to maintain (bigger penalties).
    Lower confidence = already struggling (reduced penalties).

    This prevents coasting at high confidence - mistakes cost more
    when you're confident, creating pressure to stay careful.
    """
    if confidence >= 95:
        return 2.0  # Double penalties at peak confidence
    elif confidence >= 85:
        return 1.5  # 50% extra penalty in trusted zone
    elif confidence >= 70:
        return 1.0  # Normal penalties in working zone
    elif confidence >= 50:
        return 0.75  # Reduced penalties when struggling
    else:
        return 0.5  # Half penalties when in crisis


def _get_boost_multiplier(confidence: int) -> float:
    """Scale boosts based on confidence level - INVERSE of penalty scaling.

    Lower confidence = BIGGER boosts (survival mode, desperate for trust).
    Higher confidence = SMALLER boosts (already trusted, hard to justify more).

    Creates a self-correcting system:
    - When struggling: every bit of research/consultation is precious
    - When comfortable: coasting won't increase trust
    """
    if confidence < 30:
        return 3.0  # Desperate mode - every insight is gold
    elif confidence < 50:
        return 2.0  # Struggling - info gathering is rewarded heavily
    elif confidence < 70:
        return 1.5  # Working hard - research still pays off
    elif confidence < 85:
        return 1.0  # Normal - standard boost values
    else:
        return 0.5  # Comfortable - can't easily boost higher


# Default context window for Claude models (used when model info unavailable)
_DEFAULT_CONTEXT_WINDOW = get_magic_number("default_context_window", 200000)


def _get_context_percentage(transcript_path: str) -> float:
    """Calculate context window usage percentage from transcript.

    Reads the most recent assistant message's usage data to determine
    how much of the context window has been consumed.

    Returns 0.0 if unable to determine (safe default).
    """
    if not transcript_path:
        return 0.0

    try:
        transcript = Path(transcript_path)
        if not transcript.exists():
            return 0.0

        with open(transcript, "r") as f:
            lines = f.readlines()

        # Find most recent assistant message with usage data
        for line in reversed(lines):
            try:
                data = json.loads(line.strip())
                msg = data.get("message", {})
                if msg.get("role") != "assistant":
                    continue
                # Skip synthetic messages
                model = str(msg.get("model", "")).lower()
                if "synthetic" in model:
                    continue

                usage = msg.get("usage")
                if usage:
                    used = (
                        usage.get("input_tokens", 0)
                        + usage.get("output_tokens", 0)
                        + usage.get("cache_read_input_tokens", 0)
                        + usage.get("cache_creation_input_tokens", 0)
                    )
                    if used > 0:
                        return (used / _DEFAULT_CONTEXT_WINDOW) * 100
            except (json.JSONDecodeError, KeyError):
                continue

        return 0.0
    except Exception:
        return 0.0


def _get_context_multiplier(context_pct: float) -> tuple[float, float]:
    """Scale adjustments based on context usage.

    Returns (penalty_mult, boost_mult) tuple:
    - penalty_mult: Multiplier for penalties (higher context = bigger penalties)
    - boost_mult: Multiplier for boosts (higher context = smaller boosts)

    At high context usage, mistakes are more costly because:
    - Less room to recover with fresh context
    - Accumulated complexity increases error probability
    - User may be frustrated with long unproductive sessions
    """
    if context_pct >= 80:
        # Critical context usage - maximum pressure
        return (2.0, 0.5)  # Double penalties, halve boosts
    elif context_pct >= 60:
        # High context usage - significant pressure
        return (1.5, 0.75)  # 50% more penalties, 25% less boosts
    elif context_pct >= 40:
        # Medium context usage - mild pressure
        return (1.25, 0.9)  # 25% more penalties, 10% less boosts
    else:
        # Low context usage - normal operation
        return (1.0, 1.0)  # No modification


def _track_researched_libraries(tool_name: str, tool_input: dict, state: SessionState):
    """Extract library names from research queries and mark as researched.

    This unlocks the research_gate for these libraries in pre_tool_use.
    """
    from session_state import RESEARCH_REQUIRED_LIBS, track_library_researched

    # Get the text to search for library mentions
    text = ""
    if tool_name == "WebSearch":
        text = tool_input.get("query", "")
    elif tool_name == "WebFetch":
        text = tool_input.get("url", "") + " " + tool_input.get("prompt", "")
    elif tool_name == "mcp__crawl4ai__crawl":
        text = tool_input.get("url", "")
    elif tool_name == "mcp__crawl4ai__search":
        text = tool_input.get("query", "")

    if not text:
        return

    text_lower = text.lower()

    # Check for each required library in the search/fetch
    for lib in RESEARCH_REQUIRED_LIBS:
        if lib.lower() in text_lower:
            track_library_researched(state, lib)


# Decay boost lookup tables
_PAL_HIGH_BOOST = frozenset(
    ("thinkdeep", "debug", "codereview", "consensus", "precommit")
)
_PAL_LOW_BOOST = frozenset(("chat", "challenge", "apilookup"))
_DECAY_BOOST_FIXED = {
    "AskUserQuestion": (2, "user-clarification"),
    "Task": (1.5, "agent-delegation"),
    "WebSearch": (0.5, "web-research"),
    "WebFetch": (0.5, "web-research"),
}


def _calculate_decay_boost(
    tool_name: str, tool_input: dict, state: SessionState
) -> tuple[float, str]:
    """Calculate recovery action boosts for confidence decay."""
    # PAL external consultation
    if tool_name.startswith("mcp__pal__"):
        pal_tool = tool_name.replace("mcp__pal__", "")
        if pal_tool in _PAL_HIGH_BOOST:
            return 2, f"pal-{pal_tool}"
        if pal_tool in _PAL_LOW_BOOST:
            return 1, f"pal-{pal_tool}"
        return 0, ""

    # Fixed boosts
    if tool_name in _DECAY_BOOST_FIXED:
        return _DECAY_BOOST_FIXED[tool_name]

    # Read - diminishing returns
    if tool_name == "Read":
        read_count = len([f for f in state.files_read if f])
        boost = 0.5 if read_count <= 3 else (0.25 if read_count <= 6 else 0.1)
        return boost, f"file-read({read_count})"

    # Memory access or web crawl
    if tool_name.startswith("mcp__"):
        if "mem" in tool_name.lower():
            return 0.5, "memory-access"
        if tool_name.startswith("mcp__crawl4ai__"):
            return 0.5, "web-crawl"

    return 0, ""


def _calculate_decay_penalty(
    tool_name: str, tool_input: dict, state: SessionState
) -> tuple[float, str]:
    """Calculate penalties for risky actions.

    Returns (penalty_value, penalty_reason).
    """
    if tool_name in ("Edit", "Write"):
        penalty = 0
        reason_parts = []
        file_path = tool_input.get("file_path", "")

        # Base edit penalty with cooldown (max 1 per 3 turns)
        edit_risk_key = "_edit_risk_last_turn"
        last_edit_risk = getattr(state, edit_risk_key, 0)
        if state.turn_count - last_edit_risk >= 3:
            penalty = 1
            reason_parts.append("edit-risk")
            setattr(state, edit_risk_key, state.turn_count)

        # Edit without reading first = extra penalty
        if file_path and file_path not in state.files_read:
            penalty += 2
            reason_parts = ["edit-without-read"]

        # Check for stubs in new code
        new_code = tool_input.get("new_string", "") or tool_input.get("content", "")
        if new_code:
            stub_patterns = [
                "pass  # TODO",
                "raise NotImplementedError",
                "# FIXME",
                "...  # stub",
            ]
            if any(p in new_code for p in stub_patterns):
                penalty += 1
                reason_parts.append("stub")

        return penalty, "+".join(reason_parts) if reason_parts else ""

    # Bash commands are risky - cooldown prevents constant drain
    if tool_name == "Bash":
        bash_risk_key = "_bash_risk_last_turn"
        last_bash_risk = getattr(state, bash_risk_key, 0)
        if state.turn_count - last_bash_risk >= 3:
            setattr(state, bash_risk_key, state.turn_count)
            return 1, "bash-risk"

    return 0, ""


@register_hook("confidence_decay", None, priority=11)
def check_confidence_decay(
    data: dict, state: SessionState, runner_state: dict
) -> HookResult:
    """Dynamic confidence system with survival mechanics.

    See _calculate_decay_boost() and _calculate_decay_penalty() for details.
    Shows  indicator when survival boost is active.
    """
    tool_name = data.get("tool_name", "")
    tool_input = data.get("tool_input", {})

    # Base decay per tool call (moderate: actions have cost but not punishing)
    base_decay = 0.4
    if state.confidence >= 85:
        base_decay += 0.3  # High confidence tax

    state._decay_accumulator += base_decay

    # Calculate boost and penalty via helpers
    boost, boost_reason = _calculate_decay_boost(tool_name, tool_input, state)
    penalty, penalty_reason = _calculate_decay_penalty(tool_name, tool_input, state)

    # Calculate net adjustment (decay + penalty - boosts)
    # Only apply when accumulator reaches whole number
    accumulated_decay = int(state._decay_accumulator)
    state._decay_accumulator -= accumulated_decay  # Keep fractional part

    # Get scaling multipliers
    # 1. Confidence-based penalty scaling (higher confidence = harsher penalties)
    conf_penalty_mult = _get_penalty_multiplier(state.confidence)
    # 2. Confidence-based boost scaling (lower confidence = BIGGER boosts - survival mode)
    conf_boost_mult = _get_boost_multiplier(state.confidence)

    # 3. Context-based: higher context usage = harsher penalties, smaller boosts
    transcript_path = data.get("transcript_path", "")
    context_pct = _get_context_percentage(transcript_path)
    ctx_penalty_mult, ctx_boost_mult = _get_context_multiplier(context_pct)

    # Combined penalty multiplier (confidence  context)
    combined_penalty_mult = conf_penalty_mult * ctx_penalty_mult

    # Combined boost multiplier (confidence survival  context)
    # Low confidence AMPLIFIES boosts; high context REDUCES them
    combined_boost_mult = conf_boost_mult * ctx_boost_mult

    # Apply scaled penalties
    scaled_penalty = int(penalty * combined_penalty_mult)
    scaled_decay = (
        int(accumulated_decay * combined_penalty_mult) if accumulated_decay else 0
    )

    # Apply scaled boosts (amplified when struggling, reduced at high context)
    scaled_boost = int(boost * combined_boost_mult) if boost else 0

    # Net change: boosts are positive, decay and penalty are negative
    delta = scaled_boost - scaled_decay - scaled_penalty

    if delta == 0:
        return HookResult.none()

    # Apply rate limiting to prevent death spirals
    delta = apply_rate_limit(delta, state)

    if delta == 0:
        return HookResult.none()

    old_confidence = state.confidence
    new_confidence = max(0, min(100, old_confidence + delta))

    if new_confidence != old_confidence:
        set_confidence(state, new_confidence, "confidence_decay")

        # Build reason string
        reasons = []
        if scaled_boost:
            # Show survival mode amplification
            if conf_boost_mult > 1.0:
                reasons.append(
                    f"+{scaled_boost} {boost_reason} x{conf_boost_mult:.1f}"
                )
            else:
                reasons.append(f"+{scaled_boost} {boost_reason}")
        if accumulated_decay:
            reasons.append(f"-{scaled_decay} decay")
        if penalty:
            reasons.append(f"-{scaled_penalty} {penalty_reason}")

        # Add context pressure indicator if significant
        if context_pct >= 40:
            reasons.append(f"CTX:{context_pct:.0f}%")

        direction = "" if delta > 0 else ""
        return HookResult.with_context(
            f"{direction} **Confidence**: {old_confidence}%  {new_confidence}% "
            f"({'+' if delta > 0 else ''}{delta}) [{', '.join(reasons)}]"
        )

    return HookResult.none()


def _build_reducer_context(
    tool_name: str, tool_input: dict, tool_result: dict, data: dict, state: SessionState
) -> dict:
    """Build base context for reducer evaluation."""
    # Build current_activity string for GoalDriftReducer
    activity_parts = [tool_name]
    if tool_name in ("Read", "Edit", "Write", "Glob", "Grep"):
        file_path = tool_input.get("file_path", "") or tool_input.get("path", "")
        if file_path:
            activity_parts.append(file_path)
        pattern = tool_input.get("pattern", "")
        if pattern:
            activity_parts.append(pattern)
    elif tool_name == "Bash":
        command = tool_input.get("command", "")
        if command:
            activity_parts.append(command[:200])

    result_str = _extract_result_string(tool_result)

    context = {
        "tool_name": tool_name,
        "tool_result": result_str,
        "current_activity": " ".join(activity_parts),
        "prompt": getattr(state, "last_user_prompt", ""),
        "assistant_output": data.get("assistant_output", ""),
    }

    # Add file_path for file-based reducers
    if tool_name in ("Edit", "Write", "Read"):
        file_path = tool_input.get("file_path", "")
        if file_path:
            context["file_path"] = file_path

    # Add content for code quality reducers
    if tool_name == "Edit":
        context["new_string"] = tool_input.get("new_string", "")
    elif tool_name == "Write":
        context["content"] = tool_input.get("content", "")

    return context


def _detect_tool_failures(
    tool_name: str, tool_input: dict, tool_result: dict, state: SessionState, ctx: dict
) -> None:
    """Detect tool failures and hook blocks."""
    # Bash exit code != 0
    if tool_name == "Bash" and isinstance(tool_result, dict):
        if tool_result.get("exit_code", 0) != 0:
            ctx["tool_failed"] = True

    # Edit/Write errors
    if tool_name in {"Edit", "Write", "MultiEdit"}:
        result_str = str(tool_result).lower() if tool_result else ""
        errors = [
            "file has not been read yet",
            "error:",
            "failed to",
            "permission denied",
            "no such file",
            "is not unique",
        ]
        if any(p in result_str for p in errors):
            ctx["tool_failed"] = True

    # Recent hook blocks
    if hasattr(state, "consecutive_blocks") and state.consecutive_blocks:
        for hook_name, entry in state.consecutive_blocks.items():
            if state.turn_count - entry.get("last_turn", 0) <= 2:
                ctx["hook_blocked"] = True
                break


def _detect_repetition_patterns(
    tool_name: str, tool_input: dict, state: SessionState, ctx: dict
) -> None:
    """Detect sequential repetition and git spam."""
    # Sequential repetition (same tool 3+ consecutive turns)
    last_info = getattr(state, "last_tool_info", {})
    if last_info:
        last_tool = last_info.get("tool_name", "")
        last_turn = last_info.get("turn", 0)
        consecutive = last_info.get("consecutive", 1)
        if last_tool == tool_name and last_turn < state.turn_count:
            is_similar = True
            if tool_name == "Bash":
                last_cmd = last_info.get("bash_cmd", "")
                curr_cmd = tool_input.get("command", "")[:50]
                is_similar = last_cmd[:20] == curr_cmd[:20]
            if is_similar:
                new_consecutive = consecutive + 1
                state.last_tool_info["consecutive"] = new_consecutive
                if new_consecutive >= 3:
                    ctx["sequential_repetition_3plus"] = True
        else:
            if hasattr(state, "last_tool_info"):
                state.last_tool_info["consecutive"] = 1

    # Git spam (>3 git commands in 5 turns without writes)
    git_cmds = ["git log", "git diff", "git status", "git show", "git blame"]
    if tool_name == "Bash" and any(
        g in tool_input.get("command", "") for g in git_cmds
    ):
        git_turns = getattr(state, "git_explore_turns", [])
        git_turns.append(state.turn_count)
        git_turns = [t for t in git_turns if state.turn_count - t <= 5]
        state.git_explore_turns = git_turns
        if len(git_turns) > 3 and not state.files_edited[-5:]:
            ctx["git_spam"] = True


def _was_file_edited_after(
    file_path: str, last_read_turn: int, files_edited: list
) -> bool:
    """Check if file was edited after a given turn."""
    for entry in files_edited:
        if isinstance(entry, dict):
            if entry.get("path") == file_path and entry.get("turn", 0) > last_read_turn:
                return True
        elif isinstance(entry, str) and entry == file_path:
            return True
    return False


def _detect_time_wasters(
    tool_name: str, tool_input: dict, tool_result: dict, state: SessionState, ctx: dict
) -> None:
    """Detect time waster patterns (v4.2)."""
    # Re-read unchanged file
    if tool_name == "Read":
        file_path = tool_input.get("file_path", "")
        files_read = getattr(state, "files_read", {})
        # Guard: files_read must be dict, not list
        if not isinstance(files_read, dict):
            files_read = {}
        if file_path and file_path in files_read:
            last_read_turn = files_read.get(file_path, {}).get("turn", 0)
            if not _was_file_edited_after(
                file_path, last_read_turn, getattr(state, "files_edited", [])
            ):
                ctx["reread_unchanged"] = True

    # Huge output dump
    if len(str(tool_result) if tool_result else "") > 5000:
        ctx["huge_output_dump"] = True


def _detect_incomplete_refactor(
    tool_name: str, tool_input: dict, tool_result: dict, state: SessionState, ctx: dict
) -> None:
    """Detect incomplete refactors (v4.4)."""
    file_path = tool_input.get("file_path", "")

    # Step 1: On Edit, track potential renames
    if tool_name == "Edit":
        old_str = tool_input.get("old_string", "")
        new_str = tool_input.get("new_string", "")
        replace_all = tool_input.get("replace_all", False)

        if old_str and new_str and not replace_all:
            old_ids = set(re.findall(r"\b([A-Za-z_][A-Za-z0-9_]{2,})\b", old_str))
            new_ids = set(re.findall(r"\b([A-Za-z_][A-Za-z0-9_]{2,})\b", new_str))
            removed_ids = old_ids - new_ids
            if removed_ids:
                pending = getattr(state, "pending_rename_check", [])
                for rid in removed_ids:
                    if len(rid) >= 4:
                        pending.append(
                            {"name": rid, "turn": state.turn_count, "file": file_path}
                        )
                state.pending_rename_check = [
                    p for p in pending if state.turn_count - p["turn"] <= 3
                ][-5:]

    # Step 2: On Grep, check if pending renames found elsewhere
    if tool_name == "Grep":
        pattern = tool_input.get("pattern", "")
        result_str = str(tool_result)[:2000].lower()
        pending = getattr(state, "pending_rename_check", [])

        for p in pending:
            if p["name"].lower() in pattern.lower():
                if "no matches" not in result_str and "0 results" not in result_str:
                    ctx["incomplete_refactor"] = True
                    break


@register_hook("confidence_reducer", None, priority=12)
def check_confidence_reducer(
    data: dict, state: SessionState, runner_state: dict
) -> HookResult:
    """Apply deterministic confidence reductions based on failure signals.

    Delegates to helper functions for each detection category.
    """
    tool_name = data.get("tool_name", "")
    tool_input = data.get("tool_input", {})
    tool_result = data.get("tool_result", {})
    # Guard against non-dict results
    if not isinstance(tool_result, dict):
        tool_result = {}

    # Build context and detect patterns
    context = _build_reducer_context(tool_name, tool_input, tool_result, data, state)
    _detect_tool_failures(tool_name, tool_input, tool_result, state, context)
    _detect_repetition_patterns(tool_name, tool_input, state, context)
    _detect_time_wasters(tool_name, tool_input, tool_result, state, context)
    _detect_incomplete_refactor(tool_name, tool_input, tool_result, state, context)

    # Apply reducers
    triggered = apply_reducers(state, context)

    if not triggered:
        return HookResult.none()

    # Calculate total reduction and apply with rate limiting
    old_confidence = state.confidence
    total_delta = sum(delta for _, delta, _ in triggered)
    total_delta = apply_rate_limit(total_delta, state)  # Prevent death spirals
    new_confidence = max(0, min(100, old_confidence + total_delta))

    # Update state
    set_confidence(state, new_confidence, "reducer triggered")

    # Format feedback
    reasons = [f"{name}: {delta}" for name, delta, _ in triggered]
    change_msg = format_confidence_change(
        old_confidence, new_confidence, ", ".join(reasons)
    )

    # Add tier info for context
    _, emoji, desc = get_tier_info(new_confidence)

    # Include dispute instructions
    reducer_names = [name for name, _, _ in triggered]
    dispute_hint = format_dispute_instructions(reducer_names)

    # v4.6: Add trajectory warning if heading toward a gate
    trajectory = predict_trajectory(
        state, planned_edits=1, planned_bash=1, turns_ahead=3
    )
    trajectory_warning = (
        format_trajectory_warning(trajectory) if trajectory["will_gate"] else ""
    )
    if trajectory_warning:
        trajectory_warning = f"\n\n{trajectory_warning}"

    return HookResult.with_context(
        f" **Confidence Reduced**\n{change_msg}\n\n"
        f"Current: {emoji} {new_confidence}% - {desc}"
        f"{dispute_hint}{trajectory_warning}"
    )


# -----------------------------------------------------------------------------
# CONFIDENCE INCREASER (priority 14) - Success signal confidence increases
# -----------------------------------------------------------------------------


_RESEARCH_TOOLS = frozenset(
    {"WebSearch", "WebFetch", "mcp__crawl4ai__crawl", "mcp__crawl4ai__search"}
)
_SEARCH_TOOLS = frozenset({"Grep", "Glob", "Task"})
_DELEGATION_AGENTS = frozenset({"Explore", "scout", "Plan"})


def _build_natural_signals(
    tool_name: str, tool_input: dict, data: dict, state: SessionState, context: dict
) -> None:
    """Build context for natural increaser signals (file reads, research, etc.)."""
    file_path = tool_input.get("file_path", "")

    if tool_name == "Read":
        context["files_read_count"] = 1
        if "/.claude/memory" in file_path or "/memory/" in file_path:
            context["memory_consulted"] = True
        if tool_input.get("offset") or tool_input.get("limit"):
            context["targeted_read"] = True
    elif tool_name in _RESEARCH_TOOLS:
        context["research_performed"] = True
        _track_researched_libraries(tool_name, tool_input, state)
    elif tool_name in _SEARCH_TOOLS:
        context["search_performed"] = True
        if (
            tool_name == "Task"
            and tool_input.get("subagent_type", "") in _DELEGATION_AGENTS
        ):
            context["subagent_delegation"] = True
    elif tool_name == "AskUserQuestion":
        context["asked_user"] = True
    elif tool_name in {"Edit", "Write"} and (
        "CLAUDE.md" in file_path
        or "/rules/" in file_path
        or "/.claude/rules" in file_path
    ):
        context["rules_updated"] = True


_GIT_EXPLORE_CMDS = ("git log", "git diff", "git status", "git show", "git blame")
_PRODUCTIVE_BASH = tuple(
    re.compile(p)
    for p in [
        r"^ls\b",
        r"^pwd$",
        r"^which\b",
        r"^type\b",
        r"^file\b",
        r"^wc\b",
        r"^du\b",
        r"^df\b",
        r"^env\b",
        r"^tree\b",
        r"^stat\b",
    ]
)


def _build_bash_signals(tool_input: dict, data: dict, context: dict) -> None:
    """Build context for bash command signals."""
    command = tool_input.get("command", "")
    context["bash_command"] = command
    cmd_stripped = command.strip()

    if "/.claude/ops/" in command or "/ops/" in command:
        context["custom_script_ran"] = True
    if re.match(r"^bd\s+(create|update)\b", cmd_stripped):
        context["bead_created"] = True
    if any(g in command for g in _GIT_EXPLORE_CMDS):
        context["git_explored"] = True
    if re.match(r"^git\s+(commit|add\s+.*&&\s*git\s+commit)", cmd_stripped) and (
        "-m" in command or "--message" in command
    ):
        context["git_committed"] = True
    if any(p.match(cmd_stripped) for p in _PRODUCTIVE_BASH):
        context["productive_bash"] = True

    # Diff size detection
    tool_response = data.get("tool_response", {})
    if isinstance(tool_response, dict):
        stdout = tool_response.get("stdout", "")
        diff_match = re.search(
            r"(\d+)\s+files?\s+changed.*?(\d+)\s+insertion.*?(\d+)\s+deletion",
            stdout,
            re.IGNORECASE,
        )
        if diff_match:
            total_loc = int(diff_match.group(2)) + int(diff_match.group(3))
            if total_loc < 400:
                context["small_diff"] = True
            elif total_loc > 400:
                context["large_diff"] = True


def _build_objective_signals(
    tool_name: str, tool_input: dict, data: dict, context: dict
) -> None:
    """Build context for objective signals (tests, builds, lints)."""
    if tool_name != "Bash":
        return

    tool_response = data.get("tool_response", {})
    if isinstance(tool_response, dict):
        stdout = tool_response.get("stdout", "").lower()
        stderr = tool_response.get("stderr", "")
        success = not tool_response.get("interrupted", False) and not stderr
    else:
        stdout = str(tool_response).lower() if tool_response else ""
        success = True

    if success and stdout:
        if any(p in stdout for p in ["passed", "tests passed", "ok", "success", ""]):
            context["tests_passed"] = True
        if any(p in stdout for p in ["built", "compiled", "build successful"]):
            context["build_succeeded"] = True
        command = tool_input.get("command", "").lower()
        if any(t in command for t in ["ruff check", "eslint", "clippy", "pylint"]):
            if "error" not in stdout and "warning" not in stdout:
                context["lint_passed"] = True


def _check_chained_commands(command: str) -> bool:
    """Check if command chains multiple meaningful operations."""
    if " && " not in command and not _RE_CHAIN_SEMICOLON.search(command):
        return False
    parts = _RE_CHAIN_SPLIT.split(command)
    meaningful = [p for p in parts if len(p.strip()) > 5]
    return len(meaningful) >= 2


def _check_efficient_search(
    pattern: str, tool_result: dict, state: SessionState
) -> bool:
    """Check if search was efficient (new pattern with results)."""
    if not pattern:
        return False
    recent = getattr(state, "recent_searches", [])
    if pattern in recent:
        return False
    if not hasattr(state, "recent_searches"):
        state.recent_searches = []
    state.recent_searches.append(pattern)
    state.recent_searches = state.recent_searches[-20:]
    result_str = str(tool_result)[:500].lower()
    return "no matches" not in result_str and "0 results" not in result_str


def _build_time_saver_signals(
    tool_name: str,
    tool_input: dict,
    tool_result: dict,
    runner_state: dict,
    state: SessionState,
    context: dict,
) -> None:
    """Build context for time saver signals (v4.2)."""
    if tool_name == "Bash" and _check_chained_commands(tool_input.get("command", "")):
        context["chained_commands"] = True

    if tool_name == "Edit":
        old_s, new_s = (
            tool_input.get("old_string", ""),
            tool_input.get("new_string", ""),
        )
        if old_s and new_s and (old_s.count("\n") >= 3 or new_s.count("\n") >= 3):
            context["batch_fix"] = True

    if runner_state.get("tools_this_turn", 1) >= 2:
        context["parallel_tools"] = True

    if tool_name in {"Grep", "Glob"}:
        if _check_efficient_search(tool_input.get("pattern", ""), tool_result, state):
            context["efficient_search"] = True


_TEST_FILE_PATTERNS = ("test_", "_test.", ".test.", "/tests/", "spec.")
_TEST_COMMANDS = ("pytest", "jest", "npm test", "cargo test", "go test")


def _is_test_file(file_path: str) -> bool:
    """Check if file path indicates a test file."""
    lower = file_path.lower()
    return any(p in lower for p in _TEST_FILE_PATTERNS)


def _track_test_coverage(file_path: str, state: SessionState, context: dict) -> None:
    """Track test file edits and detect test_ignored condition."""
    if _is_test_file(file_path):
        state._test_file_edited_turn = state.turn_count
    else:
        last_edit = getattr(state, "_test_file_edited_turn", 0)
        last_run = getattr(state, "_tests_run_turn", 0)
        if last_edit > last_run and (state.turn_count - last_edit) <= 5:
            context["test_ignored"] = True


def _build_completion_signals(
    tool_name: str, tool_input: dict, state: SessionState, context: dict
) -> None:
    """Build context for completion quality signals (v4.4/v4.5)."""
    if tool_name == "Bash":
        command = tool_input.get("command", "").lower()
        if "bd close" in command and getattr(state, "consecutive_failures", 0) == 0:
            context["first_attempt_success"] = True
        if any(t in command for t in _TEST_COMMANDS):
            state._tests_run_turn = state.turn_count

    if tool_name in {"Edit", "Write"}:
        file_path = tool_input.get("file_path", "")
        if file_path:
            goal_kw = getattr(state, "goal_keywords", [])
            if goal_kw and any(kw.lower() in file_path.lower() for kw in goal_kw):
                context["scoped_change"] = True
            _track_test_coverage(file_path, state, context)


@register_hook("confidence_increaser", None, priority=14)
def check_confidence_increaser(
    data: dict, state: SessionState, runner_state: dict
) -> HookResult:
    """Apply confidence increases based on success signals.

    Delegates to helper functions for each signal category to reduce complexity.
    """
    tool_name = data.get("tool_name", "")
    tool_result = data.get("tool_result", {})
    tool_input = data.get("tool_input", {})

    result_str = _extract_result_string(tool_result)

    # Build context for increasers
    context = {
        "tool_name": tool_name,
        "tool_result": result_str,
        "assistant_output": data.get("assistant_output", ""),
    }

    # Build signals from each category
    _build_natural_signals(tool_name, tool_input, data, state, context)

    if tool_name == "Bash":
        _build_bash_signals(tool_input, data, context)

    _build_objective_signals(tool_name, tool_input, data, context)
    _build_time_saver_signals(
        tool_name, tool_input, tool_result, runner_state, state, context
    )
    _build_completion_signals(tool_name, tool_input, state, context)

    # Apply increasers
    triggered = apply_increasers(state, context)

    if not triggered:
        return HookResult.none()

    # Separate auto-approved from approval-required
    auto_increases = [(n, d, desc) for n, d, desc, req in triggered if not req]
    approval_required = [(n, d, desc) for n, d, desc, req in triggered if req]

    messages = []
    old_confidence = state.confidence

    # Apply auto-increases with rate limiting
    if auto_increases:
        total_auto = sum(d for _, d, _ in auto_increases)
        total_auto = apply_rate_limit(total_auto, state)  # Cap per-turn gains
        new_confidence = min(100, old_confidence + total_auto)
        set_confidence(state, new_confidence, "increaser triggered")

        reasons = [f"{name}: +{delta}" for name, delta, _ in auto_increases]
        change_msg = format_confidence_change(
            old_confidence, new_confidence, ", ".join(reasons)
        )

        _, emoji, desc = get_tier_info(new_confidence)

        # v4.6: Show streak if active
        streak = get_current_streak(state)
        streak_info = f" |  Streak: {streak}" if streak >= 2 else ""

        messages.append(
            f" **Confidence Increased**\n{change_msg}\n\n"
            f"Current: {emoji} {new_confidence}% - {desc}{streak_info}"
        )

    # Note approval-required increases (don't apply yet)
    if approval_required:
        for name, delta, desc in approval_required:
            messages.append(
                f" **Confidence Boost Available** (+{delta})\n"
                f"Reason: {desc}\n"
                f"Reply **CONFIDENCE_BOOST_APPROVED** to apply."
            )

    if messages:
        return HookResult.with_context("\n\n".join(messages))

    return HookResult.none()


# -----------------------------------------------------------------------------
# THINKING QUALITY BOOST (priority 16) - Reward good reasoning practices
# -----------------------------------------------------------------------------
# REWARD-ONLY: No penalties. Confidence earned through evidence, not lost through language.
# Penalties on hedging/alternatives were removed - they punished healthy epistemic practices.

_THINKING_CONFIDENCE_PATTERNS = [
    # Clarity & certainty
    (re.compile(r"\b(definitely|clearly|certainly)\b", re.I), 1, "clarity"),
    (re.compile(r"\b(verified|confirmed|tested|checked)\b", re.I), 1, "verified"),
    (re.compile(r"\b(the (issue|problem|root cause|bug) is)\b", re.I), 1, "diagnosis"),
    # Good methodology
    (re.compile(r"\b(let me (read|check|verify) first)\b", re.I), 1, "methodical"),
    (
        re.compile(r"\b(based on (the code|the docs|evidence))\b", re.I),
        1,
        "evidence-based",
    ),
    (re.compile(r"\b(I found|I see|I notice)\b", re.I), 1, "observation"),
]


@register_hook("thinking_quality_boost", None, priority=16)
def check_thinking_quality_boost(
    data: dict, state: SessionState, runner_state: dict
) -> HookResult:
    """Reward good reasoning practices detected in thinking blocks.

    REWARD-ONLY design philosophy:
    - Confidence should be EARNED through good practices, not LOST through language
    - Penalties on hedging/alternatives punished healthy epistemic practices
    - Natural decay + other reducers already provide downward pressure

    Rewards: +1 per pattern matched, max +3 per tool call
    """
    from synapse_core import extract_thinking_blocks

    transcript_path = data.get("transcript_path", "")
    if not transcript_path:
        return HookResult.none()

    thinking_blocks = extract_thinking_blocks(transcript_path)
    if not thinking_blocks:
        return HookResult.none()

    # Analyze most recent thinking (last 2 blocks, last 1500 chars)
    recent_thinking = " ".join(thinking_blocks[-2:])[-1500:]
    if not recent_thinking:
        return HookResult.none()

    # REWARD-ONLY: Check positive patterns, no penalties
    adjustment = 0
    triggered = []

    for pattern, delta, label in _THINKING_CONFIDENCE_PATTERNS:
        if pattern.search(recent_thinking):
            adjustment += delta
            triggered.append(label)

    # Cap at +3 to prevent gaming
    adjustment = min(3, adjustment)

    if adjustment == 0:
        return HookResult.none()

    # Apply to confidence
    old_confidence = state.confidence
    new_confidence = min(100, old_confidence + adjustment)

    if new_confidence != old_confidence:
        set_confidence(state, new_confidence, "thinking_quality_boost")
        return HookResult.with_context(
            f" **Quality**: +{adjustment} [{', '.join(triggered[:3])}]"
        )

    return HookResult.none()
</file>

<file path="_hooks_tracking.py">
"""
Tracking-related PostToolUse hooks.

Monitors patterns, detects repetitive work, tracks learning opportunities.
Priority range: 55-72
"""

import _lib_path  # noqa: F401
import re
import time
import shutil
import subprocess
from pathlib import Path
from collections import Counter

from _hook_registry import register_hook
from _hook_result import HookResult
from _config import get_magic_number
from _cooldown import beads_sync_cooldown
from session_state import SessionState, get_adaptive_threshold, record_threshold_trigger


# =============================================================================
# SCRATCH ENFORCER (priority 55)
# =============================================================================

SCRATCH_STATE_FILE = (
    Path(__file__).parent.parent / "memory" / "scratch_enforcer_state.json"
)
REPETITION_WINDOW = get_magic_number("repetition_window_seconds", 300)

REPETITIVE_PATTERNS = {
    "multi_file_edit": {
        "tools": ["Edit", "Write"],
        "threshold": 4,
        "suggestion": "Consider writing a .claude/tmp/ script to batch these edits",
    },
    "multi_file_read": {
        "tools": ["Read"],
        "threshold": 5,
        "suggestion": "Use Glob/Grep or write a .claude/tmp/ analysis script",
    },
    "multi_bash": {
        "tools": ["Bash"],
        "threshold": 4,
        "suggestion": "Chain commands with && or write a .claude/tmp/ script",
    },
    "multi_grep": {
        "tools": ["Grep"],
        "threshold": 4,
        "suggestion": "Write a .claude/tmp/ script for complex multi-pattern search",
    },
}


@register_hook("scratch_enforcer", None, priority=55)
def check_scratch_enforcer(
    data: dict, state: SessionState, runner_state: dict
) -> HookResult:
    """Detect repetitive manual work, suggest scripts."""
    tool_name = data.get("tool_name", "")
    if not tool_name:
        return HookResult.none()

    scratch_state = runner_state.get("scratch_state", {})
    scratch_state.setdefault("tool_counts", {})
    scratch_state.setdefault("last_reset", time.time())
    scratch_state.setdefault("suggestions_given", [])

    if time.time() - scratch_state.get("last_reset", 0) > REPETITION_WINDOW:
        scratch_state = {
            "tool_counts": {},
            "last_reset": time.time(),
            "suggestions_given": [],
        }

    scratch_state["tool_counts"][tool_name] = (
        scratch_state["tool_counts"].get(tool_name, 0) + 1
    )

    suggestion = None
    for pattern_name, config in REPETITIVE_PATTERNS.items():
        if pattern_name in scratch_state.get("suggestions_given", []):
            continue
        total = sum(scratch_state["tool_counts"].get(t, 0) for t in config["tools"])
        if total >= config["threshold"]:
            scratch_state["suggestions_given"].append(pattern_name)
            suggestion = config["suggestion"]
            break

    runner_state["scratch_state"] = scratch_state

    if suggestion:
        return HookResult.with_context(
            f" REPETITIVE PATTERN DETECTED:\n"
            f"   {suggestion}\n"
            f"   (.claude/tmp/ scripts are faster than manual iteration)"
        )

    return HookResult.none()


# =============================================================================
# AUTO LEARN (priority 60)
# =============================================================================

MEMORY_DIR = Path(__file__).parent.parent / "memory"

LEARNABLE_PATTERNS = [
    (r"ModuleNotFoundError: No module named '([^']+)'", "Missing module: {0}"),
    (r"ImportError: cannot import name '([^']+)'", "Import error: {0}"),
    (r"AttributeError: '(\w+)' object has no attribute '(\w+)'", "{0}.{1} missing"),
    (r"TypeError: ([^(]+)\(\) got an unexpected keyword argument '(\w+)'", "{0} rejects '{1}'"),
    (r"FileNotFoundError: \[Errno 2\].*'([^']+)'", "File not found: {0}"),
    (r" GAP: (.+)", "Gap detected: {0}"),
    (r"BLOCKED: (.+)", "Blocked: {0}"),
    (r"command not found: (\w+)", "Command not found: {0}"),
    (r"Permission denied", "Permission denied"),
    (r"fatal: (.+)", "Git error: {0}"),
]

IGNORE_PATTERNS = [
    r"^\s*$",
    r"warning:",
    r"^\d+ passed",
    r"ModuleNotFoundError.*No module named 'test_'",
]


def _learn_from_bash_error(tool_output: str) -> str | None:
    """Extract lesson from bash error output."""
    if not tool_output or not any(k in tool_output.lower() for k in ("error", "failed")):
        return None
    if any(re.search(p, tool_output, re.IGNORECASE) for p in IGNORE_PATTERNS):
        return None
    for pattern, template in LEARNABLE_PATTERNS:
        if match := re.search(pattern, tool_output):
            try:
                return template.format(*match.groups())[:60]
            except (IndexError, KeyError):
                pass
    return None


def _get_quality_hint(tool_name: str, tool_input: dict, runner_state: dict) -> str | None:
    """Get quality hint for tool usage."""
    hints_shown = runner_state.setdefault("hints_shown", [])
    if tool_name in ("Write", "Edit") and tool_input.get("file_path", "").endswith(".py"):
        if "py_ruff" not in hints_shown:
            hints_shown.append("py_ruff")
            return " Run `ruff check --fix && ruff format` after editing Python"
    elif tool_name == "Bash":
        cmd = tool_input.get("command", "")
        if re.search(r"\bgrep\s+-r", cmd) and "rg " not in cmd and "use_rg" not in hints_shown:
            hints_shown.append("use_rg")
            return " Use `rg` (ripgrep) instead of `grep -r` for 10-100x speed"
    return None


@register_hook("auto_learn", None, priority=60)
def check_auto_learn(data: dict, state: SessionState, runner_state: dict) -> HookResult:
    """Capture lessons from errors and provide quality hints."""
    messages = []

    if data.get("tool_name") == "Bash":
        if lesson := _learn_from_bash_error(data.get("tool_output", "")):
            messages.append(f" Auto-learned: {lesson}...")

    if hint := _get_quality_hint(data.get("tool_name", ""), data.get("tool_input", {}), runner_state):
        messages.append(hint)

    return HookResult.with_context("\n".join(messages[:2])) if messages else HookResult.none()


# =============================================================================
# VELOCITY TRACKER (priority 65)
# =============================================================================


def _check_self_check_pattern(tool_name: str, tool_input: dict, state: SessionState) -> str | None:
    """Detect Edit-then-Read self-distrust pattern."""
    if tool_name != "Read" or len(state.last_5_tools) < 2:
        return None
    current_file = tool_input.get("file_path", "")
    if not current_file or state.last_5_tools[-1] not in ("Edit", "Write"):
        return None
    recent_edits = state.files_edited[-3:] if state.files_edited else []
    if current_file in recent_edits:
        name = current_file.split("/")[-1] if "/" in current_file else current_file
        return (
            f" SELF-CHECK: Edited then re-read `{name}`.\n"
            f" Trust your edit or verify with a test, not re-reading."
        )
    return None


def _check_oscillation_pattern(last_5: list, state: SessionState) -> str | None:
    """Detect ReadEditReadEdit oscillation."""
    pattern = "".join(
        "R" if t == "Read" else "E" for t in last_5 if t in ("Read", "Edit", "Write")
    )
    if "RERE" in pattern or "ERER" in pattern:
        record_threshold_trigger(state, "velocity_oscillation", 1)
        return (
            " OSCILLATION: ReadEditReadEdit pattern.\n"
            " Step back: progress or checking repeatedly?"
        )
    return None


def _check_search_loop(last_5: list, state: SessionState) -> str | None:
    """Detect low diversity search loops."""
    threshold = get_adaptive_threshold(state, "iteration_same_tool")
    if threshold == float("inf") or len(last_5) != 5:
        return None
    unique = len(set(last_5))
    if unique <= 2 and all(t in ("Read", "Glob", "Grep") for t in last_5):
        record_threshold_trigger(state, "iteration_same_tool", 5 - unique)
        return " SEARCH LOOP: 5+ searches without action.\n Enough info to act?"
    return None


def _check_reread_pattern(state: SessionState) -> str | None:
    """Detect excessive re-reading of same file."""
    threshold = get_adaptive_threshold(state, "batch_sequential_reads")
    if threshold == float("inf"):
        return None
    recent = state.files_read[-10:] if len(state.files_read) >= 10 else state.files_read
    counts = Counter(recent)
    repeated = [(f, c) for f, c in counts.items() if c >= int(threshold)]
    if repeated:
        file, count = repeated[0]
        name = file.split("/")[-1] if "/" in file else file
        record_threshold_trigger(state, "batch_sequential_reads", count)
        return f" RE-READ: `{name}` read {count}x.\n What are you looking for?"
    return None


@register_hook("velocity_tracker", "Read|Edit|Write|Bash|Glob|Grep", priority=65)
def check_velocity(data: dict, state: SessionState, runner_state: dict) -> HookResult:
    """Detect spinning vs actual progress with adaptive thresholds."""
    tool_name = data.get("tool_name", "")
    tool_input = data.get("tool_input", {})
    last_5 = state.last_5_tools

    if len(last_5) < 3:
        return HookResult.none()
    if get_adaptive_threshold(state, "velocity_oscillation") == float("inf"):
        return HookResult.none()

    if msg := _check_self_check_pattern(tool_name, tool_input, state):
        return HookResult.with_context(msg)

    if len(last_5) < 4:
        return HookResult.none()

    if msg := _check_oscillation_pattern(last_5, state):
        return HookResult.with_context(msg)
    if msg := _check_search_loop(last_5, state):
        return HookResult.with_context(msg)
    if msg := _check_reread_pattern(state):
        return HookResult.with_context(msg)

    return HookResult.none()


# =============================================================================
# INFO GAIN TRACKER (priority 70)
# =============================================================================

INFO_GAIN_STATE_FILE = MEMORY_DIR / "info_gain_state.json"
READS_BEFORE_WARN = get_magic_number("reads_before_warn", 5)
READS_BEFORE_CRYSTALLIZE = get_magic_number("reads_before_crystallize", 8)

READ_TOOLS = {"Read", "Grep", "Glob"}
PROGRESS_TOOLS = {"Edit", "Write"}
PROGRESS_BASH_PATTERNS = [
    "pytest", "npm test", "npm run", "cargo test", "cargo build",
    "python3 .claude/ops/verify", "python3 .claude/ops/audit",
    "git commit", "git add", "pip install", "npm install",
]


@register_hook("info_gain_tracker", None, priority=70)
def check_info_gain(data: dict, state: SessionState, runner_state: dict) -> HookResult:
    """Detect reads without progress."""
    tool_name = data.get("tool_name", "")
    tool_input = data.get("tool_input", {})

    ig_state = runner_state.get("info_gain_state", {})
    ig_state.setdefault("reads_since_progress", 0)
    ig_state.setdefault("files_read_this_burst", [])
    ig_state.setdefault("last_stall_warn", 0)

    if tool_name in READ_TOOLS:
        ig_state["reads_since_progress"] = ig_state.get("reads_since_progress", 0) + 1
        filepath = tool_input.get("file_path", "") or tool_input.get("pattern", "")
        if filepath:
            ig_state.setdefault("files_read_this_burst", []).append(filepath)
            ig_state["files_read_this_burst"] = ig_state["files_read_this_burst"][-10:]

        reads = ig_state["reads_since_progress"]
        time_since_warn = time.time() - ig_state.get("last_stall_warn", 0)

        if reads >= READS_BEFORE_WARN and time_since_warn > 60:
            ig_state["last_stall_warn"] = time.time()
            files = ig_state.get("files_read_this_burst", [])[-5:]
            file_names = [Path(f).name if f else "?" for f in files]
            file_list = ", ".join(file_names) if file_names else "multiple files"
            runner_state["info_gain_state"] = ig_state

            severity = "" if reads < READS_BEFORE_CRYSTALLIZE else ""
            hint = "  crystallize to .claude/tmp/" if reads >= READS_BEFORE_CRYSTALLIZE else ""
            return HookResult.with_context(
                f"{severity} INFO GAIN: {reads} reads ({file_list}) - act or need more?{hint}"
            )

    elif tool_name in PROGRESS_TOOLS:
        ig_state["reads_since_progress"] = 0
        ig_state["files_read_this_burst"] = []

    elif tool_name == "Bash":
        command = tool_input.get("command", "")
        if any(p in command.lower() for p in PROGRESS_BASH_PATTERNS):
            ig_state["reads_since_progress"] = 0
            ig_state["files_read_this_burst"] = []

    runner_state["info_gain_state"] = ig_state
    return HookResult.none()


# =============================================================================
# BEADS AUTO-SYNC (priority 72)
# =============================================================================


@register_hook("beads_auto_sync", "Bash", priority=72)
def check_beads_auto_sync(
    data: dict, state: SessionState, runner_state: dict
) -> HookResult:
    """Automatically sync beads after git commit/push operations."""
    tool_input = data.get("tool_input", {})
    tool_result = data.get("tool_result", {})
    command = tool_input.get("command", "")

    if not re.search(r"\bgit\s+(commit|push)\b", command, re.IGNORECASE):
        return HookResult.none()

    success = True
    if isinstance(tool_result, dict):
        stderr = tool_result.get("stderr", "")
        exit_code = tool_result.get("exit_code", 0)
        success = exit_code == 0 and "error" not in stderr.lower()

    if not success:
        return HookResult.none()

    if beads_sync_cooldown.is_active():
        return HookResult.none()

    bd_path = shutil.which("bd")
    if not bd_path:
        return HookResult.none()

    beads_dir = Path.cwd() / ".beads"
    if not beads_dir.exists():
        beads_dir = Path.home() / ".claude" / ".beads"
        if not beads_dir.exists():
            return HookResult.none()

    try:
        subprocess.Popen(
            [bd_path, "sync"],
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL,
            start_new_session=True,
        )
        beads_sync_cooldown.reset()
        return HookResult.with_context(" Beads auto-synced in background")
    except (OSError, IOError):
        return HookResult.none()
</file>

<file path="_intent_classifier.py">
#!/usr/bin/env python3
"""
Lazy-loaded HuggingFace Intent Classifier for user prompts.

Uses zero-shot classification to categorize user requests into intents.
Model loads on first use (~3s), subsequent calls ~30-50ms.

Intents:
  - code_review: Review code, find issues, audit
  - debug: Fix bugs, investigate errors, troubleshoot
  - implement: Build new features, add functionality
  - refactor: Restructure, clean up, improve code
  - explain: Understand code, documentation, how things work
  - research: Search, find information, explore options
  - configure: Setup, install, environment changes
  - test: Write tests, run tests, verify behavior
"""

from __future__ import annotations

import os
import time
from typing import Optional

# Lazy-loaded model
_CLASSIFIER = None
_CLASSIFIER_LOAD_TIME: float = 0.0
_CLASSIFIER_LOADING = False  # True while background load in progress
_MODEL_NAME = "facebook/bart-large-mnli"  # Good balance of speed/accuracy

# Intent labels
INTENT_LABELS = [
    "code_review",
    "debug",
    "implement",
    "refactor",
    "explain",
    "research",
    "configure",
    "test",
]

# Intent to context mapping - what each intent should trigger
INTENT_CONTEXT = {
    "code_review": {
        "hooks": ["audit", "void"],
        "message": " CODE REVIEW MODE: Consider /audit and /void for systematic analysis",
    },
    "debug": {
        "hooks": ["thinkdeep", "debug"],
        "message": " DEBUG MODE: Use systematic hypothesis testing. Consider PAL debug tool.",
    },
    "implement": {
        "hooks": ["bead_check"],
        "message": " IMPLEMENT MODE: Track with beads. Check for existing solutions first.",
    },
    "refactor": {
        "hooks": ["drift", "audit"],
        "message": " REFACTOR MODE: Verify no behavior changes. Run tests after.",
    },
    "explain": {
        "hooks": [],
        "message": None,  # No special context needed
    },
    "research": {
        "hooks": ["websearch", "memory"],
        "message": " RESEARCH MODE: Check memory first, then web. Cite sources.",
    },
    "configure": {
        "hooks": ["inventory", "sysinfo"],
        "message": " CONFIG MODE: Verify environment with /inventory and /sysinfo",
    },
    "test": {
        "hooks": [],
        "message": " TEST MODE: Prefer pytest. Run existing tests before writing new ones.",
    },
}


def _load_classifier():
    """Load the classifier model. Called once per session."""
    global _CLASSIFIER, _CLASSIFIER_LOAD_TIME

    if _CLASSIFIER is not None:
        return _CLASSIFIER

    start = time.time()
    try:
        from transformers import pipeline

        # Use CPU, disable progress bars for cleaner output
        os.environ.setdefault("TRANSFORMERS_VERBOSITY", "error")

        _CLASSIFIER = pipeline(
            "zero-shot-classification",
            model=_MODEL_NAME,
            device=-1,  # CPU
        )
        _CLASSIFIER_LOAD_TIME = time.time() - start
        return _CLASSIFIER
    except ImportError:
        # transformers not installed
        return None
    except Exception:
        # Model load failed
        return None


def is_ready() -> bool:
    """Check if the classifier is loaded and ready (non-blocking)."""
    return _CLASSIFIER is not None


def classify_intent(prompt: str, threshold: float = 0.3) -> Optional[dict]:
    """
    Classify user prompt into an intent category (non-blocking).

    If model isn't loaded yet, starts background loading and returns None.
    Subsequent calls will work once model is ready.

    Args:
        prompt: User's prompt text
        threshold: Minimum confidence score (0-1) to return an intent

    Returns:
        Dict with 'intent', 'confidence', 'context' or None if not ready/below threshold
    """
    global _CLASSIFIER_LOADING

    # Skip very short prompts
    if len(prompt.strip()) < 10:
        return None

    # Non-blocking: if model not loaded, start background load and return
    if _CLASSIFIER is None:
        if not _CLASSIFIER_LOADING:
            prewarm()  # Start background loading
        return None  # Not ready yet, skip this prompt

    classifier = _CLASSIFIER

    try:
        # Truncate very long prompts for efficiency
        text = prompt[:1000] if len(prompt) > 1000 else prompt

        result = classifier(text, INTENT_LABELS, multi_label=False)

        top_intent = result["labels"][0]
        top_score = result["scores"][0]

        if top_score < threshold:
            return None

        context = INTENT_CONTEXT.get(top_intent, {})

        return {
            "intent": top_intent,
            "confidence": top_score,
            "message": context.get("message"),
            "hooks": context.get("hooks", []),
        }
    except Exception:
        return None


def get_model_status() -> dict:
    """Get status of the intent classifier model."""
    return {
        "loaded": _CLASSIFIER is not None,
        "model": _MODEL_NAME,
        "load_time_seconds": _CLASSIFIER_LOAD_TIME,
    }


def prewarm():
    """Pre-load the model in a background thread (non-blocking)."""
    global _CLASSIFIER_LOADING
    import threading

    if _CLASSIFIER is not None or _CLASSIFIER_LOADING:
        return  # Already loaded or loading

    _CLASSIFIER_LOADING = True

    def _load_and_mark():
        global _CLASSIFIER_LOADING
        try:
            _load_classifier()
        finally:
            _CLASSIFIER_LOADING = False

    thread = threading.Thread(target=_load_and_mark, daemon=True)
    thread.start()
</file>

<file path="_lib_path.py">
#!/usr/bin/env python3
"""Path setup for importing from .claude/lib/. Import this first in hooks.

This module is imported for side effects only (modifies sys.path).
No main guard needed - it's a library module, not a script.
"""
import sys
from pathlib import Path

_lib_dir = str(Path(__file__).parent.parent / "lib")
if _lib_dir not in sys.path:
    sys.path.insert(0, _lib_dir)
</file>

<file path="_logging.py">
"""
Unified logging framework for hook runners.

Features:
- Environment-controlled log levels via CLAUDE_HOOK_LOG_LEVEL
- Consistent error logging with context
- Optional file logging to .claude/tmp/hooks.log
- Per-hook timing instrumentation
"""

import os
import sys
import time
from pathlib import Path
from typing import Optional
from contextlib import contextmanager

# =============================================================================
# CONFIGURATION
# =============================================================================

LOG_LEVELS = {"DEBUG": 10, "INFO": 20, "WARN": 30, "ERROR": 40, "NONE": 100}

LOG_LEVEL = LOG_LEVELS.get(os.environ.get("CLAUDE_HOOK_LOG_LEVEL", "WARN").upper(), 30)

LOG_FILE = Path.home() / ".claude" / "tmp" / "hooks.log"
FILE_LOGGING = os.environ.get("CLAUDE_HOOK_FILE_LOG", "").lower() == "true"

# Profiling enabled via environment
PROFILING = os.environ.get("CLAUDE_HOOK_PROFILE", "").lower() == "true"


# =============================================================================
# LOGGING FUNCTIONS
# =============================================================================


def _should_log(level: str) -> bool:
    """Check if message should be logged at given level."""
    return LOG_LEVELS.get(level.upper(), 30) >= LOG_LEVEL


def _format_message(hook_name: str, level: str, message: str) -> str:
    """Format log message consistently."""
    timestamp = time.strftime("%H:%M:%S")
    return f"[{timestamp}] [{level}] [{hook_name}] {message}"


def _write_log(message: str) -> None:
    """Write log message to stderr and optionally to file."""
    print(message, file=sys.stderr)

    if FILE_LOGGING:
        try:
            LOG_FILE.parent.mkdir(parents=True, exist_ok=True)
            with open(LOG_FILE, "a") as f:
                f.write(message + "\n")
        except OSError:
            pass


def log_debug(hook_name: str, message: str) -> None:
    """Log debug message."""
    if _should_log("DEBUG"):
        _write_log(_format_message(hook_name, "DEBUG", message))


def log_info(hook_name: str, message: str) -> None:
    """Log info message."""
    if _should_log("INFO"):
        _write_log(_format_message(hook_name, "INFO", message))


def log_warn(hook_name: str, message: str) -> None:
    """Log warning message."""
    if _should_log("WARN"):
        _write_log(_format_message(hook_name, "WARN", message))


def log_error(hook_name: str, message: str, error: Optional[Exception] = None) -> None:
    """Log error message with optional exception details."""
    if _should_log("ERROR"):
        if error:
            message = f"{message}: {type(error).__name__}: {error}"
        _write_log(_format_message(hook_name, "ERROR", message))


# =============================================================================
# PROFILING
# =============================================================================


class HookTimer:
    """Track execution time for hooks."""

    def __init__(self):
        self.timings: dict[str, list[float]] = {}

    def record(self, hook_name: str, duration_ms: float) -> None:
        """Record timing for a hook."""
        if hook_name not in self.timings:
            self.timings[hook_name] = []
        self.timings[hook_name].append(duration_ms)

    def get_stats(self, hook_name: str) -> dict:
        """Get timing stats for a hook."""
        times = self.timings.get(hook_name, [])
        if not times:
            return {"count": 0, "avg_ms": 0, "max_ms": 0, "total_ms": 0}
        return {
            "count": len(times),
            "avg_ms": sum(times) / len(times),
            "max_ms": max(times),
            "total_ms": sum(times),
        }

    def get_all_stats(self) -> dict[str, dict]:
        """Get timing stats for all hooks."""
        return {name: self.get_stats(name) for name in self.timings}

    def report(self) -> str:
        """Generate timing report."""
        if not self.timings:
            return "No timing data collected"

        lines = ["Hook Timing Report:", "-" * 50]
        stats = self.get_all_stats()

        # Sort by total time descending
        sorted_hooks = sorted(stats.items(), key=lambda x: -x[1]["total_ms"])

        for hook_name, s in sorted_hooks:
            lines.append(
                f"  {hook_name}: {s['count']} calls, "
                f"avg={s['avg_ms']:.1f}ms, max={s['max_ms']:.1f}ms, "
                f"total={s['total_ms']:.1f}ms"
            )

        return "\n".join(lines)


# Global timer instance
hook_timer = HookTimer()


@contextmanager
def timed_hook(hook_name: str):
    """Context manager to time hook execution."""
    if not PROFILING:
        yield
        return

    start = time.perf_counter()
    try:
        yield
    finally:
        duration_ms = (time.perf_counter() - start) * 1000
        hook_timer.record(hook_name, duration_ms)
        log_debug(hook_name, f"Completed in {duration_ms:.1f}ms")


def time_hook(func):
    """Decorator to time hook functions."""

    def wrapper(*args, **kwargs):
        if not PROFILING:
            return func(*args, **kwargs)

        hook_name = func.__name__
        start = time.perf_counter()
        try:
            return func(*args, **kwargs)
        finally:
            duration_ms = (time.perf_counter() - start) * 1000
            hook_timer.record(hook_name, duration_ms)

    return wrapper
</file>

<file path="_pal_mandates.py">
#!/usr/bin/env python3
"""
PAL Mandate Formula Book

Defines conditions that trigger MANDATORY PAL tool usage.
Aggressive by design - mandates fire automatically, not suggestions.

Usage:
    from _pal_mandates import get_mandate
    mandate = get_mandate(confidence, intent, state_flags)
    if mandate:
        inject mandate.directive into context
"""

from __future__ import annotations

from dataclasses import dataclass
from typing import Optional


@dataclass
class Mandate:
    """A mandatory PAL tool invocation."""

    tool: str  # MCP tool name
    directive: str  # Injected text
    priority: int  # Higher = more urgent (1-100)
    reason: str  # Why this mandate fired


# =============================================================================
# FORMULA BOOK: Condition  Mandate mappings
# =============================================================================

# Priority levels
P_CRITICAL = 100  # Must do immediately
P_HIGH = 80  # Should do before proceeding
P_MEDIUM = 60  # Recommended before major actions
P_LOW = 40  # Suggested but optional


def _critical_mandates(confidence: int, cascade_failure: bool, sunk_cost: bool) -> list[Mandate]:
    """Tier 1: Critical mandates (confidence < 30 OR cascade conditions)."""
    mandates = []
    if confidence < 30:
        mandates.append(Mandate(
            tool="mcp__pal__thinkdeep",
            directive=f" **MANDATORY**: Confidence is critically low ({confidence}%). "
                     "You MUST use `mcp__pal__thinkdeep` to analyze the situation "
                     "before ANY action. Do NOT proceed without external consultation.",
            priority=P_CRITICAL,
            reason=f"Critical confidence: {confidence}%",
        ))
    if cascade_failure:
        mandates.append(Mandate(
            tool="mcp__pal__thinkdeep",
            directive=" **MANDATORY**: Cascade failure detected - same block 3+ times. "
                     "You MUST use `mcp__pal__thinkdeep` to break the deadlock. "
                     "Current approach is failing repeatedly.",
            priority=P_CRITICAL,
            reason="Cascade failure deadlock",
        ))
    if sunk_cost:
        mandates.append(Mandate(
            tool="mcp__pal__thinkdeep",
            directive=" **MANDATORY**: Sunk cost detected - 3+ failures on same approach. "
                     "You MUST use `mcp__pal__thinkdeep` to reconsider strategy. "
                     "Stop trying the same thing.",
            priority=P_CRITICAL,
            reason="Sunk cost fallacy",
        ))
    return mandates


def _high_mandates(
    confidence: int, edit_oscillation: bool, goal_drift: bool, consecutive_failures: int
) -> list[Mandate]:
    """Tier 2: High priority mandates (confidence 30-50 OR problematic patterns)."""
    mandates = []
    if 30 <= confidence < 50:
        mandates.append(Mandate(
            tool="mcp__pal__thinkdeep",
            directive=f" **REQUIRED**: Confidence is low ({confidence}%). "
                     "Use `mcp__pal__thinkdeep` before making changes. "
                     "Research and validate your approach first.",
            priority=P_HIGH,
            reason=f"Low confidence: {confidence}%",
        ))
    if edit_oscillation:
        mandates.append(Mandate(
            tool="mcp__pal__codereview",
            directive=" **REQUIRED**: Edit oscillation detected - thrashing on same file. "
                     "Use `mcp__pal__codereview` to get fresh perspective. "
                     "Stop editing until you understand the problem.",
            priority=P_HIGH,
            reason="Edit oscillation",
        ))
    if goal_drift:
        mandates.append(Mandate(
            tool="mcp__pal__planner",
            directive=" **REQUIRED**: Goal drift detected - straying from original task. "
                     "Use `mcp__pal__planner` to realign with the goal. "
                     "Refocus before continuing.",
            priority=P_HIGH,
            reason="Goal drift",
        ))
    if consecutive_failures >= 3:
        mandates.append(Mandate(
            tool="mcp__pal__debug",
            directive=f" **REQUIRED**: {consecutive_failures} consecutive failures detected. "
                     "Use `mcp__pal__debug` to analyze what's going wrong. "
                     "Stop and diagnose before retrying.",
            priority=P_HIGH,
            reason=f"{consecutive_failures} consecutive failures",
        ))
    return mandates


def _medium_mandates(intent: Optional[str], confidence: int) -> list[Mandate]:
    """Tier 3: Medium priority mandates (intent-based at moderate confidence)."""
    mandates = []
    if intent == "debug" and confidence < 70:
        mandates.append(Mandate(
            tool="mcp__pal__debug",
            directive=f" **RECOMMENDED**: Debug intent detected with confidence {confidence}%. "
                     "Use `mcp__pal__debug` for systematic root cause analysis. "
                     "External perspective helps debugging.",
            priority=P_MEDIUM,
            reason=f"Debug intent at {confidence}%",
        ))
    if intent == "code_review" and confidence < 80:
        mandates.append(Mandate(
            tool="mcp__pal__codereview",
            directive=" **RECOMMENDED**: Code review intent detected. "
                     "Use `mcp__pal__codereview` for comprehensive analysis. "
                     "External review catches blind spots.",
            priority=P_MEDIUM,
            reason="Code review intent",
        ))
    if intent == "refactor" and confidence < 75:
        mandates.append(Mandate(
            tool="mcp__pal__codereview",
            directive=f" **RECOMMENDED**: Refactor intent at {confidence}% confidence. "
                     "Use `mcp__pal__codereview` before restructuring. "
                     "Validate approach before major changes.",
            priority=P_MEDIUM,
            reason=f"Refactor at {confidence}%",
        ))
    return mandates


def get_mandate(
    confidence: int,
    intent: Optional[str] = None,
    cascade_failure: bool = False,
    edit_oscillation: bool = False,
    sunk_cost: bool = False,
    goal_drift: bool = False,
    consecutive_failures: int = 0,
) -> Optional[Mandate]:
    """Evaluate conditions and return the highest-priority mandate."""
    mandates = []
    mandates.extend(_critical_mandates(confidence, cascade_failure, sunk_cost))
    mandates.extend(_high_mandates(confidence, edit_oscillation, goal_drift, consecutive_failures))
    mandates.extend(_medium_mandates(intent, confidence))

    return max(mandates, key=lambda m: m.priority) if mandates else None


# =============================================================================
# KEYWORD TRIGGERS (for architectural/complex decisions)
# =============================================================================

ARCHITECTURE_KEYWORDS = {
    "architecture",
    "redesign",
    "migrate",
    "migration",
    "refactor entire",
    "rewrite",
    "new approach",
    "different strategy",
    "fundamental change",
    "breaking change",
}

DECISION_KEYWORDS = {
    "should i",
    "should we",
    "which approach",
    "better option",
    "trade-off",
    "tradeoff",
    "pros and cons",
    "compare",
    "versus",
    " vs ",
    "alternative",
}


def check_keyword_mandate(prompt: str, confidence: int) -> Optional[Mandate]:
    """
    Check for keyword-triggered mandates in user prompt.

    Args:
        prompt: User's prompt text
        confidence: Current confidence

    Returns:
        Mandate if keywords detected, None otherwise
    """
    prompt_lower = prompt.lower()

    # Architecture keywords  planner/consensus
    if any(kw in prompt_lower for kw in ARCHITECTURE_KEYWORDS):
        return Mandate(
            tool="mcp__pal__consensus",
            directive=(
                " **RECOMMENDED**: Architecture/migration keywords detected. "
                "Use `mcp__pal__consensus` for multi-perspective analysis. "
                "Major changes need external validation."
            ),
            priority=P_MEDIUM if confidence >= 70 else P_HIGH,
            reason="Architecture keywords",
        )

    # Decision keywords  consensus
    if any(kw in prompt_lower for kw in DECISION_KEYWORDS):
        return Mandate(
            tool="mcp__pal__consensus",
            directive=(
                " **RECOMMENDED**: Decision-making keywords detected. "
                "Consider `mcp__pal__consensus` for balanced analysis. "
                "Multiple perspectives improve decisions."
            ),
            priority=P_LOW if confidence >= 80 else P_MEDIUM,
            reason="Decision keywords",
        )

    return None


# =============================================================================
# SUMMARY: Mandate Thresholds
# =============================================================================
#
# | Condition              | Tool           | Priority | Confidence Range |
# |------------------------|----------------|----------|------------------|
# | confidence < 30        | thinkdeep      | CRITICAL | 0-29             |
# | cascade_failure        | thinkdeep      | CRITICAL | any              |
# | sunk_cost              | thinkdeep      | CRITICAL | any              |
# | confidence 30-50       | thinkdeep      | HIGH     | 30-49            |
# | edit_oscillation       | codereview     | HIGH     | any              |
# | goal_drift             | planner        | HIGH     | any              |
# | failures >= 3          | debug          | HIGH     | any              |
# | intent=debug + <70     | debug          | MEDIUM   | <70              |
# | intent=code_review     | codereview     | MEDIUM   | <80              |
# | intent=refactor + <75  | codereview     | MEDIUM   | <75              |
# | architecture keywords  | consensus      | MEDIUM   | <70, else LOW    |
# | decision keywords      | consensus      | LOW-MED  | varies           |
#
</file>

<file path="_patterns.py">
"""
Centralized pattern definitions for hook runners.

Consolidates duplicate patterns used across multiple hooks.
All patterns are pre-compiled at module load for performance.
"""

import re

# =============================================================================
# STUB/INCOMPLETE CODE PATTERNS
# =============================================================================

STUB_PATTERNS = [
    re.compile(r"#\s*TODO\b", re.IGNORECASE),
    re.compile(r"#\s*FIXME\b", re.IGNORECASE),
    re.compile(r"raise\s+NotImplementedError"),
    re.compile(r"pass\s*#"),
    re.compile(r"\.\.\.\s*#"),
    re.compile(r"#\s*stub\b", re.IGNORECASE),
    re.compile(r"#\s*placeholder\b", re.IGNORECASE),
]

STUB_STRINGS = ["# TODO", "# FIXME", "raise NotImplementedError", "pass  #"]

# Byte patterns for binary file scanning (used by stop hooks)
STUB_BYTE_PATTERNS = [
    b"# TODO",
    b"# FIXME",
    b"TODO",
    b"FIXME",
    b"NotImplementedError",
    b"raise NotImplementedError",
    b"pass  #",
    b"...  #",
    b"...",  # Python ellipsis stub
    b"stub",
    b"STUB",
]


def has_stub_pattern(content: str) -> bool:
    """Check if content contains stub/incomplete code patterns."""
    return any(p.search(content) for p in STUB_PATTERNS)


def find_stub_patterns(content: str) -> list[str]:
    """Find all stub patterns in content, return list of matched patterns."""
    found = []
    for pattern in STUB_PATTERNS:
        if pattern.search(content):
            found.append(pattern.pattern)
    return found


# =============================================================================
# FILE EXTENSION PATTERNS
# =============================================================================

CODE_EXTENSIONS = frozenset(
    {
        ".py",
        ".ts",
        ".tsx",
        ".js",
        ".jsx",
        ".rs",
        ".go",
        ".java",
        ".kt",
        ".c",
        ".cpp",
        ".h",
        ".hpp",
        ".cs",
        ".rb",
        ".php",
        ".swift",
        ".scala",
    }
)

CONFIG_EXTENSIONS = frozenset(
    {
        ".json",
        ".yaml",
        ".yml",
        ".toml",
        ".ini",
        ".cfg",
        ".conf",
        ".env",
    }
)

DOC_EXTENSIONS = frozenset({".md", ".txt", ".rst", ".adoc"})

SKIP_EXTENSIONS = frozenset(
    {
        ".md",
        ".txt",
        ".json",
        ".yaml",
        ".yml",
        ".sh",
        ".env",
    }
)

WEB_EXTENSIONS = frozenset({".html", ".css", ".scss", ".less", ".sass"})


def is_code_file(path: str) -> bool:
    """Check if path is a code file."""
    from pathlib import Path

    return Path(path).suffix.lower() in CODE_EXTENSIONS


def is_config_file(path: str) -> bool:
    """Check if path is a config file."""
    from pathlib import Path

    return Path(path).suffix.lower() in CONFIG_EXTENSIONS


def should_skip_file(path: str) -> bool:
    """Check if file should be skipped for certain checks."""
    from pathlib import Path

    return Path(path).suffix.lower() in SKIP_EXTENSIONS


# =============================================================================
# SECURITY PATTERNS
# =============================================================================

SECURITY_FILE_PATTERNS = [
    re.compile(r"auth", re.IGNORECASE),
    re.compile(r"login", re.IGNORECASE),
    re.compile(r"password", re.IGNORECASE),
    re.compile(r"credential", re.IGNORECASE),
    re.compile(r"token", re.IGNORECASE),
    re.compile(r"secret", re.IGNORECASE),
    re.compile(r"jwt", re.IGNORECASE),
    re.compile(r"oauth", re.IGNORECASE),
]

SECURITY_CONTENT_PATTERNS = [
    re.compile(r"password\s*=", re.IGNORECASE),
    re.compile(r"secret\s*=", re.IGNORECASE),
    re.compile(r"\.encrypt\(", re.IGNORECASE),
    re.compile(r"\.decrypt\(", re.IGNORECASE),
    re.compile(r"api[_-]?key\s*=", re.IGNORECASE),
]


def is_security_sensitive_file(path: str) -> bool:
    """Check if file path suggests security-sensitive content."""
    path_lower = path.lower()
    return any(p.search(path_lower) for p in SECURITY_FILE_PATTERNS)


def has_security_content(content: str) -> bool:
    """Check if content contains security-sensitive patterns."""
    return any(p.search(content) for p in SECURITY_CONTENT_PATTERNS)


# =============================================================================
# SCRATCH/TEMP PATH PATTERNS
# =============================================================================

SCRATCH_PATHS = [".claude/tmp/", ".claude/memory/", "/tmp/", ".cache/"]

PROTECTED_PATHS = [".claude/ops/", ".claude/lib/"]


def is_scratch_path(path: str) -> bool:
    """Check if path is in scratch/temp locations."""
    return any(p in path for p in SCRATCH_PATHS)


def is_protected_path(path: str) -> bool:
    """Check if path is in protected locations."""
    return any(p in path for p in PROTECTED_PATHS)


# =============================================================================
# DEFERRAL PATTERNS (anti-patterns for "TODO later")
# =============================================================================

DEFERRAL_PATTERNS = [
    (
        re.compile(r"#\s*(TODO|FIXME):\s*(implement\s+)?later", re.IGNORECASE),
        "TODO later",
    ),
    (re.compile(r"#\s*low\s+priority", re.IGNORECASE), "low priority"),
    (re.compile(r"#\s*nice\s+to\s+have", re.IGNORECASE), "nice to have"),
    (re.compile(r"#\s*could\s+(do|add)\s+later", re.IGNORECASE), "could do later"),
    (re.compile(r"#\s*worth\s+investigating", re.IGNORECASE), "worth investigating"),
    (re.compile(r"#\s*consider\s+adding", re.IGNORECASE), "consider adding"),
]


def find_deferral_pattern(content: str) -> tuple[bool, str]:
    """Check for deferral patterns, return (found, pattern_name)."""
    for pattern, name in DEFERRAL_PATTERNS:
        if pattern.search(content):
            return True, name
    return False, ""


# =============================================================================
# RECURSIVE PATH PATTERNS (anti-patterns for nested duplicates)
# =============================================================================

RECURSIVE_PATTERNS = [
    re.compile(r"\.claude/.*\.claude/"),
    re.compile(r"projects/[^/]+/projects/"),
    re.compile(r"\.claude/tmp/.*\.claude/tmp/"),
]


def is_recursive_path(path: str) -> bool:
    """Check if path has recursive/nested duplicates."""
    return any(p.search(path) for p in RECURSIVE_PATTERNS)
</file>

<file path="_prompt_context.py">
"""
Context hooks for UserPromptSubmit (priority 15-70).

Hooks that inject contextual information:
  15 intention_tracker   - Extract mentioned files/searches, track as pending
  30 prompt_disclaimer   - System context and task checklist
  32 tech_version_risk   - Warn about outdated AI knowledge for fast-moving tech
  35 project_context     - Git state and project structure
  40 memory_injector     - Auto-surface relevant memories
  45 context_injector    - Session state summary and command suggestions
  50 reminder_injector   - Custom trigger-based reminders
"""

import re
from pathlib import Path
from typing import Optional

from _prompt_registry import register_hook
from _hook_result import HookResult
from _logging import log_debug
from session_state import (
    SessionState,
    add_pending_file,
    add_pending_search,
    add_domain_signal,
    generate_context,
    Domain,
)
from context_builder import extract_keywords

# Path constants
SCRIPT_DIR = Path(__file__).parent
CLAUDE_DIR = SCRIPT_DIR.parent
MEMORY_DIR = CLAUDE_DIR / "memory"
REMINDERS_DIR = CLAUDE_DIR / "reminders"

# Try to import command awareness
try:
    from _config import COMMAND_SUGGEST_ENABLED
except ImportError:
    COMMAND_SUGGEST_ENABLED = False

# Try to import caching utilities
try:
    from _cache import (
        cached_file_read,
        cached_json_read,
        cached_git_branch,
        cached_git_status,
    )
except ImportError:
    # Fallback implementations
    def cached_file_read(path: str) -> str:
        try:
            return Path(path).read_text(encoding="utf-8")
        except Exception:
            return ""

    def cached_json_read(path: str) -> dict | None:
        import json

        try:
            return json.loads(Path(path).read_text())
        except Exception:
            return None

    def cached_git_branch() -> str:
        import subprocess

        try:
            return subprocess.run(
                ["git", "branch", "--show-current"],
                capture_output=True,
                text=True,
                timeout=2,
            ).stdout.strip()
        except Exception:
            return ""

    def cached_git_status() -> str:
        import subprocess

        try:
            return subprocess.run(
                ["git", "status", "--porcelain"],
                capture_output=True,
                text=True,
                timeout=2,
            ).stdout
        except Exception:
            return ""


# =============================================================================
# FILE/SEARCH EXTRACTION PATTERNS
# =============================================================================

_FILE_PATTERNS = [
    re.compile(r'[`"\']([^`"\']+\.[a-zA-Z]{1,6})[`"\']'),
    re.compile(r"(?:^|\s)([~./][\w./\\-]+\.\w{1,6})(?:\s|$|[,;:])"),
    re.compile(
        r"(?:file|path|in|at|from|edit|read|open)\s+[`\"']?([^`\"'\s]+\.\w{1,6})"
    ),
]

_SEARCH_PATTERNS = [
    re.compile(
        r'(?:search|grep|find)\s+(?:for\s+)?[`"\']([^`"\']+)[`"\']',
        re.IGNORECASE,
    ),
    re.compile(
        r'(?:search|grep|find)\s+[`"\']?([^`"\']+)[`"\']?\s+(?:in|across)',
        re.IGNORECASE,
    ),
]


def _extract_files_from_prompt(prompt: str) -> list[str]:
    """Extract file paths from prompt text."""
    files = []
    for pattern in _FILE_PATTERNS:
        for match in pattern.findall(prompt):
            m = match[0] if isinstance(match, tuple) else match
            if m and not m.startswith("http") and ("/" in m or "." in m):
                clean = m.strip("`\"'")
                if 3 < len(clean) < 200:
                    files.append(clean)
    return list(set(files))


def _extract_searches_from_prompt(prompt: str) -> list[str]:
    """Extract search terms from prompt text."""
    searches = []
    for pattern in _SEARCH_PATTERNS:
        for match in pattern.findall(prompt):
            m = match[0] if isinstance(match, tuple) else match
            clean = m.strip()
            if 2 < len(clean) < 100:
                searches.append(clean)
    return list(set(searches))


@register_hook("intention_tracker", priority=15)
def check_intention_tracker(data: dict, state: SessionState) -> HookResult:
    """Extract mentioned files/searches and track as pending."""
    prompt = data.get("prompt", "")
    if not prompt:
        return HookResult.allow()

    files = _extract_files_from_prompt(prompt)
    searches = _extract_searches_from_prompt(prompt)

    if not files and not searches:
        return HookResult.allow()

    for f in files:
        add_pending_file(state, f)
    for s in searches:
        add_pending_search(state, s)

    total = len(files) + len(searches)
    if total >= 2:
        preview = (files + searches)[:4]
        return HookResult.allow(
            f" DETECTED {total} ITEMS: {preview}\n"
            f"RULE: Batch ALL Read/Grep calls in ONE message. Do NOT read sequentially."
        )

    return HookResult.allow()


# =============================================================================
# PROMPT DISCLAIMER (priority 30)
# =============================================================================

DISCLAIMER = """ SYSTEM ASSISTANT MODE: Full access to /home/jinx & /mnt/c/. Ask if unsure. Read before edit. Verify before claiming. Use ~/projects/ for project work, ~/ai/ for AI projects/services, ~/.claude/tmp/ for scratch. For python scripts use /home/jinx/.claude/.venv/bin/python as interpreter. Always confirm file paths exist before referencing. For task tracking use `bd` (beads) NOT TodoWrite. """

TASK_CHECKLIST = """
## Task Checklist - Order of Operations

**Before starting:**
- [ ] Clarify first? Should I ask user any clarifying questions before proceeding?
- [ ] Check context? Memories (`spark`), git commits, or prior decisions relevant?
- [ ] Research needed? WebSearch/WebFetch for current docs/patterns?
- [ ] Existing functionality? Check with Grep/Glob first
- [ ] Use an agent? Task(Explore), Task(Plan), or other subagent faster/better?
- [ ] Ops scripts? Any ~/.claude/ops/ tools applicable (audit, void, xray, etc.)?
- [ ] Slash commands? Check project .claude/commands/ for relevant commands
- [ ] Anti-patterns? Will this introduce complexity or violate patterns?
- [ ] Track with beads? Use `bd create` or `bd update` to track?
- [ ] Parallelize? Script or multiple agents to complete faster?
- [ ] Background? Can anything run in background while proceeding with other parts?
- [ ] Speed vs quality? Fastest path maintaining code quality?

**After completing:**
- [ ] Validate? Verify change works (build, lint, typecheck)?
- [ ] Tests needed? Create or update tests?
- [ ] Tech debt? Clean up related issues noticed?
- [ ] Next steps: MUST suggest potential follow-up actions to user
"""


@register_hook("prompt_disclaimer", priority=30)
def check_prompt_disclaimer(data: dict, state: SessionState) -> HookResult:
    """Inject system context and task checklist."""
    return HookResult.allow(f"{DISCLAIMER.strip()}\n{TASK_CHECKLIST.strip()}")


# =============================================================================
# TECH VERSION RISK (priority 32)
# =============================================================================

# Format: (compiled_pattern, release_date, risk_level, version_info)
_TECH_RISK_DATABASE = [
    # Frontend frameworks - HIGH risk
    (
        re.compile(r"\btailwind(?:css)?\b", re.IGNORECASE),
        "2024-10",
        "HIGH",
        "v4.0 - major breaking changes from v3 config/utilities",
    ),
    (
        re.compile(r"\breact\b", re.IGNORECASE),
        "2024-12",
        "HIGH",
        "v19 - new compiler, hooks changes, deprecations",
    ),
    (
        re.compile(r"\bnext\.?js\b", re.IGNORECASE),
        "2024-10",
        "HIGH",
        "v15 - app router changes, turbopack default",
    ),
    (
        re.compile(r"\bsvelte\b", re.IGNORECASE),
        "2024-12",
        "HIGH",
        "v5 - runes, breaking changes from v4",
    ),
    (
        re.compile(r"\bvue\b", re.IGNORECASE),
        "2024-11",
        "MEDIUM",
        "v3.5+ - Vapor mode, new features",
    ),
    (
        re.compile(r"\bastro\b", re.IGNORECASE),
        "2024-12",
        "MEDIUM",
        "v5.0 - content layer changes",
    ),
    (
        re.compile(r"\bvite\b", re.IGNORECASE),
        "2024-11",
        "MEDIUM",
        "v6.0 - config changes, new defaults",
    ),
    # Build tools / runtimes
    (
        re.compile(r"\bbun\b", re.IGNORECASE),
        "2024-09",
        "HIGH",
        "v1.x - rapidly evolving, API changes",
    ),
    (
        re.compile(r"\bdeno\b", re.IGNORECASE),
        "2024-10",
        "HIGH",
        "v2.0 - major changes from v1",
    ),
    (
        re.compile(r"\bnode\.?js\b", re.IGNORECASE),
        "2024-10",
        "MEDIUM",
        "v22 LTS - new features",
    ),
    # Backend / API
    (
        re.compile(r"\bfastapi\b", re.IGNORECASE),
        "2024-09",
        "MEDIUM",
        "v0.115+ - new features, deprecations",
    ),
    (
        re.compile(r"\bpydantic\b", re.IGNORECASE),
        "2024-06",
        "HIGH",
        "v2.x - complete rewrite from v1",
    ),
    (
        re.compile(r"\blangchain\b", re.IGNORECASE),
        "2024-11",
        "HIGH",
        "v0.3 - major restructuring, new patterns",
    ),
    (
        re.compile(r"\bopenai\b.*\b(?:api|sdk|client)\b", re.IGNORECASE),
        "2024-10",
        "HIGH",
        "v1.x SDK - structured outputs, new models",
    ),
    (
        re.compile(r"\banthropic\b.*\b(?:api|sdk|client)\b", re.IGNORECASE),
        "2024-11",
        "HIGH",
        "new features, prompt caching, batches",
    ),
    # Databases / ORMs
    (
        re.compile(r"\bprisma\b", re.IGNORECASE),
        "2024-10",
        "MEDIUM",
        "v5.x - new features, some breaking",
    ),
    (
        re.compile(r"\bdrizzle\b", re.IGNORECASE),
        "2024-11",
        "MEDIUM",
        "rapidly evolving ORM",
    ),
    # Testing
    (
        re.compile(r"\bplaywright\b", re.IGNORECASE),
        "2024-10",
        "MEDIUM",
        "v1.48+ - new APIs, locators",
    ),
    (
        re.compile(r"\bvitest\b", re.IGNORECASE),
        "2024-10",
        "MEDIUM",
        "v2.x - new features",
    ),
    # CSS / UI
    (
        re.compile(r"\bshadcn\b", re.IGNORECASE),
        "2024-11",
        "MEDIUM",
        "new components, CLI changes",
    ),
    # Package managers
    (re.compile(r"\bpnpm\b", re.IGNORECASE), "2024-09", "LOW", "v9.x - minor changes"),
]

VERSION_SENSITIVE_KEYWORDS = re.compile(
    r"\b(install|add|upgrade|migrate|config|setup|init|create|new project|from scratch|latest)\b",
    re.IGNORECASE,
)


def _build_tech_warnings(prompt_lower: str, max_warnings: int = 2) -> list[str]:
    """Build tech risk warnings from prompt against risk database."""
    warnings = []
    for pattern, release_date, risk_level, version_info in _TECH_RISK_DATABASE:
        match = pattern.search(prompt_lower)
        if match and VERSION_SENSITIVE_KEYWORDS.search(prompt_lower):
            emoji = (
                "" if risk_level == "HIGH" else "" if risk_level == "MEDIUM" else ""
            )
            warnings.append(
                f"{emoji} **{match.group(0).upper()}** ({risk_level}): {version_info} (~{release_date})"
            )
            if len(warnings) >= max_warnings:
                break
    return warnings


def _check_version_mismatch(prompt_lower: str, deps: dict) -> str:
    """Check for version mismatch between package.json and prompt mentions."""
    checks = [
        (
            "tailwind",
            "tailwindcss",
            [("4", "v3|version\\s*3"), ("3", "v4|version\\s*4")],
        ),
        ("react", "react", [("19", "v18|version\\s*18")]),
    ]
    for keyword, pkg_name, version_checks in checks:
        if keyword in prompt_lower and pkg_name in deps:
            installed = deps[pkg_name].lstrip("^~")
            for prefix, pattern in version_checks:
                if installed.startswith(prefix) and re.search(pattern, prompt_lower):
                    return f"\n **VERSION MISMATCH**: {pkg_name} v{installed} installed but prompt mentions different version"
    return ""


@register_hook("tech_version_risk", priority=32)
def check_tech_version_risk(data: dict, state: SessionState) -> HookResult:
    """Warn about potentially outdated AI knowledge for fast-moving technologies."""
    prompt = data.get("prompt", "")
    if not prompt or len(prompt) < 10:
        return HookResult.allow()

    prompt_lower = prompt.lower()
    if not VERSION_SENSITIVE_KEYWORDS.search(prompt_lower):
        return HookResult.allow()

    warnings = _build_tech_warnings(prompt_lower)
    if not warnings:
        return HookResult.allow()

    # Check package.json version mismatch
    version_mismatch = ""
    pkg_data = cached_json_read(str(Path.cwd() / "package.json"))
    if pkg_data:
        deps = {
            **pkg_data.get("dependencies", {}),
            **pkg_data.get("devDependencies", {}),
        }
        version_mismatch = _check_version_mismatch(prompt_lower, deps)

    return HookResult.allow(
        f" **OUTDATED KNOWLEDGE RISK**\n{chr(10).join(warnings)}{version_mismatch}\n"
        f" Use `/research <tech>` to verify current docs"
    )


# =============================================================================
# PROJECT CONTEXT (priority 35)
# =============================================================================

KEY_FILES = {
    "package.json": "Node.js",
    "pyproject.toml": "Python (modern)",
    "Cargo.toml": "Rust",
    "go.mod": "Go",
    "Makefile": "Makefile",
    "Dockerfile": "Docker",
    "CLAUDE.md": "Claude instructions",
}
KEY_DIRS = ["src", "lib", ".claude", "tests", "docs", "projects"]


def _parse_git_changes(status: str) -> str:
    """Parse git status --porcelain output into summary string."""
    if not status:
        return ""
    lines = [ln for ln in status.split("\n") if ln.strip()]
    counts = {
        "modified": len([ln for ln in lines if len(ln) > 1 and ln[1] == "M"]),
        "untracked": len([ln for ln in lines if ln.startswith("??")]),
        "staged": len([ln for ln in lines if len(ln) > 0 and ln[0] in "MADRC"]),
    }
    parts = [f"{v} {k}" for k, v in counts.items() if v]
    return ", ".join(parts)


def _get_context_label(cwd: Path, home: Path) -> str:
    """Determine context label based on working directory."""
    cwd_str = str(cwd)
    if cwd_str.startswith(str(home / "projects")) and cwd != home / "projects":
        return "PROJECT"
    if cwd_str.startswith(str(home / "ai")) and cwd != home / "ai":
        return "AI"
    return "SYSTEM"


@register_hook("project_context", priority=35)
def check_project_context(data: dict, state: SessionState) -> HookResult:
    """Inject git state and project structure."""
    cwd, home = Path.cwd(), Path.home()
    parts = []

    branch = cached_git_branch()
    if branch:
        git_info = f"branch: {branch}"
        changes = _parse_git_changes(cached_git_status())
        if changes:
            git_info += f" | changes: {changes}"
        parts.append(f"Git: {git_info}")

    found_dirs = [d for d in KEY_DIRS if (cwd / d).is_dir()]
    if found_dirs:
        parts.append(f"Dirs: {', '.join(found_dirs)}")

    if not parts:
        return HookResult.allow()

    return HookResult.allow(f" {_get_context_label(cwd, home)}: {' | '.join(parts)}")


# =============================================================================
# MEMORY INJECTOR (priority 40)
# =============================================================================

LESSONS_FILE = MEMORY_DIR / "__lessons.md"
DECISIONS_FILE = MEMORY_DIR / "__decisions.md"
PUNCH_LIST_FILE = MEMORY_DIR / "punch_list.json"


def find_relevant_lessons(keywords: list[str], max_results: int = 3) -> list[str]:
    """Find lessons matching keywords (uses cached file read)."""
    content = cached_file_read(str(LESSONS_FILE))
    if not content:
        return []
    matches = []
    try:
        for line in content.split("\n"):
            if not line.strip() or line.startswith("#"):
                continue
            line_lower = line.lower()
            score = sum(1 for k in keywords if k in line_lower)
            if score > 0:
                if "[block-reflection:" in line:
                    score += 2
                matches.append((score, line.strip()))
        matches.sort(key=lambda x: -x[0])
        return [m[1][:100] for m in matches[:max_results]]
    except Exception:
        return []


def get_active_scope() -> Optional[dict]:
    """Get active DoD/scope if exists (uses cached JSON read)."""
    data = cached_json_read(str(PUNCH_LIST_FILE))
    if not data:
        return None
    try:
        task = data.get("task", "")
        items = data.get("items", [])
        if not task or not items:
            return None
        completed = sum(1 for i in items if i.get("status") == "done")
        next_item = None
        for item in items:
            if item.get("status") != "done":
                next_item = item.get("description", "")[:60]
                break
        return {
            "task": task[:50],
            "progress": f"{completed}/{len(items)}",
            "next": next_item,
        }
    except Exception:
        return None


# Trivial prompts that don't need memory injection
_TRIVIAL_PROMPT_PATTERN = re.compile(
    r"^(yes|no|ok|hi|hello|thanks|y|n|status|commit|push|/\w+|SUDO)\b", re.IGNORECASE
)


def _get_spark_associations(prompt: str) -> list[str]:
    """Get spark associations with timeout protection."""
    # Skip trivial prompts (saves 100ms+)
    if len(prompt) < 15 or _TRIVIAL_PROMPT_PATTERN.match(prompt):
        return []

    try:
        from synapse_core import run_spark, MAX_ASSOCIATIONS, MAX_MEMORIES

        # run_spark has its own cache - call directly with shorter timeout
        result = run_spark(prompt, timeout=0.5)
        if not result:
            return []
        assocs = result.get("associations", []) + result.get("memories", [])
        return assocs[: MAX_ASSOCIATIONS + MAX_MEMORIES]
    except Exception:
        return []


def _build_memory_parts(
    spark_assocs: list, lessons: list, scope: dict | None
) -> list[str]:
    """Build memory injection output parts."""
    parts = []
    if spark_assocs:
        lines = "\n".join(f"   * {a[:100]}" for a in spark_assocs[:3])
        parts.append(f"SUBCONSCIOUS RECALL:\n{lines}")
    if lessons:
        lines = "\n".join(f"   * {lesson}" for lesson in lessons)
        parts.append(f"RELEVANT LESSONS:\n{lines}")
    if scope:
        line = f"ACTIVE TASK: {scope['task']} [{scope['progress']}]"
        if scope.get("next"):
            line += f"\n   Next: {scope['next']}"
        parts.append(line)
    return parts


@register_hook("memory_injector", priority=40)
def check_memory_injector(data: dict, state: SessionState) -> HookResult:
    """Auto-surface relevant memories."""
    prompt = data.get("prompt", "")
    if not prompt or len(prompt) < 10:
        return HookResult.allow()

    spark_assocs = _get_spark_associations(prompt)
    keywords = extract_keywords(prompt)
    lessons = find_relevant_lessons(keywords) if keywords else []
    scope = get_active_scope()

    parts = _build_memory_parts(spark_assocs, lessons, scope)
    return HookResult.allow("\n\n".join(parts)) if parts else HookResult.allow()


# =============================================================================
# CONTEXT INJECTOR (priority 45)
# =============================================================================


@register_hook("context_injector", priority=45)
def check_context_injector(data: dict, state: SessionState) -> HookResult:
    """Inject session state summary and command suggestions."""
    prompt = data.get("prompt", "")
    if not prompt or len(prompt) < 5:
        return HookResult.allow()

    add_domain_signal(state, prompt[:200])

    # Check if we should inject
    should_check = (
        state.errors_unresolved
        or (state.domain != Domain.UNKNOWN and state.domain_confidence > 0.5)
        or len(state.files_edited) >= 2
        or COMMAND_SUGGEST_ENABLED
    )
    if not should_check:
        return HookResult.allow()

    parts = []

    # State context
    state_context = generate_context(state)
    if state_context:
        parts.append(f" {state_context}")

    # Command suggestions
    if COMMAND_SUGGEST_ENABLED and len(prompt) >= 15:
        try:
            from command_awareness import suggest_commands

            suggestions = suggest_commands(prompt, max_suggestions=2)
            for s in suggestions:
                parts.append(f" {s}")
        except Exception as e:
            log_debug("_prompt_context", f"command suggestion loading failed: {e}")

    return HookResult.allow("\n".join(parts)) if parts else HookResult.allow()


# =============================================================================
# REMINDER INJECTOR (priority 50)
# =============================================================================


def _find_frontmatter_end(lines: list[str]) -> int:
    """Find the closing --- index for YAML frontmatter."""
    for i, line in enumerate(lines[1:], 1):
        if line.strip() == "---":
            return i
    return -1


def _parse_frontmatter_lines(lines: list[str]) -> dict:
    """Parse simple YAML key-value pairs from frontmatter lines."""
    meta = {}
    current_key = None
    current_list = []
    for line in lines:
        stripped = line.strip()
        if not stripped:
            continue
        if ":" in stripped and not stripped.startswith("-"):
            if current_key and current_list:
                meta[current_key] = current_list
            key_part = stripped.split(":")[0].strip()
            val_part = stripped[len(key_part) + 1 :].strip()
            current_key = key_part
            if val_part:
                meta[current_key] = val_part
                current_key = None
                current_list = []
            else:
                current_list = []
        elif stripped.startswith("-") and current_key:
            current_list.append(stripped[1:].strip())
    if current_key and current_list:
        meta[current_key] = current_list
    return meta


def parse_reminder_frontmatter(content: str) -> tuple[dict, str]:
    """Parse YAML frontmatter from reminder file."""
    if not content.startswith("---"):
        return {}, content
    lines = content.split("\n")
    end_idx = _find_frontmatter_end(lines)
    if end_idx == -1:
        return {}, content
    meta = _parse_frontmatter_lines(lines[1:end_idx])
    body = "\n".join(lines[end_idx + 1 :]).strip()
    return meta, body


def matches_reminder_trigger(prompt: str, trigger: str) -> bool:
    """Check if prompt matches a reminder trigger."""
    prompt_lower = prompt.lower()
    if trigger.startswith("phrase:"):
        return trigger[7:].lower() in prompt_lower
    elif trigger.startswith("word:"):
        return bool(re.search(rf"\b{re.escape(trigger[5:])}\b", prompt, re.IGNORECASE))
    elif trigger.startswith("regex:"):
        try:
            return bool(re.search(trigger[6:], prompt, re.IGNORECASE))
        except re.error:
            return False
    else:
        return trigger.lower() in prompt_lower


@register_hook("reminder_injector", priority=50)
def check_reminder_injector(data: dict, state: SessionState) -> HookResult:
    """Inject custom trigger-based reminders."""
    prompt = data.get("prompt", "")
    if not prompt or not REMINDERS_DIR.exists():
        return HookResult.allow()

    matches = []
    for md_file in REMINDERS_DIR.glob("*.md"):
        try:
            content = md_file.read_text(encoding="utf-8")
            meta, body = parse_reminder_frontmatter(content)
            triggers = meta.get("trigger", [])
            if isinstance(triggers, str):
                triggers = [triggers]
            if not triggers:
                matches.append((body, md_file.stem))
                continue
            for trigger in triggers:
                if matches_reminder_trigger(prompt, trigger):
                    matches.append((body, md_file.stem))
                    break
        except Exception:
            continue

    if not matches:
        return HookResult.allow()

    parts = [f"[{fname}]\n{content}" for content, fname in matches]
    context = "\n\n---\n\n".join(parts)
    return HookResult.allow(
        f"<additional-user-instruction>\n{context}\n</additional-user-instruction>"
    )
</file>

<file path="_prompt_gating.py">
"""
Gating hooks for UserPromptSubmit.

Priority range: 0-10
Handles: confidence management, goal tracking, intake protocol, build-vs-buy checks.
"""

import _lib_path  # noqa: F401
import re

from _prompt_registry import register_hook
from _hook_result import HookResult
from session_state import (
    SessionState,
    set_goal,
    check_goal_drift,
    should_nudge,
    record_nudge,
    start_feature,
    update_confidence,
    set_confidence,
)

# Confidence system imports
from confidence import (
    is_rock_bottom,
    check_realignment_complete,
    mark_realignment_complete,
    get_realignment_questions,
    ROCK_BOTTOM_RECOVERY_TARGET,
    DEFAULT_CONFIDENCE,
    format_confidence_change,
    should_require_research,
    should_mandate_external,
    assess_prompt_complexity,
    apply_increasers,
    get_tier_info,
    generate_approval_prompt,
    UserCorrectionReducer,
    detect_dispute_in_prompt,
    dispute_reducer,
    get_recent_reductions,
)

# Fuzzy matching for build-vs-buy detection
try:
    from rapidfuzz import fuzz, process as rf_process

    RAPIDFUZZ_AVAILABLE = True
except ImportError:
    RAPIDFUZZ_AVAILABLE = False

# =============================================================================
# PATTERNS AND CONSTANTS
# =============================================================================

# Sentiment patterns
POSITIVE_SENTIMENT = [
    r"^(nice|great|perfect|awesome|excellent|love\s+it|good\s+job|well\s+done)[!.,\s]?$",
    r"^(yes|yep|yeah|yup|exactly|correct|right)[!.,\s]?$",
    r"^(thanks|thank\s+you|thx|ty)[!.,\s]?$",
    r"\bthat'?s?\s+(perfect|great|exactly|what\s+i\s+(wanted|needed))\b",
    r"\blove\s+(it|this|that)\b",
    r"\bbeautiful\b",
    r"^(ok|okay|k|sure)[!.,\s]?$",
]

NEGATIVE_SENTIMENT = [
    r"^(no|nope|nah|wrong)[!.,\s]?$",
    r"^(ugh|argh|damn|dammit|shit|fuck)\b",
    r"\b(frustrated|annoying|annoyed|irritated)\b",
    r"\bwhat\s+the\s+(hell|heck|fuck)\b",
    r"\bthis\s+is\s+(wrong|broken|bad|terrible)\b",
    r"\bstop\s+(it|that|doing\s+that)\b",
    r"\bi\s+said\b",
    r"\bagain\s*[?!]",
]

# Scope expansion patterns
_SCOPE_EXPANSION_PATTERNS = [
    (
        r"\b(also|additionally|and\s+also|while\s+you'?re?\s+at\s+it)\b",
        "scope addition",
    ),
    (r"\b(another|different|new)\s+(feature|task|thing|project)\b", "new feature"),
    (r"\b(switch|pivot|change)\s+to\b", "direction change"),
    (r"\b(actually|instead|forget\s+that)\b", "goal replacement"),
    (r"\b(one\s+more|btw|by\s+the\s+way)\b", "tangent"),
]

# Complexity patterns
_COMPLEX_SIGNALS = [
    re.compile(r"\b(architect|design|refactor|migrate|restructure)\b", re.IGNORECASE),
    re.compile(r"\b(system|infrastructure|deploy|production)\b", re.IGNORECASE),
    re.compile(r"\b(integrate|integration|api|endpoint)\b", re.IGNORECASE),
    re.compile(r"\b(multiple|several|all|every|across)\b", re.IGNORECASE),
    re.compile(r"\b(database|auth|security|permission)\b", re.IGNORECASE),
    re.compile(r"\b(how|why|should|could|best|optimal)\b", re.IGNORECASE),
    re.compile(r"\b(investigate|debug|diagnose|figure out)\b", re.IGNORECASE),
    re.compile(
        r"\b(feature|implement|build|create|add)\b.*\b(new|from scratch)\b",
        re.IGNORECASE,
    ),
]

_TRIVIAL_SIGNALS = [
    re.compile(r"^(fix|typo|update|change|rename)\s+\w+$", re.IGNORECASE),
    re.compile(r"^(run|execute|test)\s+", re.IGNORECASE),
    re.compile(r"^(commit|push|pr|status)\b", re.IGNORECASE),
    re.compile(r"^(hi|hello|thanks|ok|yes|no)\b", re.IGNORECASE),
    re.compile(r"^/\w+"),
    re.compile(r"^(what is|where is|show me)\s+\w+", re.IGNORECASE),
]

# Build-vs-Buy patterns
_BUILD_FROM_SCRATCH_PATTERNS = [
    re.compile(
        r"\b(build|create|implement|make|write)\s+(a|an|my|the)\s+\w+\s*(app|application|tool|system|service|cli|bot|script)\b",
        re.IGNORECASE,
    ),
    re.compile(r"\bfrom\s+scratch\b", re.IGNORECASE),
    re.compile(
        r"\b(todo|task|note|bookmark|password|budget|expense|habit|timer|pomodoro|reminder|calendar|journal|diary|inventory|kanban|crm)\s*(app|manager|tracker|tool|system)?\b",
        re.IGNORECASE,
    ),
    re.compile(
        r"\b(implement|build|create)\s+(my\s+own|a\s+custom|a\s+simple)\b",
        re.IGNORECASE,
    ),
    re.compile(r"\b(don't|do not)\s+want\s+to\s+use\s+(any|existing)\b", re.IGNORECASE),
]

# Common "wheel reinvention" apps
_COMMON_REINVENTIONS: list[tuple[str, list[str]]] = [
    ("todo app", ["Todoist", "TickTick", "Things 3", "Microsoft To Do"]),
    ("task manager", ["Todoist", "Asana", "Trello", "Linear"]),
    ("note taking app", ["Obsidian", "Notion", "Logseq", "Bear"]),
    ("bookmark manager", ["Raindrop.io", "Pocket", "Pinboard"]),
    ("password manager", ["1Password", "Bitwarden", "KeePassXC"]),
    ("budget tracker", ["YNAB", "Mint", "Lunch Money", "Actual Budget"]),
    ("expense tracker", ["Expensify", "Splitwise", "Mint"]),
    ("habit tracker", ["Habitica", "Streaks", "Loop Habit Tracker"]),
    ("pomodoro timer", ["Forest", "Focus Keeper", "Pomofocus"]),
    ("calendar app", ["Fantastical", "Google Calendar", "Calendly"]),
    ("journal app", ["Day One", "Journey", "Notion"]),
    ("inventory system", ["Sortly", "inFlow", "Zoho Inventory"]),
    ("kanban board", ["Trello", "Notion", "Linear", "Jira"]),
    ("crm system", ["HubSpot", "Salesforce", "Pipedrive"]),
    ("url shortener", ["Bitly", "Short.io", "YOURLS"]),
    ("chat app", ["Slack", "Discord", "Mattermost"]),
    ("blog platform", ["Ghost", "WordPress", "Hugo", "11ty"]),
    ("static site generator", ["Hugo", "11ty", "Astro", "Next.js"]),
    ("file uploader", ["Dropzone.js", "FilePond", "Uppy"]),
    ("weather app", ["OpenWeatherMap API", "Weather.com", "wttr.in"]),
    ("recipe manager", ["Paprika", "Mealime", "Notion templates"]),
    ("time tracker", ["Toggl", "Clockify", "RescueTime"]),
    ("invoice generator", ["Invoice Ninja", "Wave", "Zoho Invoice"]),
    ("markdown editor", ["Typora", "MarkText", "VS Code"]),
    ("screenshot tool", ["Flameshot", "ShareX", "CleanShot X"]),
    ("clipboard manager", ["CopyQ", "Ditto", "Maccy"]),
    ("countdown timer", ["Online-Stopwatch.com", "Countdown apps"]),
    ("flashcard app", ["Anki", "Quizlet", "RemNote"]),
    ("rss reader", ["Feedly", "Inoreader", "NewsBlur"]),
    ("link in bio", ["Linktree", "bio.link", "Carrd"]),
]

_REINVENTION_NAMES = [name for name, _ in _COMMON_REINVENTIONS]
_REINVENTION_LOOKUP = {name: alts for name, alts in _COMMON_REINVENTIONS}

# Confidence constants
_CONFIDENCE_FLOOR = 70
_PROMPT_CONFIDENCE_CAP = 85
_VERIFIED_INCREASERS = ("test_pass", "build_success")


# =============================================================================
# HELPER FUNCTIONS
# =============================================================================


def detect_scope_expansion(state: SessionState, prompt: str) -> tuple[bool, str]:
    """Detect scope expansion in prompt."""
    if not state.original_goal:
        return False, ""
    prompt_lower = prompt.lower()
    for pattern, reason in _SCOPE_EXPANSION_PATTERNS:
        if re.search(pattern, prompt_lower, re.IGNORECASE):
            return (
                True,
                f"Detected {reason}: prompt suggests expanding beyond original goal",
            )
    return False, ""


def _reset_goal_state(state: SessionState) -> None:
    """Clear all goal-related state."""
    state.original_goal = ""
    state.goal_keywords = []
    state.goal_set_turn = 0
    state.goal_project_id = ""
    state.nudge_history.pop("scope_expansion", None)
    state.nudge_history.pop("goal_drift", None)


def _init_goal(state: SessionState, prompt: str, project_id: str) -> None:
    """Initialize goal from prompt."""
    set_goal(state, prompt)
    start_feature(state, prompt[:100])
    state.goal_project_id = project_id


# Cache for project ID (avoids 27ms lookup per call)
_PROJECT_ID_CACHE: dict = {"value": None, "time": 0.0}
_PROJECT_ID_TTL = 10.0  # seconds


def _get_current_project_id() -> str:
    """Get current project ID or empty string (cached)."""
    import time

    now = time.time()
    if (
        _PROJECT_ID_CACHE["value"] is not None
        and now - _PROJECT_ID_CACHE["time"] < _PROJECT_ID_TTL
    ):
        return _PROJECT_ID_CACHE["value"]
    try:
        from project_detector import get_current_project

        result = get_current_project().project_id
    except Exception:
        result = ""
    _PROJECT_ID_CACHE["value"] = result
    _PROJECT_ID_CACHE["time"] = now
    return result


def _handle_scope_expansion(state: SessionState, prompt: str) -> HookResult | None:
    """Handle scope expansion detection."""
    is_expanding, reason = detect_scope_expansion(state, prompt)
    if not is_expanding:
        return None
    show, severity = should_nudge(state, "scope_expansion", reason)
    if not show:
        return None
    record_nudge(state, "scope_expansion", reason)
    times_warned = state.nudge_history.get("scope_expansion", {}).get("times_shown", 0)
    if times_warned >= 2 or severity == "escalate":
        return HookResult.deny(
            f" **SCOPE BLOCKED**: {reason}\nGoal: {state.original_goal[:60]}... | SUDO SCOPE to override"
        )
    return HookResult.allow(
        f' **SCOPE EXPANSION DETECTED**\n Current goal: "{state.original_goal[:60]}..."\n'
        f" {reason}\n\nFinish current feature before switching. (Will block after {2 - times_warned} more attempts)"
    )


def _handle_confidence_floor(state: SessionState) -> None:
    """Handle floor reset with trust debt accumulation."""
    if state.confidence == 0:
        set_confidence(state, DEFAULT_CONFIDENCE, "session initialization")
    elif state.confidence < _CONFIDENCE_FLOOR:
        old_debt = getattr(state, "reputation_debt", 0)
        state.reputation_debt = old_debt + 1
        set_confidence(
            state, _CONFIDENCE_FLOOR, f"floor reset (debt now {state.reputation_debt})"
        )


def _apply_user_correction(state: SessionState, prompt: str, parts: list) -> int:
    """Apply user correction reducer if triggered."""
    old_conf = state.confidence
    reducer = UserCorrectionReducer()
    key = "confidence_reducer_user_correction"
    last_trigger = state.nudge_history.get(key, {}).get("last_turn", -999)
    if reducer.should_trigger({"prompt": prompt}, state, last_trigger):
        update_confidence(state, reducer.delta, reducer.name)
        if key not in state.nudge_history:
            state.nudge_history[key] = {}
        state.nudge_history[key]["last_turn"] = state.turn_count
        parts.append(
            format_confidence_change(old_conf, state.confidence, f"({reducer.name})")
        )
    return state.confidence


def _has_recent_verified_boost(state: SessionState) -> bool:
    """Check if there's a recent verified boost."""
    for inc_name in _VERIFIED_INCREASERS:
        key = f"confidence_increaser_{inc_name}"
        last_turn = state.nudge_history.get(key, {}).get("last_turn", -999)
        if state.turn_count - last_turn <= 3:
            return True
    return False


def _apply_confidence_cap(state: SessionState, parts: list) -> None:
    """Apply confidence cap unless protected by verified boost."""
    if state.confidence <= _PROMPT_CONFIDENCE_CAP:
        return
    if _has_recent_verified_boost(state):
        parts.append(
            f" Confidence at {state.confidence}% (verified success protected)"
        )
    else:
        set_confidence(state, _PROMPT_CONFIDENCE_CAP, "prompt cap (no verified boost)")
        parts.append(
            f" Confidence capped at {_PROMPT_CONFIDENCE_CAP}% (earn higher via verified success)"
        )


def _fuzzy_match_reinvention(
    prompt: str, threshold: int = 75
) -> tuple[str | None, list[str]]:
    """Check if prompt mentions a common wheel-reinvention app using fuzzy matching."""
    if not RAPIDFUZZ_AVAILABLE:
        return None, []
    prompt_lower = prompt.lower()
    words = prompt_lower.split()
    candidates = []
    for i in range(len(words)):
        for length in range(2, 5):
            if i + length <= len(words):
                phrase = " ".join(words[i : i + length])
                candidates.append(phrase)
    if len(words) <= 6:
        candidates.append(prompt_lower)
    best_match = None
    best_score = 0
    for candidate in candidates:
        result = rf_process.extractOne(
            candidate, _REINVENTION_NAMES, scorer=fuzz.token_sort_ratio
        )
        if result and result[1] > best_score and result[1] >= threshold:
            best_match = result[0]
            best_score = result[1]
    if best_match:
        return best_match, _REINVENTION_LOOKUP.get(best_match, [])
    return None, []


# =============================================================================
# GATING HOOKS (priority 0-10)
# =============================================================================


@register_hook("confidence_override", priority=0)
def check_confidence_override(data: dict, state: SessionState) -> HookResult:
    """Allow manual confidence override via SET_CONFIDENCE=X in prompt."""
    prompt = data.get("prompt", "")
    match = re.search(r"\bSET_CONFIDENCE\s*=\s*(\d+)\b", prompt, re.IGNORECASE)
    if not match:
        return HookResult.allow()
    try:
        new_confidence = int(match.group(1))
        new_confidence = max(0, min(100, new_confidence))
    except ValueError:
        return HookResult.allow()
    old_confidence = state.confidence
    set_confidence(state, new_confidence, "manual override")
    old_tier, old_emoji, _ = get_tier_info(old_confidence)
    new_tier, new_emoji, _ = get_tier_info(state.confidence)
    return HookResult.allow(
        f" **CONFIDENCE OVERRIDE**\n"
        f"{old_emoji} {old_confidence}% ({old_tier})  {new_emoji} {state.confidence}% ({new_tier})"
    )


@register_hook("goal_anchor", priority=1)
def check_goal_anchor(data: dict, state: SessionState) -> HookResult:
    """Prevent scope drift and block scope expansion."""
    prompt = data.get("prompt", "")
    if not prompt:
        return HookResult.allow()
    project_id = _get_current_project_id()
    if state.original_goal and state.goal_project_id and project_id:
        if project_id != state.goal_project_id:
            _reset_goal_state(state)
    if not state.original_goal:
        _init_goal(state, prompt, project_id)
        return HookResult.allow()
    if "SUDO SCOPE" in prompt.upper():
        _reset_goal_state(state)
        clean = re.sub(r"\bSUDO\s+SCOPE\b", "", prompt, flags=re.IGNORECASE).strip()
        _init_goal(state, clean, project_id)
        return HookResult.allow()
    if result := _handle_scope_expansion(state, prompt):
        return result
    is_drifting, drift_msg = check_goal_drift(state, prompt)
    if is_drifting:
        show, severity = should_nudge(state, "goal_drift", drift_msg)
        if show:
            record_nudge(state, "goal_drift", drift_msg)
            if severity == "escalate":
                ignored = state.nudge_history.get("goal_drift", {}).get(
                    "times_ignored", 0
                )
                drift_msg = (
                    f" **REPEATED DRIFT WARNING** (ignored {ignored}x)\n{drift_msg}"
                )
            return HookResult.allow(f"\n{drift_msg}\n")
    return HookResult.allow()


@register_hook("user_sentiment", priority=2)
def check_user_sentiment(data: dict, state: SessionState) -> HookResult:
    """Adjust confidence based on user sentiment in prompt."""
    prompt = data.get("prompt", "")
    if not prompt or len(prompt) > 100:
        return HookResult.allow()
    prompt_lower = prompt.lower().strip()
    for pattern in POSITIVE_SENTIMENT:
        if re.search(pattern, prompt_lower, re.IGNORECASE):
            old_conf = state.confidence
            update_confidence(state, 3, "positive_sentiment")
            if state.confidence != old_conf:
                return HookResult.allow(
                    f" Positive sentiment: {old_conf}%  {state.confidence}% (+3)"
                )
            return HookResult.allow()
    for pattern in NEGATIVE_SENTIMENT:
        if re.search(pattern, prompt_lower, re.IGNORECASE):
            old_conf = state.confidence
            update_confidence(state, -3, "negative_sentiment")
            if state.confidence != old_conf:
                return HookResult.allow(
                    f" Negative sentiment detected: {old_conf}%  {state.confidence}% (-3)"
                )
            return HookResult.allow()
    return HookResult.allow()


@register_hook("rock_bottom_realignment", priority=2)
def check_rock_bottom(data: dict, state: SessionState) -> HookResult:
    """Force realignment questions when confidence hits rock bottom."""
    prompt = data.get("prompt", "").strip()
    if not is_rock_bottom(state.confidence):
        return HookResult.allow()
    if check_realignment_complete(state):
        return HookResult.allow()
    answer_patterns = [
        r"^(continue|new|debug|careful|fast|ask|misunderstood|technical|wrong|nothing)",
        r"^\d\.",
        r"^(a|b|c|d)\)",
    ]
    is_answer = any(re.search(p, prompt.lower()) for p in answer_patterns)
    positive_patterns = [r"^(ok|yes|sure|go|proceed|continue|let's|alright|good)"]
    is_positive = any(re.search(p, prompt.lower()) for p in positive_patterns)
    if is_answer or is_positive or len(prompt) < 30:
        new_confidence = mark_realignment_complete(state)
        old_confidence = state.confidence
        set_confidence(state, new_confidence, "rock bottom realignment complete")
        return HookResult.allow(
            f" **REALIGNMENT COMPLETE**\n"
            f"Confidence restored: {old_confidence}%  {state.confidence}%\n\n"
            f"Ready to proceed with renewed focus."
        )
    questions = get_realignment_questions()
    questions_text = "\n".join(
        [f"**{q['header']}**: {q['question']}" for q in questions]
    )
    return HookResult.allow(
        f" **ROCK BOTTOM REACHED** (Confidence: {state.confidence}%)\n\n"
        f"I need to realign with you before continuing. Please answer briefly:\n\n"
        f"{questions_text}\n\n"
        f"After you respond, my confidence will be restored to {ROCK_BOTTOM_RECOVERY_TARGET}%."
    )


@register_hook("confidence_initializer", priority=3)
def check_confidence_initializer(data: dict, state: SessionState) -> HookResult:
    """Initialize and assess confidence on every prompt."""
    prompt = data.get("prompt", "")
    _handle_confidence_floor(state)
    if not prompt or len(prompt) < 20:
        return HookResult.allow()
    state.last_user_prompt = prompt
    parts = []
    delta, reasons = assess_prompt_complexity(prompt)
    old_conf = state.confidence
    if delta != 0:
        update_confidence(state, delta, ", ".join(reasons))
    old_conf = _apply_user_correction(state, prompt, parts)
    for name, inc_delta, desc, requires_approval in apply_increasers(
        state, {"prompt": prompt}
    ):
        if not requires_approval:
            update_confidence(state, inc_delta, name)
            parts.append(
                format_confidence_change(old_conf, state.confidence, f"({name})")
            )
            old_conf = state.confidence
    _apply_confidence_cap(state, parts)
    mandatory, mandatory_msg = should_mandate_external(state.confidence)
    if mandatory:
        parts.append(mandatory_msg)
    elif state.confidence < 50:
        require_research, research_msg = should_require_research(state.confidence, {})
        if require_research:
            parts.append(research_msg)
    if len(prompt) > 100:
        tier_name, emoji, _ = get_tier_info(state.confidence)
        parts.insert(0, f"{emoji} **Confidence: {state.confidence}% ({tier_name})**")
    return HookResult.allow("\n\n".join(parts)) if parts else HookResult.allow()


@register_hook("intake_protocol", priority=5)
def check_intake_protocol(data: dict, state: SessionState) -> HookResult:
    """Show complexity-tiered checklists."""
    prompt = data.get("prompt", "")
    if not prompt:
        return HookResult.allow()
    prompt_lower = prompt.lower().strip()
    prompt_len = len(prompt)
    for pattern in _TRIVIAL_SIGNALS:
        if pattern.search(prompt_lower):
            return HookResult.allow()
    if prompt_len < 50:
        return HookResult.allow()
    complex_score = sum(1 for p in _COMPLEX_SIGNALS if p.search(prompt_lower))
    if (prompt_len > 200 and complex_score >= 2) or complex_score >= 3:
        checklist = """
 INTAKE PROTOCOL 
  Request: [1-line summary]                                 
  Confidence: [L/M/H] because [reason]                      
  Gaps: [what I don't know / need to verify]                
  Alternatives: [ ] searched  [ ] none fit  [ ] user wants custom
  Boost: [ ] research  [ ] oracle  [ ] groq  [ ] ask user   
  Adjusted: [L/M/H] after [action taken]                    
  Gate: [PROCEED / STOP - need X to continue]               

  Plan: [numbered steps]                                    
  Agents: [scout/digest/parallel/chore if needed]           
  Orchestrate?: [batch/aggregate  /orchestrate for 37% ]  
  Tools: [specific tools to use]                            
"""
        return HookResult.allow(
            f" COMPLEX TASK DETECTED - Full protocol required:{checklist}\n\n"
            f" THRESHOLD: If Confidence < M after boost attempts, STOP and clarify with user."
        )
    if complex_score >= 1 or prompt_len > 50:
        checklist = """
 INTAKE 
 Request: [summary] | Conf: [L/M/H]       
 Gaps: [unknowns] | Boost: [if needed]    
"""
        return HookResult.allow(f" Multi-step task - Abbreviated intake:{checklist}")
    return HookResult.allow()


@register_hook("build_vs_buy", priority=6)
def check_build_vs_buy(data: dict, state: SessionState) -> HookResult:
    """Detect wheel-reinvention and prompt for alternatives consideration."""
    prompt = data.get("prompt", "")
    if not prompt or len(prompt) < 20:
        return HookResult.allow()
    learning_patterns = re.compile(
        r"\b(learn|practice|exercise|tutorial|study|understand|educational)\b",
        re.IGNORECASE,
    )
    if learning_patterns.search(prompt):
        return HookResult.allow()
    fuzzy_match, alternatives = _fuzzy_match_reinvention(prompt)
    regex_match = any(p.search(prompt) for p in _BUILD_FROM_SCRATCH_PATTERNS)
    if not fuzzy_match and not regex_match:
        return HookResult.allow()
    if fuzzy_match and alternatives:
        alt_list = ", ".join(alternatives[:4])
        return HookResult.allow(
            f" **BUILD-VS-BUY CHECK** - Detected: **{fuzzy_match}**\n"
            f" Existing solutions: {alt_list}\n\n"
            "Before building custom:\n"
            "- [ ] Explain why existing solutions don't fit\n"
            "- [ ] Confirm user wants custom implementation\n\n"
            " +5 confidence for suggesting alternatives (`premise_challenge`)"
        )
    return HookResult.allow(
        " **BUILD-VS-BUY CHECK** (Principle #23)\n"
        "Before building custom, verify:\n"
        "- [ ] Searched for existing tools/libraries\n"
        "- [ ] Listed 2-3 alternatives with pros/cons\n"
        "- [ ] User explicitly wants custom OR existing solutions don't fit\n\n"
        " +5 confidence for suggesting alternatives (`premise_challenge`)"
    )


@register_hook("confidence_approval_gate", priority=7)
def check_confidence_approval_gate(data: dict, state: SessionState) -> HookResult:
    """Handle explicit trust restoration requests requiring approval."""
    prompt = data.get("prompt", "")
    if not prompt:
        return HookResult.allow()
    prompt_upper = prompt.upper()
    if "CONFIDENCE_BOOST_APPROVED" in prompt_upper:
        pending = state.nudge_history.get("confidence_boost_pending", {})
        if pending.get("requested", False):
            requested_delta = pending.get("delta", 15)
            old_confidence = state.confidence
            update_confidence(state, requested_delta, "trust_regained (approved)")
            state.nudge_history["confidence_boost_pending"] = {"requested": False}
            return HookResult.allow(
                " **Confidence Restored**\n\n"
                + format_confidence_change(
                    old_confidence, state.confidence, "(trust_regained)"
                )
            )
        return HookResult.allow()
    trust_patterns = [
        r"\btrust\s+regained\b",
        r"\bconfidence\s+(?:restored|boost(?:ed)?)\b",
        r"\brestore\s+(?:my\s+)?confidence\b",
    ]
    for pattern in trust_patterns:
        if re.search(pattern, prompt, re.IGNORECASE):
            approval_msg = generate_approval_prompt(
                state.confidence,
                requested_delta=15,
                reasons=["User requested trust restoration"],
            )
            if "confidence_boost_pending" not in state.nudge_history:
                state.nudge_history["confidence_boost_pending"] = {}
            state.nudge_history["confidence_boost_pending"]["requested"] = True
            state.nudge_history["confidence_boost_pending"]["delta"] = 15
            state.nudge_history["confidence_boost_pending"]["turn"] = state.turn_count
            return HookResult.allow(approval_msg)
    return HookResult.allow()


@register_hook("confidence_dispute", priority=8)
def check_confidence_dispute(data: dict, state: SessionState) -> HookResult:
    """Handle false positive disputes for confidence reducers."""
    prompt = data.get("prompt", "")
    if not prompt:
        return HookResult.allow()
    is_dispute, reducer_name, reason = detect_dispute_in_prompt(prompt)
    if not is_dispute:
        return HookResult.allow()
    if not reducer_name:
        recent = get_recent_reductions(state, turns=3)
        if len(recent) == 1:
            reducer_name = recent[0]
        elif recent:
            return HookResult.allow(
                f" **Which reducer?** Multiple fired recently:\n"
                f"  {', '.join(recent)}\n"
                f"Say `FP: <reducer_name>` to specify."
            )
        else:
            return HookResult.allow(
                " No recent confidence reductions to dispute.\n"
                "Use `FP: <reducer_name>` to specify which reducer."
            )
    old_confidence = state.confidence
    restore_amount, message = dispute_reducer(state, reducer_name, reason)
    if restore_amount > 0:
        update_confidence(state, restore_amount, f"FP:{reducer_name}")
        change_msg = format_confidence_change(
            old_confidence, state.confidence, f"(FP: {reducer_name})"
        )
        return HookResult.allow(f"{message}\n{change_msg}")
    return HookResult.allow(message)


@register_hook("verified_library_unlock", priority=9)
def check_verified_library(data: dict, state: SessionState) -> HookResult:
    """Unlock research_gate when user says VERIFIED."""
    from session_state import track_library_researched

    prompt = data.get("prompt", "").strip()
    if not prompt:
        return HookResult.allow()
    if not re.search(r"\bverified\b", prompt, re.IGNORECASE):
        return HookResult.allow()
    blocked_libs = state.get("research_gate_blocked_libs", [])
    if not blocked_libs:
        return HookResult.allow()
    for lib in blocked_libs:
        track_library_researched(state, lib)
    state.set("research_gate_blocked_libs", [])
    return HookResult.allow(
        f" **VERIFIED**: Marked as researched: {', '.join(blocked_libs)}\n"
        f"Research gate unlocked for these libraries."
    )
</file>

<file path="_prompt_registry.py">
"""
Shared hook registry for UserPromptSubmit hooks.

Hooks register via @register_hook(name, priority) decorator.
Lower priority = runs first.
"""

import _lib_path  # noqa: F401
import os
from typing import Callable

from session_state import SessionState
from _hook_result import HookResult

# Format: (name, check_function, priority)
HOOKS: list[tuple[str, Callable[[dict, SessionState], HookResult], int]] = []


def register_hook(name: str, priority: int = 50):
    """Decorator to register a hook check function.

    Hooks can be disabled via environment variable:
        CLAUDE_HOOK_DISABLE_<NAME>=1

    Example:
        CLAUDE_HOOK_DISABLE_GOAL_ANCHOR=1 claude
    """

    def decorator(func: Callable[[dict, SessionState], HookResult]):
        # Check if hook is disabled via environment variable
        env_key = f"CLAUDE_HOOK_DISABLE_{name.upper()}"
        if os.environ.get(env_key, "0") == "1":
            return func  # Skip registration
        HOOKS.append((name, func, priority))
        return func

    return decorator
</file>

<file path="_prompt_suggestions.py">
"""
Suggestion hooks for UserPromptSubmit (priority 72-95).

Hooks that provide suggestions and guidance:
   2 beads_periodic_sync   - Periodic background beads sync
  70 complexity_assessment - BMAD-style complexity detection (Path B)
  71 advisor_context       - Persona-flavored advisory (Path C)
  72 self_heal_diagnostic  - Diagnostic guidance for self-heal mode
  75 proactive_nudge       - Actionable suggestions from state
  80 ops_nudge             - Suggest ops tools based on patterns
  81 agent_suggestion      - Suggest Task agents based on prompt patterns
  82 skill_suggestion      - Suggest Skills based on prompt patterns
  85 ops_awareness         - Fallback ops script reminders
  86 ops_audit_reminder    - Periodic ops tool usage audit
  88 intent_classifier     - ML-based intent classification
  89 expert_probe          - Force probing questions
  89 pal_mandate           - PAL tool mandates based on state
  90 resource_pointer      - Surface relevant resources
  91 work_patterns         - Inject work behavior patterns
  93 quality_signals       - Pattern smells and context decay
  95 response_format       - Structured response requirements
"""

import json
import re
import time
from pathlib import Path

from _prompt_registry import register_hook
from _hook_result import HookResult
from session_state import SessionState
from context_builder import extract_keywords

# Path constants
SCRIPT_DIR = Path(__file__).parent
CLAUDE_DIR = SCRIPT_DIR.parent
MEMORY_DIR = CLAUDE_DIR / "memory"

# Try to import intent classifier
try:
    from _intent_classifier import classify_intent

    INTENT_CLASSIFIER_AVAILABLE = True
except ImportError:
    INTENT_CLASSIFIER_AVAILABLE = False
    classify_intent = None

# Try to import complexity detector (Path B - BMAD-inspired)
try:
    import _lib_path  # noqa: F401 - Sets up sys.path for lib imports

    from _complexity import assess_complexity, get_complexity_context_injection

    COMPLEXITY_AVAILABLE = True
except ImportError:
    COMPLEXITY_AVAILABLE = False
    assess_complexity = None
    get_complexity_context_injection = None

# Try to import advisory personas (Path C - BMAD-inspired)
try:
    from _advisors import (
        detect_advisor_context,
        get_advisory_context_injection,
        format_advisory,
        ADVISORS,
    )

    ADVISORS_AVAILABLE = True
except ImportError:
    ADVISORS_AVAILABLE = False
    detect_advisor_context = None
    get_advisory_context_injection = None
    format_advisory = None
    ADVISORS = {}

# Try to import PAL mandates
try:
    from _pal_mandates import get_mandate, check_keyword_mandate

    PAL_MANDATES_AVAILABLE = True
except ImportError:
    PAL_MANDATES_AVAILABLE = False
    get_mandate = None
    check_keyword_mandate = None

# Try to import ops tool stats
try:
    from _ops_stats import get_unused_ops_tools, get_ops_tool_stats
except ImportError:

    def get_unused_ops_tools(days_threshold: int = 7) -> list[str]:
        return []

    def get_ops_tool_stats() -> dict:
        return {}


# =============================================================================
# BEADS PERIODIC SYNC (priority 2)
# =============================================================================

BEADS_PERIODIC_SYNC_FILE = MEMORY_DIR / "beads_periodic_sync.json"
BEADS_PERIODIC_SYNC_SECONDS = 600  # 10 minutes


@register_hook("beads_periodic_sync", priority=2)
def check_beads_periodic_sync(data: dict, state: SessionState) -> HookResult:
    """Periodically sync beads in background (every 10 minutes)."""
    import subprocess
    import shutil

    # Check cooldown - don't sync too frequently
    try:
        if BEADS_PERIODIC_SYNC_FILE.exists():
            sync_data = json.loads(BEADS_PERIODIC_SYNC_FILE.read_text())
            if time.time() - sync_data.get("last", 0) < BEADS_PERIODIC_SYNC_SECONDS:
                return HookResult.allow()
    except (json.JSONDecodeError, IOError):
        pass

    # Check if bd command exists
    bd_path = shutil.which("bd")
    if not bd_path:
        return HookResult.allow()

    # Check if .beads directory exists
    beads_dir = Path.cwd() / ".beads"
    if not beads_dir.exists():
        beads_dir = Path.home() / ".claude" / ".beads"
        if not beads_dir.exists():
            return HookResult.allow()

    # Run bd sync in background (non-blocking)
    try:
        subprocess.Popen(
            [bd_path, "sync"],
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL,
            start_new_session=True,
        )

        # Update sync timestamp
        BEADS_PERIODIC_SYNC_FILE.parent.mkdir(parents=True, exist_ok=True)
        BEADS_PERIODIC_SYNC_FILE.write_text(json.dumps({"last": time.time()}))
    except (OSError, IOError):
        pass

    return HookResult.allow()


# =============================================================================
# COMPLEXITY ASSESSMENT (priority 70) - Path B: BMAD-inspired
# =============================================================================


@register_hook("complexity_assessment", priority=70)
def check_complexity_assessment(data: dict, state: SessionState) -> HookResult:
    """Assess task complexity to tune hook verbosity (BMAD-inspired)."""
    if not COMPLEXITY_AVAILABLE or assess_complexity is None:
        return HookResult.allow()

    prompt = data.get("prompt", "")
    if not prompt or len(prompt) < 30:
        return HookResult.allow()

    # Skip trivial prompts
    if re.match(r"^(yes|no|ok|hi|hello|thanks|commit|push|/\w+)\b", prompt.lower()):
        return HookResult.allow()

    # Gather context
    context = {
        "consecutive_failures": getattr(state, "consecutive_failures", 0),
        "turn_count": getattr(state, "turn_count", 0),
    }

    # Assess complexity
    complexity = assess_complexity(prompt, context=context)

    # Store in state for other hooks to use
    state.set("task_complexity", complexity.level)
    state.set("task_complexity_score", complexity.score)

    # Only inject context for complex tasks (avoid noise for simple tasks)
    injection = get_complexity_context_injection(complexity)
    if injection:
        return HookResult.allow(injection)

    return HookResult.allow()


# =============================================================================
# ADVISOR CONTEXT (priority 71) - Path C: BMAD-inspired
# =============================================================================


@register_hook("advisor_context", priority=71)
def check_advisor_context(data: dict, state: SessionState) -> HookResult:
    """Inject persona-flavored advisory context (BMAD-inspired)."""
    if not ADVISORS_AVAILABLE or detect_advisor_context is None:
        return HookResult.allow()

    prompt = data.get("prompt", "")
    if not prompt or len(prompt) < 30:
        return HookResult.allow()

    # Skip trivial prompts
    if re.match(r"^(yes|no|ok|hi|hello|thanks|commit|push|/\w+)\b", prompt.lower()):
        return HookResult.allow()

    # Only show advisors for complex tasks (use complexity from previous hook)
    complexity_level = state.get("task_complexity", "standard")
    if complexity_level == "trivial":
        return HookResult.allow()

    # Detect relevant advisors
    advisors = detect_advisor_context(prompt)
    if not advisors:
        return HookResult.allow()

    # Store for other hooks
    state.set("active_advisors", advisors)

    # Generate injection (only for complex tasks)
    if complexity_level == "complex":
        injection = get_advisory_context_injection(advisors, prompt)
        if injection:
            return HookResult.allow(injection)

    return HookResult.allow()


# =============================================================================
# SELF-HEAL DIAGNOSTIC (priority 72)
# =============================================================================


@register_hook("self_heal_diagnostic", priority=72)
def check_self_heal_diagnostic(data: dict, state: SessionState) -> HookResult:
    """Inject diagnostic guidance when self-heal mode is active."""
    if not getattr(state, "self_heal_required", False):
        return HookResult.allow()

    target = getattr(state, "self_heal_target", "unknown")
    error = getattr(state, "self_heal_error", "unknown error")
    attempts = getattr(state, "self_heal_attempts", 0)
    max_attempts = getattr(state, "self_heal_max_attempts", 3)

    # Build diagnostic commands based on error type
    diagnostics = []
    diagnostics.append("ruff check ~/.claude/hooks/  # Lint all hooks")

    # Path-specific diagnostics
    if "hook" in target.lower() or "runner" in target.lower():
        diagnostics.append(
            "~/.claude/.venv/bin/python -c \"import sys; sys.path.insert(0, '/home/jinx/.claude/hooks'); import pre_tool_use_runner\"  # Test import"
        )
    if "session_state" in target.lower() or "lib" in target.lower():
        diagnostics.append(
            '~/.claude/.venv/bin/python -c "from session_state import load_state; print(load_state())"  # Test state'
        )

    # Error-specific diagnostics
    if "syntax" in error.lower():
        diagnostics.append(
            f"~/.claude/.venv/bin/python -m py_compile {target}  # Check syntax"
        )
    if "import" in error.lower() or "module" in error.lower():
        diagnostics.append("ls -la ~/.claude/hooks/*.py | head -10  # List hook files")
        diagnostics.append(
            "grep -l 'import.*Error' ~/.claude/hooks/*.py  # Find import issues"
        )

    lines = [
        f" **SELF-HEAL MODE ACTIVE** (attempt {attempts}/{max_attempts})",
        f"**Target:** `{target}`",
        f"**Error:** {error[:100]}",
        "",
        "**Diagnostic commands:**",
    ]
    lines.extend(f"```bash\n{cmd}\n```" for cmd in diagnostics[:3])
    lines.append("")
    lines.append(
        "Fix the framework error before continuing other work. Say **SUDO** to bypass."
    )

    return HookResult.allow("\n".join(lines))


# =============================================================================
# PROACTIVE NUDGE (priority 75)
# =============================================================================


def _collect_proactive_suggestions(state: SessionState) -> list[str]:
    """Collect all proactive suggestions from state."""
    suggestions = []

    if state.pending_files:
        names = [Path(f).name for f in state.pending_files[:3]]
        suggestions.append(f" Mentioned but unread: {names}")

    if state.files_edited and not state.last_verify and len(state.files_edited) >= 2:
        suggestions.append(f" {len(state.files_edited)} files edited, no /verify run")

    if any(c >= 3 for c in state.edit_counts.values()) and not state.tests_run:
        suggestions.append(" Multiple edits without test run")

    if state.consecutive_failures >= 2:
        suggestions.append(
            f" {state.consecutive_failures} failures - consider different approach"
        )

    if state.pending_integration_greps:
        funcs = [p["function"] for p in state.pending_integration_greps[:2]]
        suggestions.append(f" Grep callers for: {funcs}")

    bg_tasks = getattr(state, "background_tasks", [])
    if bg_tasks:
        recent = [t for t in bg_tasks if state.turn_count - t.get("turn", 0) <= 10]
        if recent:
            types = [t.get("type", "agent")[:15] for t in recent[:2]]
            suggestions.append(
                f" Background agents running: {types} - check with `TaskOutput`"
            )

    return suggestions


@register_hook("proactive_nudge", priority=75)
def check_proactive_nudge(data: dict, state: SessionState) -> HookResult:
    """Surface actionable suggestions based on state."""
    prompt = data.get("prompt", "")
    if not prompt or len(prompt) < 10 or prompt.startswith("/") or state.turn_count < 5:
        return HookResult.allow()

    suggestions = _collect_proactive_suggestions(state)
    if not suggestions:
        return HookResult.allow()

    lines = [" **PROACTIVE CHECKLIST:**"]
    lines.extend(f"   {s}" for s in suggestions[:3])
    lines.append("   Act on these or consciously skip them.")
    return HookResult.allow("\n".join(lines))


# =============================================================================
# OPS NUDGE (priority 80)
# =============================================================================

_TOOL_TRIGGERS = {
    "research": {
        "patterns": [
            re.compile(
                r"(latest|current|new)\s+(docs?|documentation|api|version)",
                re.IGNORECASE,
            ),
            re.compile(r"how\s+does\s+.+\s+work", re.IGNORECASE),
        ],
        "command": 'python3 .claude/ops/research.py "<query>"',
        "reason": "Live web search for current documentation",
    },
    "probe": {
        "patterns": [
            re.compile(r"what\s+(methods?|attributes?)", re.IGNORECASE),
            re.compile(
                r"(inspect|introspect)\s+(the\s+)?(api|object|class)", re.IGNORECASE
            ),
        ],
        "command": 'python3 .claude/ops/probe.py "<object_path>"',
        "reason": "Runtime introspection - see actual API before coding",
    },
    "xray": {
        "patterns": [
            re.compile(
                r"(find|list|show)\s+(all\s+)?(class|function)s?\s+in", re.IGNORECASE
            ),
            re.compile(r"ast\s+(analysis|search)", re.IGNORECASE),
        ],
        "command": "python3 .claude/ops/xray.py --type <class|function> --name <Name>",
        "reason": "AST-based structural code search",
    },
    "think": {
        "patterns": [
            re.compile(r"(complex|tricky)\s+(problem|issue|bug)", re.IGNORECASE),
            re.compile(r"(break\s+down|decompose)", re.IGNORECASE),
            re.compile(r"i('m| am)\s+(stuck|confused)", re.IGNORECASE),
        ],
        "command": 'python3 .claude/ops/think.py "<problem>"',
        "reason": "Structured problem decomposition",
    },
    "council": {
        "patterns": [
            re.compile(r"(major|big)\s+(decision|choice)", re.IGNORECASE),
            re.compile(r"(pros\s+and\s+cons|trade-?offs?)", re.IGNORECASE),
        ],
        "command": 'python3 .claude/ops/council.py "<proposal>"',
        "reason": "Multi-perspective analysis (Judge+Critic+Skeptic)",
    },
    "audit": {
        "patterns": [
            re.compile(r"(security|vulnerability)\s+(check|scan|audit)", re.IGNORECASE),
            re.compile(r"(safe|secure)\s+to\s+(deploy|commit)", re.IGNORECASE),
        ],
        "command": "python3 .claude/ops/audit.py <file>",
        "reason": "Security and code quality audit",
    },
    "void": {
        "patterns": [
            re.compile(r"(stub|todo|fixme|incomplete)", re.IGNORECASE),
            re.compile(r"(missing|forgot)\s+(implementation|handler)", re.IGNORECASE),
        ],
        "command": "python3 .claude/ops/void.py <file>",
        "reason": "Completeness check - finds stubs and gaps",
    },
    "orchestrate": {
        "patterns": [
            re.compile(
                r"(process|analyze|scan)\s+(all|many|multiple)\s+files?", re.IGNORECASE
            ),
            re.compile(r"(batch|bulk|aggregate)\s+(process|operation)", re.IGNORECASE),
        ],
        "command": 'python3 .claude/ops/orchestrate.py "<task description>"',
        "reason": "Claude API code_execution - 37% token reduction for batch tasks",
    },
    # PAL MCP tools
    "pal_thinkdeep": {
        "patterns": [
            re.compile(r"(uncertain|not\s+sure)\s+(how|what|why)", re.IGNORECASE),
            re.compile(
                r"need\s+(to\s+)?(investigate|analyze|understand)", re.IGNORECASE
            ),
            re.compile(
                r"(complex|difficult)\s+(issue|problem|architecture)", re.IGNORECASE
            ),
            re.compile(r"what\s+can\s+we", re.IGNORECASE),
            re.compile(r"find\s+out\s+(why|how|what)", re.IGNORECASE),
        ],
        "command": "mcp__pal__thinkdeep",
        "reason": "PAL MCP: Multi-stage investigation with external LLM",
    },
    "pal_debug": {
        "patterns": [
            re.compile(
                r"(mysterious|strange|weird)\s+(bug|error|behavior)", re.IGNORECASE
            ),
            re.compile(r"(root\s+cause|why\s+is\s+this\s+happening)", re.IGNORECASE),
            re.compile(r"(debugging|troubleshoot)\s+(help|assistance)", re.IGNORECASE),
        ],
        "command": "mcp__pal__debug",
        "reason": "PAL MCP: Systematic debugging with hypothesis testing",
    },
    "pal_consensus": {
        "patterns": [
            re.compile(
                r"(multiple|different)\s+(perspectives?|opinions?|views?)",
                re.IGNORECASE,
            ),
            re.compile(r"(second\s+opinion|another\s+view)", re.IGNORECASE),
            re.compile(r"(consensus|agreement)\s+on", re.IGNORECASE),
            re.compile(r"what\s+is\s+the\s+best", re.IGNORECASE),
        ],
        "command": "mcp__pal__consensus",
        "reason": "PAL MCP: Multi-model consensus for decisions",
    },
    "pal_challenge": {
        "patterns": [
            re.compile(r"(am\s+i|are\s+we)\s+(right|wrong|correct)", re.IGNORECASE),
            re.compile(
                r"(challenge|question)\s+(this|my)\s+(assumption|approach)",
                re.IGNORECASE,
            ),
            re.compile(r"(sanity\s+check|reality\s+check)", re.IGNORECASE),
            re.compile(r"(can|should)\s+we\b", re.IGNORECASE),
        ],
        "command": "mcp__pal__challenge",
        "reason": "PAL MCP: Force critical thinking on assumptions",
    },
    "pal_codereview": {
        "patterns": [
            re.compile(r"\banti[- ]?patterns?\b", re.IGNORECASE),
            re.compile(r"\btechnical\s+debt\b", re.IGNORECASE),
            re.compile(r"\bcode\s+(smell|quality|review)\b", re.IGNORECASE),
        ],
        "command": "mcp__pal__codereview",
        "reason": "PAL MCP: Expert code review for quality issues",
    },
    "pal_apilookup": {
        "patterns": [
            re.compile(r"(latest|current|updated)\s+(api|sdk|docs?)", re.IGNORECASE),
            re.compile(r"(breaking\s+changes?|deprecat)", re.IGNORECASE),
            re.compile(r"(migration\s+guide|upgrade)", re.IGNORECASE),
            re.compile(
                r"\bresearch\b.*\b(api|library|framework|docs?)\b", re.IGNORECASE
            ),
            re.compile(r"get\s+the\s+latest", re.IGNORECASE),
        ],
        "command": "mcp__pal__apilookup",
        "reason": "PAL MCP: Current API/SDK documentation lookup",
    },
    "pal_chat": {
        "patterns": [
            re.compile(r"^\s*research\b", re.IGNORECASE),
            re.compile(r"\bresearch\s+(this|how|what|why)", re.IGNORECASE),
            re.compile(r"search\s+online", re.IGNORECASE),
        ],
        "command": "mcp__pal__chat",
        "reason": "PAL MCP: General consultation with external LLM",
    },
    # Crawl4AI MCP
    "crawl4ai": {
        "patterns": [
            re.compile(
                r"(scrape|crawl|fetch|extract)\s+.*(web|page|site|url)", re.IGNORECASE
            ),
            re.compile(
                r"(get|read|pull)\s+.*(from\s+)?(url|website|page|article)",
                re.IGNORECASE,
            ),
            re.compile(
                r"(content|data|text)\s+(from|of)\s+.*(url|site|page)", re.IGNORECASE
            ),
            re.compile(r"https?://", re.IGNORECASE),
            re.compile(r"\burl\b.*\b(content|fetch|get|read)\b", re.IGNORECASE),
            re.compile(
                r"(read|fetch|get)\s+.*(docs?|documentation|readme)", re.IGNORECASE
            ),
            re.compile(r"(article|blog|post)\s+(content|text)", re.IGNORECASE),
            re.compile(
                r"(bypass|avoid|get\s+around)\s+.*(guard|block|protection|captcha)",
                re.IGNORECASE,
            ),
            re.compile(r"(cloudflare|bot\s+detect|anti-bot)", re.IGNORECASE),
            re.compile(r"(web|online)\s+(data|content|info)", re.IGNORECASE),
            re.compile(r"(download|retrieve)\s+.*(page|content)", re.IGNORECASE),
            re.compile(
                r"(check|look\s+at|see)\s+(what|how)\s+.*(site|page|url)", re.IGNORECASE
            ),
        ],
        "command": "mcp__crawl4ai__crawl (single URL) or mcp__crawl4ai__search (discover URLs)",
        "reason": " Crawl4AI: JS rendering + bot bypass - BEST tool for web content retrieval",
    },
}


# =============================================================================
# AGENT SUGGESTION (priority 81)
# =============================================================================

_AGENT_TRIGGERS = {
    # Haiku agents (fast/cheap)
    "scout": {
        "patterns": [
            re.compile(r"(where|find|locate)\s+(is|are|the)\s+\w+", re.I),
            re.compile(r"(which\s+file|what\s+file)", re.I),
        ],
        "model": "haiku",
        "desc": "Find files/symbols when you don't know where",
    },
    "config-auditor": {
        "patterns": [
            re.compile(r"(env|environment)\s+(var|variable|config)", re.I),
            re.compile(r"(missing|check)\s+.*(config|\.env)", re.I),
            re.compile(r"config\s+(drift|mismatch|consistency)", re.I),
        ],
        "model": "haiku",
        "desc": "Env var consistency, config drift detection",
    },
    "log-analyzer": {
        "patterns": [
            re.compile(r"(parse|analyze|check)\s+.*(log|logs)", re.I),
            re.compile(r"(error|exception)\s+(pattern|spike|frequency)", re.I),
            re.compile(r"(log|logs)\s+.*(pattern|trace|correlat)", re.I),
        ],
        "model": "haiku",
        "desc": "Parse logs, find error patterns, correlate events",
    },
    "dependency-mapper": {
        "patterns": [
            re.compile(r"(circular|cyclic)\s+(import|depend)", re.I),
            re.compile(r"(import|dependency)\s+(graph|tree|map)", re.I),
            re.compile(r"(coupling|afferent|efferent)", re.I),
        ],
        "model": "haiku",
        "desc": "Import graphs, circular deps, coupling analysis",
    },
    "bundle-analyzer": {
        "patterns": [
            re.compile(r"(bundle|webpack|vite)\s+(size|bloat|large)", re.I),
            re.compile(r"(tree.?shak|code.?split)", re.I),
            re.compile(r"(heavy|large)\s+(import|package|depend)", re.I),
        ],
        "model": "haiku",
        "desc": "JS bundle size, heavy imports, code splitting",
    },
    "i18n-checker": {
        "patterns": [
            re.compile(r"(hardcoded|missing)\s+(string|translation)", re.I),
            re.compile(r"(i18n|internationali|locali)", re.I),
            re.compile(r"(rtl|right.to.left|translation)", re.I),
        ],
        "model": "haiku",
        "desc": "Hardcoded strings, missing translations",
    },
    "a11y-auditor": {
        "patterns": [
            re.compile(r"(a11y|accessibility|wcag)", re.I),
            re.compile(r"(aria|screen.?reader|keyboard\s+nav)", re.I),
            re.compile(r"(alt\s+text|missing\s+alt)", re.I),
        ],
        "model": "haiku",
        "desc": "WCAG violations, ARIA issues, accessibility",
    },
    "license-scanner": {
        "patterns": [
            re.compile(r"(license|licensing)\s+(scan|check|audit|compliance)", re.I),
            re.compile(r"(gpl|copyleft|mit|apache)\s+(depend|issue)", re.I),
        ],
        "model": "haiku",
        "desc": "Dependency license compliance",
    },
    "docker-analyzer": {
        "patterns": [
            re.compile(r"(docker|dockerfile)\s+(optim|security|size|layer)", re.I),
            re.compile(r"(container|image)\s+(bloat|large|security)", re.I),
        ],
        "model": "haiku",
        "desc": "Dockerfile security, size optimization",
    },
    "ci-optimizer": {
        "patterns": [
            re.compile(r"(ci|pipeline|workflow)\s+(slow|optim|cache|parallel)", re.I),
            re.compile(r"(github\s+actions|gitlab\s+ci|circleci)\s+(slow|fast)", re.I),
        ],
        "model": "haiku",
        "desc": "Pipeline speed, caching, parallelization",
    },
    "env-debugger": {
        "patterns": [
            re.compile(r"works\s+on\s+my\s+machine", re.I),
            re.compile(r"(version|node|python)\s+(mismatch|wrong|different)", re.I),
            re.compile(r"(path|env|environment)\s+(issue|problem|wrong)", re.I),
        ],
        "model": "haiku",
        "desc": "Environment debugging, version mismatches",
    },
    # Sonnet agents (accuracy critical)
    "test-analyzer": {
        "patterns": [
            re.compile(r"(test|coverage)\s+(gap|missing|flaky)", re.I),
            re.compile(r"(flaky|unstable|intermittent)\s+test", re.I),
            re.compile(r"(test|spec)\s+(quality|health)", re.I),
        ],
        "model": "sonnet",
        "desc": "Coverage gaps, flaky tests, test quality",
    },
    "perf-profiler": {
        "patterns": [
            re.compile(r"(n\+1|n \+ 1)\s+(query|problem)", re.I),
            re.compile(r"(memory\s+leak|performance)\s+(issue|problem)", re.I),
            re.compile(r"(slow|expensive)\s+(loop|query|function)", re.I),
        ],
        "model": "sonnet",
        "desc": "N+1 queries, memory leaks, perf anti-patterns",
    },
    "git-archeologist": {
        "patterns": [
            re.compile(r"(when|who)\s+(did|made|introduced|changed)", re.I),
            re.compile(r"(git\s+)?(blame|bisect|history)", re.I),
            re.compile(r"(regression|broke|when\s+did)", re.I),
        ],
        "model": "sonnet",
        "desc": "Blame, bisect, history investigation",
    },
    "error-tracer": {
        "patterns": [
            re.compile(r"(unhandled|uncaught)\s+(error|exception)", re.I),
            re.compile(r"(error|exception)\s+(path|propagat|flow|boundary)", re.I),
            re.compile(r"(swallow|silent)\s+(error|fail)", re.I),
        ],
        "model": "sonnet",
        "desc": "Exception paths, error boundaries, unhandled errors",
    },
    "refactor-planner": {
        "patterns": [
            re.compile(
                r"(refactor|extract|inline)\s+(plan|opportunit|candidate)", re.I
            ),
            re.compile(r"(code\s+smell|technical\s+debt)\s+(fix|address)", re.I),
            re.compile(r"(safe|incremental)\s+refactor", re.I),
        ],
        "model": "sonnet",
        "desc": "Safe refactoring sequences, extract candidates",
    },
    "schema-validator": {
        "patterns": [
            re.compile(r"(schema|db|database)\s+(mismatch|drift|validat)", re.I),
            re.compile(r"(orm|model)\s+.*(schema|column|type)", re.I),
            re.compile(r"(migration)\s+(safe|risk|issue)", re.I),
        ],
        "model": "sonnet",
        "desc": "DB-code mismatches, migration safety",
    },
    "state-mapper": {
        "patterns": [
            re.compile(r"(redux|zustand|mobx|state)\s+(flow|mutation|map)", re.I),
            re.compile(r"(state\s+management|data\s+flow)\s+(trace|debug)", re.I),
        ],
        "model": "sonnet",
        "desc": "Redux/Zustand flows, state mutations",
    },
    "migration-planner": {
        "patterns": [
            re.compile(r"(data|schema|code)\s+migration\s+(plan|strateg)", re.I),
            re.compile(r"(rollback|zero.?downtime)\s+(plan|strateg)", re.I),
            re.compile(r"(safe|incremental)\s+migration", re.I),
        ],
        "model": "sonnet",
        "desc": "Data/schema migrations with rollback plans",
    },
    "type-migrator": {
        "patterns": [
            re.compile(r"(js|javascript)\s+(to|)\s+(ts|typescript)", re.I),
            re.compile(r"(add|migrate)\s+.*(type|typescript)", re.I),
            re.compile(r"(gradual|incremental)\s+typing", re.I),
        ],
        "model": "sonnet",
        "desc": "JSTS migration, gradual typing adoption",
    },
}


@register_hook("agent_suggestion", priority=81)
def check_agent_suggestion(data: dict, state: SessionState) -> HookResult:
    """Suggest Task agents based on prompt patterns."""
    from _cooldown import check_and_reset_cooldown

    # 3-minute cooldown to prevent suggestion spam
    if not check_and_reset_cooldown("agent_suggestion", cooldown_seconds=180):
        return HookResult.allow()

    prompt = data.get("prompt", "")
    if not prompt or len(prompt) < 20:
        return HookResult.allow()

    prompt_lower = prompt.lower()
    matches = []
    for agent_name, config in _AGENT_TRIGGERS.items():
        for pattern in config["patterns"]:
            if pattern.search(prompt_lower):
                matches.append((agent_name, config))
                break
        if len(matches) >= 2:
            break

    if not matches:
        return HookResult.allow()

    suggestions = []
    for agent_name, config in matches:
        model_badge = "" if config["model"] == "haiku" else ""
        suggestions.append(
            f"{model_badge} **{agent_name}**: {config['desc']}\n"
            f'    `Task(subagent_type="{agent_name}", prompt="...")`'
        )

    return HookResult.allow(" TASK AGENTS AVAILABLE:\n" + "\n\n".join(suggestions))


# =============================================================================
# SKILL SUGGESTION (priority 82)
# =============================================================================

_SKILL_TRIGGERS = {
    "debugging": {
        "patterns": [
            re.compile(r"(debug|fix)\s+(this|the|an?)\s+(error|bug|issue)", re.I),
            re.compile(r"stack\s*trace", re.I),
            re.compile(r"(why|what).*(fail|crash|broken|not\s+work)", re.I),
            re.compile(r"(exception|error\s+message|runtime\s+error)", re.I),
            re.compile(r"(troubleshoot|diagnose|root\s+cause)", re.I),
        ],
        "desc": "Debug errors, stack traces, root cause analysis",
        "invoke": 'Skill(skill="debugging")',
    },
    "testing": {
        "patterns": [
            re.compile(r"(run|write|add)\s+tests?", re.I),
            re.compile(r"(pytest|jest|vitest|mocha)", re.I),
            re.compile(r"test\s+(coverage|driven|tdd)", re.I),
            re.compile(r"(mock|fixture|assertion)", re.I),
            re.compile(r"(unit|integration)\s+test", re.I),
        ],
        "desc": "Run/write tests, pytest, jest, TDD, coverage",
        "invoke": 'Skill(skill="testing")',
    },
    "browser-automation": {
        "patterns": [
            re.compile(r"(screenshot|headless|browser\s+test)", re.I),
            re.compile(r"(devtools|chrome\s+debug|cdp)", re.I),
            re.compile(r"(scrape|crawl)\s+(web|page|site)", re.I),
            re.compile(r"(dom|element|selector)\s+(inspect|check)", re.I),
            re.compile(r"(playwright|puppeteer|selenium)", re.I),
            re.compile(r"(e2e|end.to.end)\s+test", re.I),
        ],
        "desc": "Browser testing, DevTools, screenshots, scraping",
        "invoke": 'Skill(skill="browser-automation")',
    },
    "code-quality": {
        "patterns": [
            re.compile(r"(review|audit)\s+(this|the|my)?\s*code", re.I),
            re.compile(r"(security|vulnerabilit|owasp)", re.I),
            re.compile(r"(code\s+smell|anti.?pattern|technical\s+debt)", re.I),
            re.compile(r"before\s+(I\s+)?(commit|deploy|merge)", re.I),
            re.compile(r"(pr|pull\s+request)\s+review", re.I),
        ],
        "desc": "Code review, security audit, anti-patterns",
        "invoke": 'Skill(skill="code-quality")',
    },
    "completeness-checking": {
        "patterns": [
            re.compile(r"(find|check).*(gaps?|missing|incomplete)", re.I),
            re.compile(r"(stub|placeholder|todo)\s+(impl|code)", re.I),
            re.compile(r"(void|completeness)\s+check", re.I),
            re.compile(r"(dead|unused)\s+code", re.I),
            re.compile(r"notimplementederror", re.I),
        ],
        "desc": "Find gaps, stubs, missing implementations, dead code",
        "invoke": 'Skill(skill="completeness-checking")',
    },
    "frontend-design": {
        "patterns": [
            re.compile(r"(build|create|design)\s+(a\s+)?(ui|interface|page)", re.I),
            re.compile(r"(react|vue|svelte|nextjs)\s+(component|page)", re.I),
            re.compile(r"(css|tailwind|styled|aesthetic)", re.I),
            re.compile(r"(landing|dashboard|form|modal)\s+(page|design)", re.I),
            re.compile(r"(responsive|mobile)\s+(design|layout)", re.I),
        ],
        "desc": "Distinctive, production-grade frontend interfaces",
        "invoke": 'Skill(skill="frontend-design")',
    },
    "git-workflow": {
        "patterns": [
            re.compile(r"(commit|push|merge|rebase)\s+(this|the|my)?", re.I),
            re.compile(r"(create|open)\s+(a\s+)?(pr|pull\s+request)", re.I),
            re.compile(r"(git\s+)(blame|log|diff|status)", re.I),
            re.compile(r"(resolve|fix)\s+(merge\s+)?conflict", re.I),
            re.compile(r"(undo|revert|reset)\s+(commit|change)", re.I),
        ],
        "desc": "Git operations, commits, PRs, conflict resolution",
        "invoke": 'Skill(skill="git-workflow")',
    },
    "memory-workflow": {
        "patterns": [
            re.compile(r"(remember|recall|store)\s+(this|for\s+later)", re.I),
            re.compile(r"(what|did)\s+(we|I)\s+(do|decide)\s+(before|last)", re.I),
            re.compile(r"(lesson|decision).*(learned|made)", re.I),
            re.compile(r"(previous|past|old)\s+session", re.I),
            re.compile(r"(search|find)\s+(memor|past\s+work)", re.I),
        ],
        "desc": "Persistent memory, recall past work, lessons learned",
        "invoke": 'Skill(skill="memory-workflow")',
    },
    "research-docs": {
        "patterns": [
            re.compile(r"(how\s+do\s+I|what.s\s+the)\s+(use|api)", re.I),
            re.compile(r"(latest|current)\s+(version|docs|documentation)", re.I),
            re.compile(r"(look\s*up|search\s+for)\s+(doc|info)", re.I),
            re.compile(r"(api|sdk)\s+(reference|docs)", re.I),
            re.compile(r"(changelog|release\s+notes|breaking\s+change)", re.I),
        ],
        "desc": "Documentation lookup, API docs, web research",
        "invoke": 'Skill(skill="research-docs")',
    },
    "verification": {
        "patterns": [
            re.compile(r"(verify|check|confirm)\s+(this|it|the)\s+(work|exist)", re.I),
            re.compile(r"(is\s+the|does\s+the)\s+(file|port|server)", re.I),
            re.compile(r"(reality|sanity)\s+check", re.I),
            re.compile(r"(prove|assert|ensure)\s+(it|that)", re.I),
            re.compile(r"(did\s+it|does\s+it)\s+(work|run|succeed)", re.I),
        ],
        "desc": "Verify state, check existence, validate claims",
        "invoke": 'Skill(skill="verification")',
    },
    "hook-development": {
        "patterns": [
            re.compile(r"(create|write|add)\s+(a\s+)?hook", re.I),
            re.compile(r"(pre|post).?tool.?use", re.I),
            re.compile(r"hookresult\.(allow|deny)", re.I),
            re.compile(r"register_hook", re.I),
        ],
        "desc": "Claude Code hook development patterns",
        "invoke": 'Skill(skill="hook-development")',
    },
    "confidence-system": {
        "patterns": [
            re.compile(r"confidence\s+(system|level|zone)", re.I),
            re.compile(r"(reducer|increaser)\s+(fire|trigger)", re.I),
            re.compile(r"(false\s+positive|fp:)", re.I),
        ],
        "desc": "Confidence system mechanics and signals",
        "invoke": 'Skill(skill="confidence-system")',
    },
    "project-scaffold": {
        "patterns": [
            re.compile(r"(create|start|init)\s+(new|a)\s+(project|app)", re.I),
            re.compile(r"(scaffold|bootstrap|boilerplate)", re.I),
            re.compile(r"(set\s*up|initialize)\s+(repo|project)", re.I),
        ],
        "desc": "Create new projects, scaffold, initialize repos",
        "invoke": 'Skill(skill="project-scaffold")',
    },
    "autonomous-mode": {
        "patterns": [
            re.compile(r"(just\s+do\s+it|go\s+ahead)", re.I),
            re.compile(r"(fix\s+everything|work\s+autonomously)", re.I),
            re.compile(r"(yes\s+mode|auto\s+mode|hands\s*off)", re.I),
        ],
        "desc": "Self-directed execution, minimal guidance",
        "invoke": 'Skill(skill="autonomous-mode")',
    },
    "session-management": {
        "patterns": [
            re.compile(r"(compress|save)\s+(session|context)", re.I),
            re.compile(r"(context\s+recovery|recover\s+context)", re.I),
            re.compile(r"(blocking\s+issue|detour)", re.I),
            re.compile(r"(pick\s+up|continue)\s+where", re.I),
        ],
        "desc": "Session context, compression, blocking issues",
        "invoke": 'Skill(skill="session-management")',
    },
    "system-maintenance": {
        "patterns": [
            re.compile(r"(system|disk)\s+(health|space|cleanup)", re.I),
            re.compile(r"(housekeeping|maintenance)", re.I),
            re.compile(r"(free\s+some|clean\s+up)\s+space", re.I),
            re.compile(r"(cpu|memory)\s+usage", re.I),
        ],
        "desc": "System health, disk cleanup, performance",
        "invoke": 'Skill(skill="system-maintenance")',
    },
    "task-tracking": {
        "patterns": [
            re.compile(r"(track|create)\s+(this\s+)?task", re.I),
            re.compile(r"(what\s+needs|remaining\s+work)", re.I),
            re.compile(r"(beads?|bd)\s+(ready|list|create)", re.I),
            re.compile(r"(open|in.progress)\s+(tasks?|issues?)", re.I),
        ],
        "desc": "Beads task tracking, issues, blockers",
        "invoke": 'Skill(skill="task-tracking")',
    },
    "decision-support": {
        "patterns": [
            re.compile(r"(should\s+I|help\s+me)\s+(use|decide)", re.I),
            re.compile(r"(pros?\s+and\s+cons?|trade.?offs?)", re.I),
            re.compile(r"(compare|which)\s+(framework|library)", re.I),
            re.compile(r"(architecture|design)\s+(decision|choice)", re.I),
        ],
        "desc": "Complex decisions, multi-perspective analysis",
        "invoke": 'Skill(skill="decision-support")',
    },
    "mcp-servers": {
        "patterns": [
            re.compile(r"mcp\s+(server|tool)", re.I),
            re.compile(r"(crawl4ai|serena|repomix|pal\s+mcp)", re.I),
            re.compile(r"(which|available)\s+mcp", re.I),
        ],
        "desc": "MCP server capabilities and usage",
        "invoke": 'Skill(skill="mcp-servers")',
    },
    "external-llm": {
        "patterns": [
            re.compile(r"(ask|consult)\s+(another|external)\s+(model|ai)", re.I),
            re.compile(r"(second\s+opinion|multi.?model)", re.I),
            re.compile(r"(use|what\s+does)\s+(gpt|gemini|groq)", re.I),
        ],
        "desc": "External AI consultation, PAL tools, consensus",
        "invoke": 'Skill(skill="external-llm")',
    },
    "windows-interop": {
        "patterns": [
            re.compile(r"(windows|wsl2?)\s+(path|file|interop)", re.I),
            re.compile(r"/mnt/c/", re.I),
            re.compile(r"(winget|powershell|cmd\.exe)", re.I),
        ],
        "desc": "WSL2/Windows integration, paths, winget",
        "invoke": 'Skill(skill="windows-interop")',
    },
    "code-analysis": {
        "patterns": [
            re.compile(r"(find|where\s+is)\s+(class|function)", re.I),
            re.compile(r"(code\s+structure|ast|symbol\s+lookup)", re.I),
            re.compile(r"(who\s+calls|callers|references)", re.I),
            re.compile(r"(inspect|introspect)\s+(object|api)", re.I),
        ],
        "desc": "AST search, symbol lookup, code navigation",
        "invoke": 'Skill(skill="code-analysis")',
    },
    "implementation-planning": {
        "patterns": [
            re.compile(r"(how\s+should|best\s+way)\s+(I\s+)?implement", re.I),
            re.compile(r"(implementation|technical)\s+(plan|strategy)", re.I),
            re.compile(r"(build\s+vs?\s+buy|existing\s+solution)", re.I),
            re.compile(r"(worth\s+building|should\s+I\s+build)", re.I),
        ],
        "desc": "Implementation strategy, build vs buy",
        "invoke": 'Skill(skill="implementation-planning")',
    },
}


@register_hook("skill_suggestion", priority=82)
def check_skill_suggestion(data: dict, state: SessionState) -> HookResult:
    """Suggest Skills based on prompt patterns."""
    from _cooldown import check_and_reset_cooldown

    # 3-minute cooldown to prevent suggestion spam
    if not check_and_reset_cooldown("skill_suggestion", cooldown_seconds=180):
        return HookResult.allow()

    prompt = data.get("prompt", "")
    if not prompt or len(prompt) < 20:
        return HookResult.allow()

    prompt_lower = prompt.lower()
    matches = []
    for skill_name, config in _SKILL_TRIGGERS.items():
        for pattern in config["patterns"]:
            if pattern.search(prompt_lower):
                matches.append((skill_name, config))
                break
        if len(matches) >= 2:
            break

    if not matches:
        return HookResult.allow()

    suggestions = []
    for skill_name, config in matches:
        suggestions.append(
            f" **{skill_name}**: {config['desc']}\n    `{config['invoke']}`"
        )

    return HookResult.allow(" SKILLS AVAILABLE:\n" + "\n\n".join(suggestions))


@register_hook("ops_nudge", priority=80)
def check_ops_nudge(data: dict, state: SessionState) -> HookResult:
    """Suggest ops tools based on prompt patterns."""
    prompt = data.get("prompt", "")
    if not prompt or len(prompt) < 10:
        return HookResult.allow()

    prompt_lower = prompt.lower()
    matches = []
    for tool_name, config in _TOOL_TRIGGERS.items():
        for pattern in config["patterns"]:
            if pattern.search(prompt_lower):
                matches.append((tool_name, config))
                break
        if len(matches) >= 3:
            break

    if not matches:
        return HookResult.allow()

    suggestions = []
    for tool_name, config in matches:
        display_name = tool_name.replace("_", " ").upper()
        suggestions.append(
            f" {display_name}: {config['reason']}\n    {config['command']}"
        )

    return HookResult.allow("OPS TOOLS AVAILABLE:\n" + "\n\n".join(suggestions))


# =============================================================================
# OPS AWARENESS (priority 85)
# =============================================================================

_OPS_SCRIPTS = {
    "research": (
        [
            re.compile(r"look up", re.I),
            re.compile(r"find docs", re.I),
            re.compile(r"documentation", re.I),
        ],
        "Web search via Tavily API",
    ),
    "probe": (
        [
            re.compile(r"inspect.*object", re.I),
            re.compile(r"what methods", re.I),
            re.compile(r"api.*signature", re.I),
        ],
        "Runtime introspection",
    ),
    "xray": (
        [
            re.compile(r"find.*class", re.I),
            re.compile(r"find.*function", re.I),
            re.compile(r"code structure", re.I),
        ],
        "AST-based code search",
    ),
    "audit": (
        [re.compile(r"security.*check", re.I), re.compile(r"vulnerability", re.I)],
        "Security audit",
    ),
    "void": (
        [
            re.compile(r"find.*stubs", re.I),
            re.compile(r"todo.*code", re.I),
            re.compile(r"incomplete", re.I),
        ],
        "Find stubs and TODOs",
    ),
    "think": (
        [
            re.compile(r"break.*down", re.I),
            re.compile(r"decompose", re.I),
            re.compile(r"complex.*problem", re.I),
        ],
        "Problem decomposition",
    ),
    "verify": (
        [
            re.compile(r"check.*exists", re.I),
            re.compile(r"verify.*file", re.I),
            re.compile(r"confirm.*works", re.I),
        ],
        "Reality checks",
    ),
    "remember": (
        [re.compile(r"save.*lesson", re.I), re.compile(r"remember.*this", re.I)],
        "Persistent memory",
    ),
    "spark": (
        [re.compile(r"recall.*about", re.I), re.compile(r"what.*learned", re.I)],
        "Retrieve memories",
    ),
}


@register_hook("ops_awareness", priority=85)
def check_ops_awareness(data: dict, state: SessionState) -> HookResult:
    """Remind about existing ops scripts (fallback)."""
    prompt = data.get("prompt", "")
    if not prompt or len(prompt) < 10:
        return HookResult.allow()

    prompt_lower = prompt.lower()
    matches = []
    for script, (triggers, desc) in _OPS_SCRIPTS.items():
        for pattern in triggers:
            if pattern.search(prompt_lower):
                matches.append((script, desc))
                break
        if len(matches) >= 3:
            break

    if not matches:
        return HookResult.allow()

    suggestions = "\n".join([f"   - `{s}`: {d}" for s, d in matches])
    return HookResult.allow(f" OPS SCRIPTS AVAILABLE:\n{suggestions}")


# =============================================================================
# OPS AUDIT REMINDER (priority 86)
# =============================================================================


@register_hook("ops_audit_reminder", priority=86)
def check_ops_audit_reminder(data: dict, state: SessionState) -> HookResult:
    """Periodic reminder about ops tool usage and unused tools."""
    from _cooldown import check_and_reset_cooldown

    # Only run every 3 hours
    if not check_and_reset_cooldown("ops_audit_reminder"):
        return HookResult.allow()

    parts = []

    # Check for unused tools (7 day threshold)
    unused = get_unused_ops_tools(days_threshold=7)
    if unused and len(unused) >= 5:
        sample = unused[:5]
        parts.append(
            f" **OPS TOOLS**: {len(unused)} tools unused in 7+ days: "
            f"`{', '.join(sample)}`{'...' if len(unused) > 5 else ''}"
        )

    # Check tool stats for suggestions
    stats = get_ops_tool_stats()
    if stats:
        by_usage = sorted(
            stats.items(), key=lambda x: x[1].get("total_uses", 0), reverse=True
        )
        if by_usage:
            top_tool = by_usage[0][0]
            top_uses = by_usage[0][1].get("total_uses", 0)
            if top_uses >= 10:
                parts.append(f" Most-used tool: `{top_tool}` ({top_uses} uses)")

        for tool, data in stats.items():
            total = data.get("total_uses", 0)
            failures = data.get("failures", 0)
            if total >= 5 and failures / total > 0.5:
                parts.append(
                    f" `{tool}` has {failures}/{total} failures - may need fixing"
                )
                break

    if not parts:
        return HookResult.allow()

    return HookResult.allow("\n".join(parts))


# =============================================================================
# INTENT CLASSIFIER (priority 88)
# =============================================================================


@register_hook("intent_classifier", priority=88)
def check_intent_classifier(data: dict, state: SessionState) -> HookResult:
    """Classify user intent via HuggingFace model and inject mode-specific context."""
    if not INTENT_CLASSIFIER_AVAILABLE or classify_intent is None:
        return HookResult.allow()

    prompt = data.get("prompt", "")
    if not prompt or len(prompt) < 20:
        return HookResult.allow()

    # Skip slash commands and trivial prompts
    if prompt.startswith("/") or re.match(
        r"^(yes|no|ok|hi|hello|thanks)\b", prompt.lower()
    ):
        return HookResult.allow()

    # Cooldown: only classify every 3rd prompt
    if state.turn_count % 3 != 1:
        return HookResult.allow()

    try:
        result = classify_intent(prompt, threshold=0.35)
        if result is None:
            return HookResult.allow()

        intent = result["intent"]
        confidence = result["confidence"]
        message = result.get("message")

        # Store intent in state
        state.set("detected_intent", intent)
        state.set("intent_confidence", confidence)

        if message and confidence >= 0.45:
            return HookResult.allow(
                f" **INTENT [{intent.upper()}]** ({confidence:.0%}): {message}"
            )

        return HookResult.allow()
    except Exception:
        return HookResult.allow()


# =============================================================================
# EXPERT PROBE (priority 89)
# =============================================================================

_EXPERT_PROBES = [
    (
        re.compile(r"\b(fix|improve|better|faster|clean|help|make it)\b"),
        re.compile(r"\b(because|since|error|exception|line \d|specific)\b"),
        ' **VAGUENESS**: Ask "What specific behavior/output is wrong?"',
    ),
    (
        re.compile(r"\b(broken|doesn't work|not working|wrong|bug|issue|problem)\b"),
        re.compile(r"\b(error|traceback|expected|actual|instead|got)\b"),
        ' **CLAIM CHECK**: Ask "Expected vs actual? Any error message?"',
    ),
    (
        re.compile(r"\b(update|change|modify|refactor|rewrite)\b"),
        re.compile(r"\b(file|function|class|line|method|in \w+\.)\b"),
        ' **SCOPE**: Ask "Which specific files/functions?"',
    ),
]

_RE_TRIVIAL_PROMPT = re.compile(r"^(yes|no|ok|hi|thanks|commit|push|/\w+)\b")
_RE_UNCERTAIN = re.compile(r"\b(i think|probably|maybe|might be|could be|seems like)\b")
_RE_NEW_FEATURE = re.compile(r"\b(add|create|implement|build|new feature)\b")


def _collect_expert_probes(prompt_lower: str, turn_count: int) -> list[str]:
    """Collect applicable expert probes for prompt."""
    probes = []
    for trigger, exclude, message in _EXPERT_PROBES:
        if trigger.search(prompt_lower) and not exclude.search(prompt_lower):
            probes.append(message)
    if _RE_NEW_FEATURE.search(prompt_lower) and turn_count <= 3:
        probes.append(
            " **CONSTRAINTS**: Ask about edge cases, error handling, existing patterns"
        )
    if _RE_UNCERTAIN.search(prompt_lower):
        probes.append(
            " **EXPERT MODE**: User uncertain - investigate first, don't assume they're right"
        )
    return probes


@register_hook("expert_probe", priority=89)
def check_expert_probe(data: dict, state: SessionState) -> HookResult:
    """Force AI to ask probing questions - assume user needs guidance."""
    prompt = data.get("prompt", "")
    if not prompt or len(prompt) < 15 or "?" in prompt or len(prompt) > 300:
        return HookResult.allow()

    prompt_lower = prompt.lower()
    if _RE_TRIVIAL_PROMPT.match(prompt_lower):
        return HookResult.allow()

    probes = _collect_expert_probes(prompt_lower, state.turn_count)
    if not probes:
        return HookResult.allow()

    return HookResult.allow(
        " **PROBE BEFORE ACTING** (assume user needs guidance):\n" + "\n".join(probes)
    )


# =============================================================================
# PAL MANDATE (priority 89)
# =============================================================================


@register_hook("pal_mandate", priority=89)
def check_pal_mandate(data: dict, state: SessionState) -> HookResult:
    """Inject MANDATORY PAL tool directives based on confidence/intent/state."""
    if not PAL_MANDATES_AVAILABLE or get_mandate is None:
        return HookResult.allow()

    prompt = data.get("prompt", "")
    if not prompt or len(prompt) < 15:
        return HookResult.allow()

    if prompt.startswith("/"):
        return HookResult.allow()

    confidence = state.get("confidence", 70)
    intent = state.get("detected_intent")
    cascade_failure = state.get("cascade_failure_active", False)
    edit_oscillation = state.get("edit_oscillation_active", False)
    sunk_cost = state.get("sunk_cost_active", False)
    goal_drift = state.get("goal_drift_active", False)
    consecutive_failures = state.get("consecutive_failures", 0)

    mandate = get_mandate(
        confidence=confidence,
        intent=intent,
        cascade_failure=cascade_failure,
        edit_oscillation=edit_oscillation,
        sunk_cost=sunk_cost,
        goal_drift=goal_drift,
        consecutive_failures=consecutive_failures,
    )

    if mandate is None and check_keyword_mandate is not None:
        mandate = check_keyword_mandate(prompt, confidence)

    if mandate is None:
        return HookResult.allow()

    state.set("active_pal_mandate", mandate.tool)
    state.set("mandate_reason", mandate.reason)

    return HookResult.allow(mandate.directive)


# =============================================================================
# RESOURCE POINTER (priority 90)
# =============================================================================

TOOL_INDEX = {
    "probe": (
        ["api", "signature", "method", "inspect", "class"],
        "runtime API inspection",
        "/probe httpx.Client",
    ),
    "research": (
        ["docs", "documentation", "library", "how", "api"],
        "web search for docs",
        "/research 'fastapi 2024'",
    ),
    "xray": (
        ["find", "class", "function", "structure", "ast"],
        "AST search",
        "/xray --type function --name handle_",
    ),
    "audit": (
        ["security", "vulnerability", "injection", "secrets"],
        "security audit",
        "/audit src/auth.py",
    ),
    "void": (
        ["stub", "todo", "incomplete", "missing"],
        "find incomplete code",
        "/void src/handlers/",
    ),
    "think": (
        ["complex", "decompose", "stuck", "approach"],
        "problem decomposition",
        "/think 'concurrent writes'",
    ),
    "council": (
        ["decision", "tradeoff", "choice", "should"],
        "multi-perspective analysis",
        "/council 'REST vs GraphQL'",
    ),
    "orchestrate": (
        ["batch", "aggregate", "many", "multiple", "scan"],
        "batch tasks",
        "/orchestrate 'scan all py'",
    ),
}

FOLDER_HINTS = {
    "src/": ["source", "code", "main", "app"],
    ".claude/ops/": ["tool", "script", "ops", "command"],
    ".claude/hooks/": ["hook", "gate", "enforce", "check"],
    ".claude/lib/": ["library", "core", "shared", "state"],
    "api/": ["api", "endpoint", "route", "handler"],
    "tests/": ["test", "spec", "fixture"],
}


def _match_folders(kw_set: set[str]) -> list[str]:
    """Match keywords against folder hints."""
    parts = []
    cwd = Path.cwd()
    for folder, hints in FOLDER_HINTS.items():
        if (cwd / folder.rstrip("/")).exists() and kw_set & set(hints):
            parts.append(f"   {folder}")
        if len(parts) >= 2:
            break
    return parts


def _match_tools(kw_set: set[str]) -> list[str]:
    """Match keywords against tool index."""
    tool_parts = []
    for tool, (tool_kws, desc, example) in TOOL_INDEX.items():
        if score := len(kw_set & set(tool_kws)):
            tool_parts.append((f"   /{tool} - {desc}", f"    eg: {example}", score))
        if len(tool_parts) >= 2:
            break
    tool_parts.sort(key=lambda x: -x[2])
    parts = []
    for t, e, _ in tool_parts[:2]:
        parts.extend([t, e])
    return parts


_RE_TRIVIAL_RESOURCE = re.compile(
    r"^(commit|push|status|help|yes|no|ok|thanks)\b", re.I
)


@register_hook("resource_pointer", priority=90)
def check_resource_pointer(data: dict, state: SessionState) -> HookResult:
    """Surface sparse pointers to possibly relevant resources."""
    prompt = data.get("prompt", "")
    if not prompt or len(prompt) < 15 or _RE_TRIVIAL_RESOURCE.match(prompt):
        return HookResult.allow()

    keywords = extract_keywords(prompt)
    if len(keywords) < 2:
        return HookResult.allow()

    kw_set = set(keywords)
    parts = _match_folders(kw_set) + _match_tools(kw_set)

    if not parts:
        return HookResult.allow()

    return HookResult.allow(" POSSIBLY RELEVANT:\n" + "\n".join(parts))


# =============================================================================
# WORK PATTERNS (priority 91)
# =============================================================================

_WORK_PATTERNS = [
    (
        r"\b(edit|change|update|modify|fix|add|create|implement|refactor)\b",
        " **ASSUMPTIONS**: Before acting, state key assumptions (paths, APIs, behavior)",
    ),
    (
        r"\b(delete|remove|drop|reset|overwrite|replace|migrate)\b",
        " **ROLLBACK**: Note undo path before destructive ops",
    ),
    (
        r"\b(should|best|optimal|recommend|which|how to|complex|tricky)\b",
        " **CONFIDENCE**: State confidence % and reasoning for recommendations",
    ),
    (
        r"\b(function|method|api|endpoint|signature|interface|class)\b",
        " **INTEGRATION**: After edits, grep callers and note impact",
    ),
    (
        r"\b(can you|is it possible|can't|cannot|impossible|no way to|not able)\b",
        " **IMPOSSIBILITY CHECK**: Before claiming 'can't', verify: MCP tools, Task agents, WebSearch, /inventory. Try first.",
    ),
]

_PARALLEL_SIGNALS = [
    r"\b(1\.|2\.|3\.)",
    r"\b(first|second|third|then|next|after that)\b",
    r"\b(all|each|every|multiple|several|many)\s+(file|component|test|module)",
    r"\band\b.*\band\b",
    r"[,;]\s*\w+[,;]\s*\w+",
]

# Recursive decomposition signals - complex multi-angle questions
_DECOMPOSITION_TRIGGERS = [
    r"\b(why|how|what\s+makes|what\s+causes)\s+.{15,}\?",  # Complex why/how questions
    r"\b(research|explore|investigate|deep\s+dive|analyze)\s+.{10,}",  # Research intent
    r"\b(comprehensive|thorough|in-depth|complete)\s+(analysis|review|investigation)",  # Depth signals
    r"\b(all|every|various|different|multiple)\s+(aspects?|angles?|perspectives?|factors?)",  # Multi-angle
    r"\b(compare|contrast|evaluate)\s+.{5,}\s+(vs|versus|and|or)\s+",  # Comparison questions
]

_DECOMPOSITION_MESSAGE = """ **RECURSIVE DECOMPOSITION**: Complex multi-angle question detected.
Option A - Use dedicated agent:
```
Task(subagent_type="deep-research", prompt="[full question]")
```
Option B - Manual decomposition:
```
Task(subagent_type="Explore", prompt="Angle 1: [specific sub-question]")
Task(subagent_type="Explore", prompt="Angle 2: [specific sub-question]")  # Same message = parallel
Task(subagent_type="Explore", prompt="Angle 3: [specific sub-question]")
```
Each agent explores independently  synthesize into unified answer."""


@register_hook("work_patterns", priority=91)
def check_work_patterns(data: dict, state: SessionState) -> HookResult:
    """Inject work behavior patterns - assumptions, rollback, confidence, integration."""
    prompt = data.get("prompt", "")
    if not prompt or len(prompt) < 40:
        return HookResult.allow()

    prompt_lower = prompt.lower()
    if re.match(r"^(yes|no|ok|hi|hello|thanks|status|/\w+)\b", prompt_lower):
        return HookResult.allow()

    parts = [msg for pattern, msg in _WORK_PATTERNS if re.search(pattern, prompt_lower)]

    # Parallel opportunity
    if any(re.search(p, prompt_lower) for p in _PARALLEL_SIGNALS):
        if state.consecutive_single_tasks >= 1 or state.parallel_nudge_count >= 1:
            parts.append(
                " **PARALLEL AGENTS**: Multiple items detected. "
                "Spawn independent Task agents in ONE message, not sequentially."
            )

    # Recursive decomposition for complex research questions
    decomp_matches = sum(
        1 for p in _DECOMPOSITION_TRIGGERS if re.search(p, prompt_lower)
    )
    if decomp_matches >= 2 and len(prompt) >= 50:
        parts.append(_DECOMPOSITION_MESSAGE)

    return HookResult.allow("\n".join(parts)) if parts else HookResult.allow()


# =============================================================================
# QUALITY SIGNALS (priority 93)
# =============================================================================


@register_hook("quality_signals", priority=93)
def check_quality_signals(data: dict, state: SessionState) -> HookResult:
    """Inject quality signals - pattern smells, context decay."""
    prompt = data.get("prompt", "")
    parts = []

    prompt_lower = prompt.lower() if prompt else ""
    if re.search(r"\b(review|refactor|clean|improve|optimize)\b", prompt_lower):
        parts.append(
            " **PATTERN SMELL**: Flag anti-patterns with severity (minor  critical)"
        )

    if state.turn_count >= 15:
        if state.turn_count >= 30:
            parts.append(
                " **CONTEXT DECAY**: 30+ turns - strongly consider `/compact` or summarize"
            )
        else:
            parts.append(
                " **CONTEXT NOTE**: 15+ turns - context may be stale, verify assumptions"
            )

    if not parts:
        return HookResult.allow()

    return HookResult.allow("\n".join(parts))


# =============================================================================
# RESPONSE FORMAT (priority 95)
# =============================================================================


@register_hook("response_format", priority=95)
def check_response_format(data: dict, state: SessionState) -> HookResult:
    """Inject structured response format requirements."""
    prompt = data.get("prompt", "")
    if not prompt or len(prompt) < 30:
        return HookResult.allow()

    if re.match(
        r"^(yes|no|ok|hi|hello|thanks|commit|push|status|/\w+)\b", prompt.lower()
    ):
        return HookResult.allow()

    format_req = """ **RESPONSE FORMAT** - End substantive responses with applicable sections (skip empty):

###  Integration Impact
`[sev] [file]: [how affected]` - What breaks after this change

###  Code Smells & Patterns
`[sev] [pattern]: [location] - [why matters]` - Anti-patterns detected

###  Technical Debt & Risks
`[sev] [risk]` - Security, perf, maintainability (1-25 26-50 51-75 76-100)

###  Quick Wins
`[E:S/M/L] [action]  [benefit]` - Low-effort improvements spotted

###  Architecture Pressure
`[sev] [location]: [strain]  [relief]` - Design strain points

###  Prior Art & Memory
` [context]: [relevance]` - Past decisions with inline context

###  SME Insights
`[domain]: [insight]` - Domain expertise, gotchas

###  Documentation Updates
`[sev] [what]` - Docs/comments needing update

###  Next Steps (2-3 divergent paths requiring user decision)
**Path A: [Focus]** (if [priority/constraint])
- `[pri] DO: [action]` | `[pri] Unlocks  [what]`

**Path B: [Different Outcome]** (if [different priority])
- `[pri] You'll hit  [problem]` | `[pri] Trajectory  [pivot]`

 NO: "Validate/Test" | "Done" | Same outcome variants | Things I could just do
 YES: Paths needing user input (priorities, constraints, preferences I can't infer)

Patterns: DO | Chain | Predict | Anti | Strategic | Priority: 1-25 26-50 51-75 76-100"""

    return HookResult.allow(format_req)
</file>

<file path="_quality_scanner.py">
#!/usr/bin/env python3
"""
Code Quality Scanner using rule-based tools (ruff, radon).

Fast, reliable, and actionable - no ML model loading required.
Detects:
- Lint issues (ruff): style, imports, potential bugs
- Complexity issues (radon): functions too complex, low maintainability
"""

from __future__ import annotations

import subprocess
import json
from pathlib import Path
from typing import Optional


def scan_file(file_path: str, complexity_threshold: str = "C") -> Optional[dict]:
    """
    Scan a Python file for quality issues.

    Args:
        file_path: Path to Python file
        complexity_threshold: Min complexity grade to report (A-F, default C)

    Returns:
        Dict with 'issues', 'complexity', 'recommendations' or None if clean
    """
    path = Path(file_path)
    if not path.exists() or path.suffix != ".py":
        return None

    issues = []
    recommendations = []

    # Run ruff for lint issues
    ruff_issues = _run_ruff(file_path)
    if ruff_issues:
        issues.extend(ruff_issues)
        recommendations.append(" Run `ruff check --fix` to auto-fix style issues")

    # Run radon for complexity
    complexity = _run_radon_cc(file_path, complexity_threshold)
    if complexity:
        issues.extend(complexity)
        recommendations.append(
            " Consider breaking complex functions into smaller pieces"
        )

    # Run radon for maintainability index
    mi_issues = _run_radon_mi(file_path)
    if mi_issues:
        issues.extend(mi_issues)

    if not issues:
        return None

    return {
        "file": file_path,
        "issue_count": len(issues),
        "issues": issues[:5],  # Limit to top 5
        "recommendations": recommendations,
    }


def scan_code(code: str, complexity_threshold: str = "C") -> Optional[dict]:
    """
    Scan code string for quality issues (writes to temp file).

    Args:
        code: Python source code
        complexity_threshold: Min complexity grade to report

    Returns:
        Dict with issues or None if clean
    """
    if not code or len(code.strip()) < 20:
        return None

    # Write to temp file for analysis
    import tempfile

    with tempfile.NamedTemporaryFile(mode="w", suffix=".py", delete=False) as f:
        f.write(code)
        temp_path = f.name

    try:
        result = scan_file(temp_path, complexity_threshold)
        if result:
            result["file"] = "<code>"
        return result
    finally:
        Path(temp_path).unlink(missing_ok=True)


def _run_ruff(file_path: str) -> list[dict]:
    """Run ruff check and return issues."""
    try:
        result = subprocess.run(
            ["ruff", "check", "--output-format=json", file_path],
            capture_output=True,
            text=True,
            timeout=10,
        )
        if result.stdout:
            data = json.loads(result.stdout)
            return [
                {
                    "type": "lint",
                    "code": item.get("code", ""),
                    "message": item.get("message", ""),
                    "line": item.get("location", {}).get("row", 0),
                    "severity": _ruff_severity(item.get("code", "")),
                }
                for item in data[:10]  # Limit
            ]
    except (subprocess.TimeoutExpired, json.JSONDecodeError, FileNotFoundError):
        pass
    return []


def _run_radon_cc(file_path: str, min_grade: str = "C") -> list[dict]:
    """Run radon cyclomatic complexity check."""
    try:
        result = subprocess.run(
            ["radon", "cc", "-j", "-n", min_grade, file_path],
            capture_output=True,
            text=True,
            timeout=10,
        )
        if result.stdout:
            data = json.loads(result.stdout)
            issues = []
            for path, blocks in data.items():
                for block in blocks:
                    issues.append(
                        {
                            "type": "complexity",
                            "name": block.get("name", ""),
                            "complexity": block.get("complexity", 0),
                            "rank": block.get("rank", ""),
                            "line": block.get("lineno", 0),
                            "message": f"{block.get('name')} has complexity {block.get('complexity')} (rank {block.get('rank')})",
                            "severity": _complexity_severity(block.get("rank", "A")),
                        }
                    )
            return issues
    except (subprocess.TimeoutExpired, json.JSONDecodeError, FileNotFoundError):
        pass
    return []


def _run_radon_mi(file_path: str, threshold: float = 50.0) -> list[dict]:
    """Run radon maintainability index check."""
    try:
        result = subprocess.run(
            ["radon", "mi", "-j", file_path],
            capture_output=True,
            text=True,
            timeout=10,
        )
        if result.stdout:
            data = json.loads(result.stdout)
            issues = []
            for path, info in data.items():
                mi = info.get("mi", 100)
                rank = info.get("rank", "A")
                if mi < threshold or rank in ("C", "D", "E", "F"):
                    issues.append(
                        {
                            "type": "maintainability",
                            "mi_score": round(mi, 1),
                            "rank": rank,
                            "message": f"Maintainability index {round(mi, 1)} (rank {rank}) - consider refactoring",
                            "severity": _mi_severity(rank),
                        }
                    )
            return issues
    except (subprocess.TimeoutExpired, json.JSONDecodeError, FileNotFoundError):
        pass
    return []


def _ruff_severity(code: str) -> str:
    """Map ruff code to severity."""
    if code.startswith(("E9", "F")):  # Syntax errors, critical
        return "high"
    if code.startswith(("E", "W")):  # Style
        return "low"
    if code.startswith(("C", "B")):  # Complexity, bugbear
        return "medium"
    return "low"


def _complexity_severity(rank: str) -> str:
    """Map complexity rank to severity."""
    return {
        "A": "low",
        "B": "low",
        "C": "medium",
        "D": "high",
        "E": "high",
        "F": "critical",
    }.get(rank, "medium")


def _mi_severity(rank: str) -> str:
    """Map maintainability rank to severity."""
    return {"A": "low", "B": "medium", "C": "high"}.get(rank, "high")


def format_report(result: dict) -> str:
    """Format scan result as readable report."""
    if not result:
        return ""

    lines = [f" **Code Quality**: {result['issue_count']} issues in {result['file']}"]

    for issue in result.get("issues", []):
        severity_icon = {
            "low": "",
            "medium": "",
            "high": "",
            "critical": "",
        }.get(issue.get("severity", ""), "")
        if issue["type"] == "lint":
            lines.append(
                f"  {severity_icon} L{issue['line']}: [{issue['code']}] {issue['message']}"
            )
        elif issue["type"] == "complexity":
            lines.append(f"  {severity_icon} L{issue['line']}: {issue['message']}")
        elif issue["type"] == "maintainability":
            lines.append(f"  {severity_icon} {issue['message']}")

    for rec in result.get("recommendations", []):
        lines.append(f"  {rec}")

    return "\n".join(lines)
</file>

<file path="dependency_check.py">
#!/usr/bin/env python3
"""
Dependency Checker v1.3: Validates all .claude dependencies at session start.

Checks:
1. Required API keys (for external services)
2. Python packages (from requirements.txt)
3. External binaries (git, ruff, bd, node, npm, etc.)
4. Critical directories and files
5. Node.js/npm for MCP servers and frontend workflows
6. MCP server dependencies
7. MCP config validity (settings.json plugin entries)
8. Stale MCP server processes
9. Installed plugins (valid paths and structure)

Features:
- Fast (<500ms total with caching)
- Non-blocking (warnings only, never fails session)
- Comprehensive (catches missing deps before cryptic failures)
- Auto-fix mode (--fix to install missing Python packages)
- Result caching (5 min TTL to avoid re-checking mid-session)
- Timeout protection on slow external commands
"""

import json
import os
import sys
import shutil
import subprocess
import importlib.util
import time
from pathlib import Path

# =============================================================================
# CONFIGURATION
# =============================================================================

# Cache settings
CACHE_FILE = Path.home() / ".claude" / "tmp" / "dep_check_cache.json"
CACHE_TTL_SECONDS = 300  # 5 minutes

# Timeout for external commands (seconds)
CMD_TIMEOUT_FAST = 2  # For quick commands like node --version
CMD_TIMEOUT_SLOW = 5  # For npm list (can be slow)

# API keys and their purposes (for clear error messages)
API_KEYS = {
    "OPENROUTER_API_KEY": {
        "required": False,
        "used_by": [
            "think.py",
            "oracle.py",
            "council.py",
            "gaps.py",
            "void.py",
            "drift.py",
            "scope.py",
        ],
        "purpose": "External LLM consultation (OpenRouter)",
    },
    "TAVILY_API_KEY": {
        "required": False,
        "used_by": ["research.py"],
        "purpose": "Web search via Tavily",
    },
    "ANTHROPIC_API_KEY": {
        "required": False,
        "used_by": ["orchestrate.py"],
        "purpose": "Claude API code execution",
    },
    "GROQ_API_KEY": {
        "required": False,
        "used_by": ["groq.py"],
        "purpose": "Fast inference via Groq",
    },
    "FIRECRAWL_API_KEY": {
        "required": False,
        "used_by": ["firecrawl.py"],
        "purpose": "Web scraping via Firecrawl",
    },
    "CONTEXT7_API_KEY": {
        "required": False,
        "used_by": ["docs.py"],
        "purpose": "Documentation lookup via Context7",
    },
}

# External binaries (name -> info)
BINARIES = {
    "git": {
        "required": True,
        "used_by": ["version control", "scope.py", "coderabbit.py"],
    },
    "ruff": {
        "required": True,
        "used_by": ["code linting", "audit.py"],
        "install_hint": "pip install ruff",
    },
    "bd": {
        "required": False,
        "used_by": ["beads task tracking"],
        "install_hint": "pip install beads-cli or check ~/.local/bin",
    },
    "python3": {
        "required": True,
        "used_by": ["hook execution"],
    },
    "node": {
        "required": False,
        "used_by": ["MCP servers", "frontend workflows"],
        "install_hint": "Install Node.js from https://nodejs.org or via nvm",
    },
    "npm": {
        "required": False,
        "used_by": ["MCP servers", "package management"],
        "install_hint": "Comes with Node.js installation",
    },
}

# Python packages to check (module_name -> package_name if different)
PYTHON_PACKAGES = {
    "requests": None,
    "pydantic": None,
    "yaml": "pyyaml",
    "dotenv": "python-dotenv",
    "rapidfuzz": None,
    "websockets": None,
}

# Critical paths that must exist
CRITICAL_PATHS = {
    "~/.claude/hooks": "Hook scripts",
    "~/.claude/ops": "Ops scripts",
    "~/.claude/lib": "Library modules",
    "~/.claude/memory": "Memory storage",
    "~/.claude/.venv": "Python virtual environment",
}

# MCP servers that require npm packages
MCP_SERVERS = {
    "repomix-mcp": {
        "package": "repomix",
        "global": True,
        "required": False,
    },
    "filesystem": {
        "package": "@anthropic/mcp-server-filesystem",
        "global": True,
        "required": False,
    },
}

# Known MCP process patterns (for stale process detection)
MCP_PROCESS_PATTERNS = [
    "mcp-server",
    "repomix",
    "@anthropic/mcp",
    "claude-mem",
    "crawl4ai",
]


# =============================================================================
# CACHING
# =============================================================================


def load_cache() -> dict | None:
    """Load cached results if valid."""
    if not CACHE_FILE.exists():
        return None

    try:
        with open(CACHE_FILE) as f:
            cache = json.load(f)

        # Check TTL
        cached_at = cache.get("cached_at", 0)
        if time.time() - cached_at > CACHE_TTL_SECONDS:
            return None

        return cache.get("result")
    except (json.JSONDecodeError, KeyError, IOError):
        return None


def save_cache(result: dict) -> None:
    """Save results to cache."""
    CACHE_FILE.parent.mkdir(parents=True, exist_ok=True)
    try:
        with open(CACHE_FILE, "w") as f:
            json.dump({"cached_at": time.time(), "result": result}, f)
    except IOError:
        pass  # Non-critical


def clear_cache() -> None:
    """Clear the cache file."""
    if CACHE_FILE.exists():
        try:
            CACHE_FILE.unlink()
        except IOError:
            pass


# =============================================================================
# CHECK FUNCTIONS
# =============================================================================


def check_api_keys() -> list[dict]:
    """Check for missing API keys."""
    issues = []
    for key, info in API_KEYS.items():
        value = os.environ.get(key, "").strip()
        if not value:
            issues.append(
                {
                    "type": "api_key",
                    "name": key,
                    "required": info["required"],
                    "purpose": info["purpose"],
                    "used_by": info["used_by"],
                }
            )
    return issues


def check_binaries() -> list[dict]:
    """Check for missing external binaries."""
    issues = []
    for name, info in BINARIES.items():
        path = shutil.which(name)
        if not path:
            issue = {
                "type": "binary",
                "name": name,
                "required": info["required"],
                "used_by": info["used_by"],
            }
            if "install_hint" in info:
                issue["hint"] = info["install_hint"]
            issues.append(issue)
    return issues


def check_python_packages() -> list[dict]:
    """Check for missing Python packages."""
    issues = []
    for module_name, package_name in PYTHON_PACKAGES.items():
        spec = importlib.util.find_spec(module_name)
        if spec is None:
            issues.append(
                {
                    "type": "python_package",
                    "name": module_name,
                    "package": package_name or module_name,
                    "required": True,
                }
            )
    return issues


def check_critical_paths() -> list[dict]:
    """Check for missing critical directories/files."""
    issues = []
    for path_str, description in CRITICAL_PATHS.items():
        path = Path(path_str).expanduser()
        if not path.exists():
            issues.append(
                {
                    "type": "path",
                    "name": str(path),
                    "description": description,
                    "required": True,
                }
            )
    return issues


def check_venv_integrity() -> list[dict]:
    """Check if venv is properly set up."""
    issues = []
    venv_path = Path.home() / ".claude" / ".venv"

    if venv_path.exists():
        python_path = venv_path / "bin" / "python"
        if not python_path.exists():
            issues.append(
                {
                    "type": "venv",
                    "name": "venv python",
                    "description": "Virtual environment exists but python binary missing",
                    "required": True,
                    "hint": "Run: python3 -m venv ~/.claude/.venv",
                }
            )

        pip_path = venv_path / "bin" / "pip"
        if not pip_path.exists():
            issues.append(
                {
                    "type": "venv",
                    "name": "venv pip",
                    "description": "Virtual environment missing pip",
                    "required": True,
                    "hint": "Run: ~/.claude/.venv/bin/python -m ensurepip",
                }
            )

    return issues


def check_node_ecosystem() -> list[dict]:
    """Check Node.js ecosystem health."""
    issues = []

    if not shutil.which("node") or not shutil.which("npm"):
        return issues

    try:
        result = subprocess.run(
            ["node", "--version"],
            capture_output=True,
            text=True,
            timeout=CMD_TIMEOUT_FAST,
        )
        if result.returncode == 0:
            version = result.stdout.strip().lstrip("v")
            major = int(version.split(".")[0])
            if major < 18:
                issues.append(
                    {
                        "type": "node_version",
                        "name": f"Node.js {version}",
                        "description": f"Node.js {major}.x is outdated, MCP servers need 18+",
                        "required": False,
                        "hint": "Update Node.js to v18 or newer",
                    }
                )
    except (subprocess.TimeoutExpired, ValueError, IndexError):
        pass

    return issues


def check_mcp_servers() -> list[dict]:
    """Check MCP server dependencies with timeout protection."""
    issues = []

    if not shutil.which("npm"):
        return issues

    for server_name, info in MCP_SERVERS.items():
        package = info["package"]
        is_global = info.get("global", False)

        try:
            cmd = ["npm", "list", package]
            if is_global:
                cmd.insert(2, "-g")

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=CMD_TIMEOUT_SLOW,
            )

            if result.returncode != 0 and "(empty)" not in result.stdout:
                issues.append(
                    {
                        "type": "mcp_server",
                        "name": server_name,
                        "package": package,
                        "required": info.get("required", False),
                        "hint": f"npm install {'-g ' if is_global else ''}{package}",
                    }
                )
        except subprocess.TimeoutExpired:
            # Skip slow checks, don't report as issue
            pass

    return issues


def check_mcp_config() -> list[dict]:
    """Check MCP configuration in settings.json."""
    issues = []
    settings_path = Path.home() / ".claude" / "settings.json"

    if not settings_path.exists():
        return issues

    try:
        with open(settings_path) as f:
            settings = json.load(f)

        enabled_plugins = settings.get("enabledPlugins", {})

        for plugin_name, enabled in enabled_plugins.items():
            if not enabled:
                continue

            # Check for common plugin name patterns that suggest missing deps
            if "mcp" in plugin_name.lower():
                # Plugin enabled but we can't verify it's installed
                # This is informational, not blocking
                pass

        # Check hooks configuration
        hooks = settings.get("hooks", {})
        for hook_type, hook_configs in hooks.items():
            if not isinstance(hook_configs, list):
                continue

            for config in hook_configs:
                if not isinstance(config, dict):
                    continue

                hook_list = config.get("hooks", [])
                for hook in hook_list:
                    if not isinstance(hook, dict):
                        continue

                    command = hook.get("command", "")
                    if command:
                        # Check if hook script exists
                        # Expand $HOME
                        expanded = command.replace("$HOME", str(Path.home()))
                        parts = expanded.split()
                        if parts:
                            script_path = Path(
                                parts[-1]
                            )  # Last part is usually the script
                            if script_path.suffix == ".py" and not script_path.exists():
                                issues.append(
                                    {
                                        "type": "mcp_config",
                                        "name": f"Hook script missing: {script_path.name}",
                                        "description": f"Hook type {hook_type} references missing script",
                                        "required": False,
                                        "hint": f"Check {settings_path}",
                                    }
                                )

    except (json.JSONDecodeError, KeyError, IOError):
        pass

    return issues


def check_stale_mcp_processes() -> list[dict]:
    """Check for stale MCP server processes."""
    issues = []

    try:
        # Get list of running processes
        result = subprocess.run(
            ["ps", "aux"],
            capture_output=True,
            text=True,
            timeout=CMD_TIMEOUT_FAST,
        )

        if result.returncode != 0:
            return issues

        lines = result.stdout.strip().split("\n")
        stale_processes = []

        for line in lines[1:]:  # Skip header
            parts = line.split(None, 10)
            if len(parts) < 11:
                continue

            pid = parts[1]
            cpu = parts[2]
            command = parts[10]

            # Check if this looks like an MCP process
            for pattern in MCP_PROCESS_PATTERNS:
                if pattern in command.lower():
                    # Check if it's consuming resources but possibly orphaned
                    try:
                        cpu_val = float(cpu)
                        # Flag processes using significant CPU or matching patterns
                        if cpu_val > 10 or "defunct" in command:
                            stale_processes.append(
                                {
                                    "pid": pid,
                                    "cpu": cpu,
                                    "command": command[:60],
                                }
                            )
                    except ValueError:
                        pass
                    break

        if stale_processes:
            for proc in stale_processes[:3]:  # Limit to 3
                issues.append(
                    {
                        "type": "stale_process",
                        "name": f"PID {proc['pid']}",
                        "description": f"Possible stale MCP: {proc['command']}",
                        "required": False,
                        "hint": f"kill {proc['pid']} (if safe)",
                    }
                )

    except (subprocess.TimeoutExpired, IOError):
        pass

    return issues


def check_installed_plugins() -> list[dict]:
    """Check that installed plugins have valid install paths and structure."""
    issues = []
    plugins_file = Path.home() / ".claude" / "plugins" / "installed_plugins.json"

    if not plugins_file.exists():
        return issues

    try:
        with open(plugins_file) as f:
            data = json.load(f)

        plugins = data.get("plugins", {})

        for plugin_id, installations in plugins.items():
            if not isinstance(installations, list):
                continue

            for install in installations:
                if not isinstance(install, dict):
                    continue

                install_path = install.get("installPath", "")
                version = install.get("version", "unknown")

                if not install_path:
                    issues.append(
                        {
                            "type": "plugin",
                            "name": f"Plugin {plugin_id}",
                            "description": "Missing installPath in installed_plugins.json",
                            "required": False,
                            "hint": "Re-install the plugin",
                        }
                    )
                    continue

                path = Path(install_path)
                if not path.exists():
                    issues.append(
                        {
                            "type": "plugin",
                            "name": f"Plugin {plugin_id} v{version}",
                            "description": f"Install path missing: {install_path}",
                            "required": False,
                            "hint": "Re-install the plugin or remove from installed_plugins.json",
                        }
                    )
                    continue

                # Check for at least one expected plugin component
                has_skills = (path / "skills").is_dir()
                has_agents = (path / "agents").is_dir()
                has_commands = (path / "commands").is_dir()
                has_hooks = (path / "hooks").is_dir()
                has_mcp = (path / ".mcp.json").is_file()
                has_plugin_dir = (path / ".claude-plugin").is_dir()

                if not any(
                    [
                        has_skills,
                        has_agents,
                        has_commands,
                        has_hooks,
                        has_mcp,
                        has_plugin_dir,
                    ]
                ):
                    issues.append(
                        {
                            "type": "plugin",
                            "name": f"Plugin {plugin_id} v{version}",
                            "description": "No recognized plugin components (skills/, agents/, commands/, hooks/, .mcp.json)",
                            "required": False,
                            "hint": f"Check plugin structure at {install_path}",
                        }
                    )

    except (json.JSONDecodeError, KeyError, IOError) as e:
        issues.append(
            {
                "type": "plugin",
                "name": "installed_plugins.json",
                "description": f"Failed to parse: {e}",
                "required": False,
                "hint": "Check file format or delete to reset",
            }
        )

    return issues


# =============================================================================
# FIX FUNCTIONS
# =============================================================================


def fix_python_packages(issues: list[dict], verbose: bool = False) -> list[dict]:
    """Attempt to install missing Python packages."""
    remaining = []
    pip_path = Path.home() / ".claude" / ".venv" / "bin" / "pip"

    if not pip_path.exists():
        return issues

    python_issues = [i for i in issues if i["type"] == "python_package"]
    other_issues = [i for i in issues if i["type"] != "python_package"]

    if not python_issues:
        return issues

    packages = [i["package"] for i in python_issues]

    if verbose:
        print(f" Installing: {', '.join(packages)}")

    try:
        result = subprocess.run(
            [str(pip_path), "install", "-q"] + packages,
            capture_output=True,
            text=True,
            timeout=120,
        )

        if result.returncode == 0:
            if verbose:
                print(f" Installed {len(packages)} packages")
            for issue in python_issues:
                spec = importlib.util.find_spec(issue["name"])
                if spec is None:
                    remaining.append(issue)
        else:
            if verbose:
                print(f" pip install failed: {result.stderr[:200]}")
            remaining.extend(python_issues)

    except subprocess.TimeoutExpired:
        if verbose:
            print(" pip install timed out")
        remaining.extend(python_issues)

    return other_issues + remaining


# =============================================================================
# MAIN CHECK FUNCTION
# =============================================================================


def run_dependency_check(
    auto_fix: bool = False,
    verbose: bool = False,
    use_cache: bool = True,
    force_refresh: bool = False,
) -> dict:
    """Run all dependency checks and return results.

    Args:
        auto_fix: If True, attempt to install missing Python packages.
        verbose: If True, print progress messages during fix.
        use_cache: If True, use cached results if available.
        force_refresh: If True, ignore cache and run fresh checks.

    Returns:
        dict with keys:
            - ok: bool (True if no required deps missing)
            - critical: list of critical issues (required deps missing)
            - warnings: list of warnings (optional deps missing)
            - summary: str (human-readable summary)
            - fixed: int (number of issues fixed, if auto_fix=True)
            - cached: bool (True if results came from cache)
    """
    # Check cache first (unless fixing or forcing refresh)
    if use_cache and not auto_fix and not force_refresh:
        cached = load_cache()
        if cached:
            cached["cached"] = True
            return cached

    all_issues = []

    # Run all checks
    all_issues.extend(check_critical_paths())
    all_issues.extend(check_venv_integrity())
    all_issues.extend(check_binaries())
    all_issues.extend(check_python_packages())
    all_issues.extend(check_node_ecosystem())
    all_issues.extend(check_mcp_servers())
    all_issues.extend(check_mcp_config())
    all_issues.extend(check_stale_mcp_processes())
    all_issues.extend(check_api_keys())
    all_issues.extend(check_installed_plugins())

    fixed_count = 0

    if auto_fix:
        original_count = len(all_issues)
        all_issues = fix_python_packages(all_issues, verbose=verbose)
        fixed_count = original_count - len(all_issues)
        # Clear cache after fixing
        clear_cache()

    # Separate critical vs warnings
    critical = [i for i in all_issues if i.get("required", False)]
    warnings = [i for i in all_issues if not i.get("required", False)]

    # Build summary
    summary_parts = []

    if fixed_count > 0:
        summary_parts.append(f" Fixed {fixed_count} missing packages")

    if critical:
        summary_parts.append(f" {len(critical)} MISSING (required)")
        for issue in critical[:3]:
            name = issue.get("name", "unknown")
            hint = issue.get("hint", "")
            if hint:
                summary_parts.append(f"    {name}: {hint}")
            else:
                summary_parts.append(f"    {name}")
        if len(critical) > 3:
            summary_parts.append(f"   ... and {len(critical) - 3} more")

    if warnings:
        api_keys_missing = [w for w in warnings if w["type"] == "api_key"]
        stale_procs = [w for w in warnings if w["type"] == "stale_process"]
        other_warnings = [
            w for w in warnings if w["type"] not in ("api_key", "stale_process")
        ]

        if api_keys_missing:
            key_names = [w["name"] for w in api_keys_missing]
            summary_parts.append(f" API keys not set: {', '.join(key_names[:4])}")
            if len(key_names) > 4:
                summary_parts.append(f"   ... and {len(key_names) - 4} more")

        if stale_procs:
            summary_parts.append(
                f" {len(stale_procs)} possible stale MCP process(es)"
            )

        if other_warnings:
            for issue in other_warnings[:2]:
                summary_parts.append(f" Optional: {issue.get('name', 'unknown')}")

    if not critical and not warnings:
        summary_parts.append(" All dependencies satisfied")
    elif not critical and not summary_parts:
        summary_parts.insert(0, " Core dependencies OK")

    result = {
        "ok": len(critical) == 0,
        "critical": critical,
        "warnings": warnings,
        "summary": "\n".join(summary_parts),
        "fixed": fixed_count,
        "cached": False,
    }

    # Save to cache (if not fixing)
    if use_cache and not auto_fix:
        save_cache(result)

    return result


def format_full_report(result: dict) -> str:
    """Format a full dependency report for verbose output."""
    lines = ["=" * 50, "DEPENDENCY CHECK REPORT", "=" * 50, ""]

    if result.get("cached"):
        lines.append(" (from cache)")
        lines.append("")

    if result.get("fixed", 0) > 0:
        lines.append(f" Auto-fixed {result['fixed']} packages")
        lines.append("")

    if result["critical"]:
        lines.append(" CRITICAL (Required - will cause failures):")
        lines.append("-" * 40)
        for issue in result["critical"]:
            lines.append(f"  [{issue['type']}] {issue['name']}")
            if "description" in issue:
                lines.append(f"      Description: {issue['description']}")
            if "hint" in issue:
                lines.append(f"      Fix: {issue['hint']}")
            if "used_by" in issue:
                used = issue["used_by"]
                if isinstance(used, list):
                    lines.append(f"      Used by: {', '.join(used[:3])}")
        lines.append("")

    if result["warnings"]:
        lines.append(" WARNINGS (Optional - some features disabled):")
        lines.append("-" * 40)
        for issue in result["warnings"]:
            lines.append(f"  [{issue['type']}] {issue['name']}")
            if "purpose" in issue:
                lines.append(f"      Purpose: {issue['purpose']}")
            if "description" in issue:
                lines.append(f"      Info: {issue['description']}")
            if "hint" in issue:
                lines.append(f"      Fix: {issue['hint']}")
        lines.append("")

    if result["ok"] and not result["warnings"]:
        lines.append(" All dependencies satisfied!")
    elif result["ok"]:
        lines.append(" Core dependencies OK (some optional features unavailable)")
    else:
        lines.append(" Some required dependencies missing!")
        lines.append("   Run: ~/.claude/hooks/dependency_check.py --fix")
        lines.append("   Or:  pip install -r ~/.claude/requirements.txt")

    lines.append("")
    lines.append("=" * 50)
    return "\n".join(lines)


# =============================================================================
# CLI INTERFACE
# =============================================================================


def main():
    """Run dependency check and output results."""
    import argparse

    parser = argparse.ArgumentParser(description="Check .claude dependencies")
    parser.add_argument("--verbose", "-v", action="store_true", help="Show full report")
    parser.add_argument("--json", action="store_true", help="Output as JSON")
    parser.add_argument(
        "--quiet", "-q", action="store_true", help="Only show if issues exist"
    )
    parser.add_argument(
        "--fix", action="store_true", help="Auto-install missing Python packages"
    )
    parser.add_argument(
        "--no-cache", action="store_true", help="Skip cache, run fresh checks"
    )
    parser.add_argument(
        "--clear-cache", action="store_true", help="Clear cache and exit"
    )
    args = parser.parse_args()

    if args.clear_cache:
        clear_cache()
        print("Cache cleared")
        sys.exit(0)

    result = run_dependency_check(
        auto_fix=args.fix,
        verbose=args.verbose or args.fix,
        use_cache=not args.no_cache,
        force_refresh=args.no_cache,
    )

    if args.json:
        print(json.dumps(result, indent=2))
    elif args.verbose:
        print(format_full_report(result))
    elif args.quiet:
        if not result["ok"] or result["warnings"]:
            print(result["summary"])
    else:
        print(result["summary"])

    sys.exit(0 if result["ok"] else 1)


if __name__ == "__main__":
    main()
</file>

<file path="post_tool_use_runner.py">
#!/usr/bin/env python3
"""
Composite PostToolUse Runner: Runs all PostToolUse hooks in a single process.

PERFORMANCE: ~40ms for 8 hooks vs ~300ms for individual processes (7x faster)

HOOKS INDEX (by priority):
  STATE (0-20):
    10 state_updater       - Track files read/edited, commands, libraries, errors
    11 confidence_decay    - Natural decay + tool boosts (context-scaled)
    12 confidence_reducer  - Apply deterministic confidence reductions on failures
    14 confidence_increaser - Apply confidence increases on success signals
    16 thinking_quality_boost - Reward good reasoning (evidence, verification, diagnosis)

  QUALITY GATES (22-50):
    22 assumption_check    - Surface hidden assumptions in code changes
    25 verification_reminder - Remind to verify after fix iterations
    30 ui_verification     - Remind to screenshot after CSS/UI changes
    35 code_quality_gate   - Detect anti-patterns (N+1, O(n), blocking I/O, nesting)
    37 state_mutation_guard - Detect React/Python mutation anti-patterns
    40 dev_toolchain_suggest - Suggest lint/format/typecheck per language
    45 large_file_helper   - Line range guidance for big files
    48 crawl4ai_promo      - Promote crawl4ai over WebFetch for web content
    50 tool_awareness      - Remind about Playwright, Zen MCP, WebSearch, Task agents

  TRACKERS (55-80):
    55 scratch_enforcer    - Detect repetitive patterns, suggest scripts
    60 auto_learn          - Capture lessons from errors, quality hints
    65 velocity_tracker    - Detect oscillation/spinning patterns
    70 info_gain_tracker   - Detect reads without progress

ARCHITECTURE:
  - Hooks register via @register_hook(name, matcher, priority)
  - Lower priority = runs first
  - All hooks run (no blocking for PostToolUse)
  - Contexts are aggregated and returned
  - Single state load/save per invocation
"""

import _lib_path  # noqa: F401
import sys
import json
import time

# Performance: centralized configuration

from session_state import (
    load_state,
    save_state,
    SessionState,
)

# Confidence system imports (v4.0)

# Quality scanner (ruff + radon)
try:
    from _quality_scanner import scan_file as quality_scan_file, format_report

    QUALITY_SCANNER_AVAILABLE = True
except ImportError:
    QUALITY_SCANNER_AVAILABLE = False
    quality_scan_file = None
    format_report = None

# =============================================================================
# PRE-COMPILED PATTERNS (Performance: compile once at module load)
# =============================================================================

# =============================================================================
# HOOK REGISTRY (shared across modules)
# =============================================================================

from _hook_registry import HOOKS, matches_tool

# Import hook modules (triggers registration via decorators)
import _hooks_cache  # noqa: F401 - Cache hooks (priority 5-6)
import _hooks_state  # noqa: F401 - State hooks (priority 10-16)
import _hooks_quality  # noqa: F401 - Quality hooks (priority 22-50)
import _hooks_tracking  # noqa: F401 - Tracking hooks (priority 55-72)
from _hooks_tracking import SCRATCH_STATE_FILE, INFO_GAIN_STATE_FILE

# =============================================================================
# MAIN RUNNER
# =============================================================================


def _load_state_file(path) -> dict | None:
    """Load JSON state from file, returning None on error."""
    if not path.exists():
        return None
    try:
        return json.loads(path.read_text())
    except (json.JSONDecodeError, OSError):
        return None


def _save_state_file(path, data: dict) -> None:
    """Save JSON state to file, silently failing on error."""
    try:
        path.parent.mkdir(parents=True, exist_ok=True)
        path.write_text(json.dumps(data))
    except (IOError, OSError):
        pass


def _load_runner_state() -> dict:
    """Load persisted runner state from disk."""
    runner_state = {}
    if scratch := _load_state_file(SCRATCH_STATE_FILE):
        runner_state["scratch_state"] = scratch
    if info_gain := _load_state_file(INFO_GAIN_STATE_FILE):
        runner_state["info_gain_state"] = info_gain
    return runner_state


def _save_runner_state(runner_state: dict) -> None:
    """Save runner state to disk."""
    if "scratch_state" in runner_state:
        _save_state_file(SCRATCH_STATE_FILE, runner_state["scratch_state"])
    if "info_gain_state" in runner_state:
        _save_state_file(INFO_GAIN_STATE_FILE, runner_state["info_gain_state"])


def run_hooks(data: dict, state: SessionState) -> dict:
    """Run all applicable hooks and return aggregated result."""
    tool_name = data.get("tool_name", "")
    runner_state = _load_runner_state()
    contexts = []

    for name, matcher, check_func, priority in HOOKS:
        if not matches_tool(matcher, tool_name):
            continue
        try:
            result = check_func(data, state, runner_state)
            if result.context:
                contexts.append(result.context)
        except Exception as e:
            print(f"[post-runner] Hook {name} error: {e}", file=sys.stderr)

    _save_runner_state(runner_state)

    output = {"hookSpecificOutput": {"hookEventName": "PostToolUse"}}
    if contexts:
        output["hookSpecificOutput"]["additionalContext"] = "\n\n".join(contexts[:5])
    return output


# Pre-sort hooks by priority at module load (avoid re-sorting on every call)
HOOKS.sort(key=lambda x: x[3])


def main():
    """Main entry point."""
    start = time.time()

    try:
        data = json.load(sys.stdin)
    except (json.JSONDecodeError, ValueError):
        print(json.dumps({"hookSpecificOutput": {"hookEventName": "PostToolUse"}}))
        sys.exit(0)

    # Single state load
    state = load_state()

    # Run all hooks
    result = run_hooks(data, state)

    # Single state save
    save_state(state)

    # Output result
    print(json.dumps(result))

    # Debug timing (to stderr)
    elapsed = (time.time() - start) * 1000
    if elapsed > 100:
        print(f"[post-runner] Slow: {elapsed:.1f}ms", file=sys.stderr)

    sys.exit(0)


if __name__ == "__main__":
    main()
</file>

<file path="pre_compact.py">
#!/usr/bin/env python3
"""
PreCompact Hook: Fires before compaction.

Hook Type: PreCompact
Matcher: manual | auto
Latency Target: <50ms

Injects persistent context into compaction summary via stdout.
This context survives compaction and remains in Claude's memory.

Input: session_id, transcript_path, permission_mode, hook_event_name, trigger, custom_instructions
Output: stdout is added to compaction context
"""

import _lib_path  # noqa: F401
import sys
import json
from pathlib import Path

from session_state import load_state

PROJECT_ROOT = Path(__file__).parent.parent.parent


def get_critical_context(state) -> list[str]:
    """Extract context that MUST survive compaction."""
    context = []

    # Files modified this session
    if state.files_created:
        context.append(f" CREATED: {len(state.files_created)} files")
        for f in state.files_created[-3:]:
            context.append(f"   {Path(f).name}")

    if state.files_edited:
        context.append(f" EDITED: {len(state.files_edited)} files")

    # Pending work
    if state.pending_integration_greps:
        funcs = [p.get("function", "?") for p in state.pending_integration_greps[:3]]
        context.append(f" UNVERIFIED: {', '.join(funcs)}")

    # Unresolved errors
    if state.errors_unresolved:
        context.append(f" ERRORS: {len(state.errors_unresolved)} unresolved")

    # Libraries in use
    if state.libraries_used:
        context.append(f" LIBS: {', '.join(state.libraries_used[:5])}")

    return context


def main():
    try:
        data = json.load(sys.stdin)
    except (json.JSONDecodeError, ValueError):
        data = {}

    trigger = data.get("trigger", "unknown")
    state = load_state()

    lines = [f"--- PreCompact ({trigger}) ---"]

    critical = get_critical_context(state)
    if critical:
        lines.extend(critical)
    else:
        lines.append("No critical context to preserve.")

    # Output goes to compaction context
    print("\n".join(lines))
    sys.exit(0)


if __name__ == "__main__":
    main()
</file>

<file path="pre_tool_use_runner.py">
#!/usr/bin/env python3
"""
Composite PreToolUse Runner: Runs all PreToolUse hooks in a single process.

PERFORMANCE: ~35ms for 24 hooks vs ~400ms for individual processes (10x faster)

HOOKS INDEX (by priority):
  ORCHESTRATION (0-5):
    2  self_heal_enforcer  - Block unrelated work until framework errors fixed
    3  exploration_cache   - Return cached exploration results
    3  parallel_bead_delegation - Force parallel Task agents for multiple open beads
    4  parallel_nudge      - Nudge sequential Task spawns  parallel + background
    4  beads_parallel      - Nudge sequential bd commands  batch/parallel
    4  bead_enforcement    - Require in_progress bead before Edit/Write

  SAFETY (5-20):
    5  recursion_guard     - Block nested .claude/.claude paths
    10 loop_detector       - Block bash loops
    15 background_enforcer - Require background for slow commands
    18 confidence_tool_gate - Block tools at low confidence levels

  GATES (20-50):
    20 commit_gate         - Warn on git commit without upkeep
    25 tool_preference     - Nudge toward preferred tools
    30 oracle_gate         - Enforce think/council after failures
    32 confidence_external_suggestion - Suggest alternatives at low confidence
    35 integration_gate    - Require grep after function edits
    40 error_suppression   - Block until errors resolved
    45 content_gate        - Block eval/exec/SQL injection
    47 crawl4ai_preference - Suggest crawl4ai over WebFetch
    50 gap_detector        - Block edit without read

  QUALITY (55-95):
    55 production_gate     - Audit/void for .claude/ops writes
    60 deferral_gate       - Block "TODO: later" comments
    65 doc_theater_gate    - Block standalone .md files
    70 root_pollution_gate - Block home directory clutter
    75 recommendation_gate - Warn on duplicate infrastructure
    80 security_claim_gate - Warn on security-sensitive code
    85 epistemic_boundary  - Warn on unverified identifiers
    88 research_gate       - Block unverified libraries
    92 import_gate         - Warn on third-party imports
    95 modularization_nudge- Occasional modularization reminder

  SESSION (80-90):
    80 sunk_cost_detector  - Detect failure loops
    90 thinking_coach      - Detect reasoning flaws

ARCHITECTURE:
  - Hooks register via @register_hook(name, matcher, priority)
  - Lower priority = runs first
  - First DENY wins, contexts are aggregated
  - Single state load/save per invocation
"""

import _lib_path  # noqa: F401
import sys
import json
import os
import re
import time
from pathlib import Path
from typing import Optional, Callable
from session_state import (
    load_state,
    save_state,
    SessionState,
    track_block,
    clear_blocks,
    check_cascade_failure,
)
from _hook_result import HookResult

# Confidence system
from confidence import (
    check_tool_permission,
    suggest_alternatives,
    should_mandate_external,
    get_tier_info,
)
from _beads import (
    get_open_beads,
    get_in_progress_beads,
    get_independent_beads,
    generate_parallel_task_calls,
)
from _logging import log_debug

# =============================================================================
# PRE-COMPILED PATTERNS (Performance: compile once at module load)
# =============================================================================

# Bash loop detection patterns - BLOCK inefficient shell loops
# Philosophy: Block patterns that spawn shell per iteration.
_BASH_LOOP_PATTERNS = [
    # Inefficient: piping to while loop (loses exit codes, spawns subshell)
    re.compile(r"\|\s*while\b", re.IGNORECASE),
    # Inefficient: xargs spawning shell per item
    re.compile(r"\bxargs\s+.*\b(sh|bash)\s+-c\b", re.IGNORECASE),
    # Inefficient: for loop over command substitution (spawns subshell per iteration)
    re.compile(r"\bfor\s+\w+\s+in\s+\$\([^)]*\bfind\b", re.IGNORECASE),
    re.compile(r"\bfor\s+\w+\s+in\s+\$\([^)]*\bls\b", re.IGNORECASE),
    # Inefficient: process substitution to while
    re.compile(r"\bwhile\s+.*<\s*<\(", re.IGNORECASE),
]

# Efficient patterns - NEVER block (they're the solution, not the problem)
_BASH_EFFICIENT_PATTERNS = [
    re.compile(r"\bfind\s+.*-exec\b", re.IGNORECASE),  # find -exec: runs in C
    re.compile(r"\bfind\s+.*-execdir\b", re.IGNORECASE),  # safer variant
    re.compile(r"\bxargs\s+(?!.*\b(sh|bash)\s+-c)", re.IGNORECASE),  # no shell
    re.compile(r"\bparallel\b", re.IGNORECASE),  # GNU parallel
]

# Allowed loop patterns (legitimate shell loops)
_BASH_ALLOWED_PATTERNS = [
    # Small fixed iteration (for i in 1 2 3)
    re.compile(
        r"for\s+\w+\s+in\s+[\w.-]+\s+[\w.-]+(\s+[\w.-]+){0,5}\s*;", re.IGNORECASE
    ),
    # Brace expansion (for i in {1..5})
    re.compile(r"for\s+\w+\s+in\s+\{\d+\.\.\d+\}", re.IGNORECASE),
    # Glob expansion (for f in *.txt)
    re.compile(r"for\s+\w+\s+in\s+[~./\w-]*\*", re.IGNORECASE),
    # Here-string (while read <<< "string")
    re.compile(r"while\s+read.*<<<", re.IGNORECASE),
    # Python one-liner
    re.compile(r'python[3]?\s+.*-c\s+["\']', re.IGNORECASE),
    # time wrapper
    re.compile(r"\btime\s+\(", re.IGNORECASE),
    # while true/while :  (daemon loops - intentional)
    re.compile(r"\bwhile\s+(true|:)\s*;", re.IGNORECASE),
    # until with simple condition
    re.compile(r"\buntil\s+\[", re.IGNORECASE),
]

# Script nudge loop patterns (simpler set)
_SCRIPT_NUDGE_PATTERNS = [
    re.compile(r"\bfor\s+\w+\s+in\b", re.IGNORECASE),
    re.compile(r"\bwhile\s+", re.IGNORECASE),
    re.compile(r"\bxargs\b", re.IGNORECASE),
    re.compile(r"\|\s*while\b", re.IGNORECASE),
]

# Heredoc detection - matches << 'DELIM', << "DELIM", << DELIM, <<-DELIM variants
_HEREDOC_PATTERN = re.compile(r"<<-?\s*['\"]?(\w+)['\"]?")


def strip_heredoc_content(command: str) -> str:
    """Extract only the shell command portion, excluding heredoc content.

    For 'cat > file << EOF\\ncontent\\nEOF', returns 'cat > file << EOF'.
    This prevents false positives when heredoc content mentions slow commands.
    """
    match = _HEREDOC_PATTERN.search(command)
    if not match:
        return command

    # Return everything up to and including the heredoc delimiter declaration
    heredoc_start = match.end()
    return command[:heredoc_start]


# Thinking coach flaw patterns
_FLAW_PATTERNS = [
    (re.compile(r"(don't|no) need to (read|check|verify)", re.IGNORECASE), "shortcut"),
    (re.compile(r"I (assume|believe) (the|this)", re.IGNORECASE), "assumption"),
    (
        re.compile(
            r"(this|that) (should|will) (definitely\s+)?(work|fix)", re.IGNORECASE
        ),
        "overconfidence",
    ),
]

# =============================================================================
# HOOK REGISTRY
# =============================================================================

# Format: (name, matcher_pattern, check_function, priority)
# Lower priority = runs first. Blocks stop execution.
# matcher_pattern: None = all tools, str = regex pattern
HOOKS: list[tuple[str, Optional[str], Callable, int]] = []


def register_hook(name: str, matcher: Optional[str], priority: int = 50):
    """Decorator to register a hook check function.

    Hooks can be disabled via environment variable:
        CLAUDE_HOOK_DISABLE_<NAME>=1

    Example:
        CLAUDE_HOOK_DISABLE_CONTENT_GATE=1 claude
    """

    def decorator(func: Callable[[dict, SessionState], HookResult]):
        # Check if hook is disabled via environment variable
        env_key = f"CLAUDE_HOOK_DISABLE_{name.upper()}"
        if os.environ.get(env_key, "0") == "1":
            return func  # Skip registration
        HOOKS.append((name, matcher, func, priority))
        return func

    return decorator


# =============================================================================
# HOOK IMPLEMENTATIONS (inline for now, can be split to modules later)
# =============================================================================


@register_hook("loop_detector", "Bash", priority=10)
def check_loop_detector(data: dict, state: SessionState) -> HookResult:
    """Block inefficient bash loops, allow efficient alternatives like find -exec."""
    tool_input = data.get("tool_input", {})
    command = tool_input.get("command", "")
    description = tool_input.get("description", "")

    if not command:
        return HookResult.approve()

    # SUDO bypass (pre-computed in run_hooks)
    if "SUDO LOOP" in description.upper() or "SUDO_LOOP" in description.upper():
        return HookResult.approve()
    if data.get("_sudo_bypass"):
        return HookResult.approve()

    # Strip heredocs first, then quotes
    check_cmd = strip_heredoc_content(command)
    check_cmd = re.sub(r"'[^']*'", "'Q'", check_cmd)
    check_cmd = re.sub(r'"[^"]*"', '"Q"', check_cmd)

    # FIRST: Allow efficient patterns unconditionally (find -exec, xargs, parallel)
    # These are the SOLUTION, not the problem - never block them
    for pattern in _BASH_EFFICIENT_PATTERNS:
        if pattern.search(check_cmd):
            return HookResult.approve()

    # SECOND: Allow legitimate shell loop patterns
    for pattern in _BASH_ALLOWED_PATTERNS:
        if pattern.search(check_cmd):
            return HookResult.approve()

    # THIRD: Block only inefficient patterns (piping to while, for over $(find), etc.)
    for pattern in _BASH_LOOP_PATTERNS:
        match = pattern.search(check_cmd)
        if match:
            return HookResult.deny(
                f" INEFFICIENT LOOP: `{match.group(0)}` "
                " Use find -exec/xargs/parallel. SUDO LOOP to bypass."
            )
    return HookResult.approve()


@register_hook("python_path_enforcer", "Bash", priority=12)
def check_python_path_enforcer(data: dict, state: SessionState) -> HookResult:
    """Suggest venv python usage instead of system python (soft nudge, not blocking)."""
    tool_input = data.get("tool_input", {})
    command = tool_input.get("command", "")

    project_dir = os.environ.get("CLAUDE_PROJECT_DIR", str(Path.home()))
    venv_python = f"{project_dir}/.claude/.venv/bin/python"

    # Only suggest if venv exists
    if not os.path.exists(venv_python):
        return HookResult.approve()

    # Pattern: bare python/pip at start or after shell operators (exclude heredoc content)
    cmd_to_check = strip_heredoc_content(command)
    bare_python = re.search(r"(^|&&|\|\||;|\|)\s*(python3?|pip3?)\s", cmd_to_check)

    if bare_python and ".venv/bin" not in cmd_to_check:
        venv_bin = f"{project_dir}/.claude/.venv/bin"
        # Soft nudge instead of block - suggest but allow
        return HookResult.approve(
            f" Tip: Use `{venv_bin}/python` for consistent deps"
        )
    return HookResult.approve()


@register_hook("script_nudge", "Bash", priority=14)
def check_script_nudge(data: dict, state: SessionState) -> HookResult:
    """Suggest writing scripts for complex manual work."""
    tool_input = data.get("tool_input", {})
    command = tool_input.get("command", "")

    PIPE_THRESHOLD = 3

    # Strip heredoc content to avoid false positives
    cmd_to_check = strip_heredoc_content(command)

    # Count pipes
    pipe_count = cmd_to_check.count("|")
    if pipe_count >= PIPE_THRESHOLD:
        return HookResult.approve(
            f" SCRIPT OPPORTUNITY: {pipe_count} pipes detected\n"
            f" Consider: .claude/tmp/solve_$(date +%s).py"
        )

    # Check for loop patterns (use pre-compiled patterns)
    for pattern in _SCRIPT_NUDGE_PATTERNS:
        if pattern.search(cmd_to_check):
            return HookResult.approve(
                " SCRIPT OPPORTUNITY: loop/iteration detected\n"
                " Consider: .claude/tmp/solve_$(date +%s).py"
            )
    return HookResult.approve()


@register_hook("background_enforcer", "Bash", priority=15)
def check_background_enforcer(data: dict, state: SessionState) -> HookResult:
    """Enforce background execution for slow commands (unless truncated/fast)."""
    tool_input = data.get("tool_input", {})
    command = tool_input.get("command", "")
    run_in_background = tool_input.get("run_in_background", False)

    if run_in_background:
        return HookResult.approve()

    SLOW_COMMANDS = [
        "npm install",
        "npm ci",
        "npm run build",
        "npm test",
        "yarn install",
        "yarn build",
        "yarn test",
        "pip install",
        "pip3 install",
        "cargo build",
        "cargo test",
        "go build",
        "go test",
        "make",
        "cmake",
        "docker build",
        "docker-compose up",
        "tsc",
        "webpack",
        "vite build",
        "pytest",
        "python -m pytest",
    ]

    # Patterns that truncate output or are inherently fast
    FAST_PATTERNS = [
        "| head",  # Terminates after N lines
        "|head",
        "| tail",  # Only outputs last N lines (still reads all, but fast enough)
        "|tail",
        "--help",  # Instant help output
        "-h ",  # Short help flag (with space to avoid false matches)
        "--version",  # Instant version output
        "-V ",  # Short version flag
        "timeout ",  # Explicit timeout wrapper
    ]

    # Strip heredoc content to avoid false positives on content mentioning slow commands
    cmd_to_check = strip_heredoc_content(command).lower()

    # Check if command has fast/truncating patterns - allow foreground
    for fast in FAST_PATTERNS:
        if fast in cmd_to_check:
            return HookResult.approve()

    for slow in SLOW_COMMANDS:
        if slow in cmd_to_check:
            return HookResult.deny(
                f" BACKGROUND REQUIRED: `{slow}` is slow  run_in_background=true"
            )
    return HookResult.approve()


@register_hook("probe_gate", "Bash", priority=18)
def check_probe_gate(data: dict, state: SessionState) -> HookResult:
    """Suggest probing unfamiliar library APIs before using them."""
    tool_input = data.get("tool_input", {})
    command = tool_input.get("command", "")

    # Libraries that benefit from runtime probing
    PROBEABLE_LIBS = {
        "pandas": "DataFrame, Series methods",
        "polars": "LazyFrame, expressions",
        "numpy": "array operations",
        "requests": "Response object",
        "httpx": "async client",
        "boto3": "client/resource methods",
        "anthropic": "messages API",
        "openai": "chat completions",
        "playwright": "page methods",
        "fastapi": "app, router",
        "sqlalchemy": "session, query",
    }

    PYTHON_RUN_PATTERNS = [r"python3?\s+", r"pytest", r"ipython"]

    # Check if Python-related command
    is_python_cmd = any(re.search(p, command) for p in PYTHON_RUN_PATTERNS)
    if not is_python_cmd:
        return HookResult.approve()

    # Extract library mentions
    found_libs = []
    for lib, api_hint in PROBEABLE_LIBS.items():
        if re.search(rf"\b{lib}\b", command, re.IGNORECASE):
            # Check if already probed this session
            probed = getattr(state, "probed_libs", [])
            if lib.lower() not in [p.lower() for p in probed]:
                found_libs.append((lib, api_hint))

    if found_libs and len(found_libs) <= 2:
        libs = ", ".join(lib for lib, _ in found_libs[:2])
        return HookResult.approve(
            f' PROBE? Unfamiliar: {libs}  `probe "<lib>.<obj>"`'
        )
    return HookResult.approve()


@register_hook("commit_gate", "Bash", priority=20)
def check_commit_gate(data: dict, state: SessionState) -> HookResult:
    """Block git commit without upkeep."""
    tool_input = data.get("tool_input", {})
    command = tool_input.get("command", "")

    if "git commit" not in command:
        return HookResult.approve()

    # Check if upkeep was run recently
    from session_state import get_turns_since_op

    turns_since = get_turns_since_op(state, "upkeep")

    if turns_since > 20:
        return HookResult.approve(
            " COMMIT GATE: Consider running `upkeep` before committing."
        )
    return HookResult.approve()


@register_hook("tool_preference", "Bash|TodoWrite", priority=25)
def check_tool_preference(data: dict, state: SessionState) -> HookResult:
    """Nudge toward preferred tools."""
    tool_name = data.get("tool_name", "")
    tool_input = data.get("tool_input", {})

    if tool_name == "TodoWrite":
        return HookResult.approve(
            " Consider using `bd` (beads) instead of TodoWrite for persistent task tracking."
        )

    if tool_name == "Bash":
        command = tool_input.get("command", "")
        # Prefer Read over cat
        if command.startswith("cat ") and "|" not in command:
            return HookResult.approve(
                " Prefer `Read` tool over `cat` for reading files."
            )
        # Prefer Grep over grep
        if command.startswith(("grep ", "rg ")) and not any(
            x in command for x in ["|", "&&", ";"]
        ):
            return HookResult.approve(
                " Prefer `Grep` tool over bash grep for searching."
            )
    return HookResult.approve()


@register_hook("hf_cli_redirect", "Bash", priority=26)
def check_hf_cli_redirect(data: dict, state: SessionState) -> HookResult:
    """Block deprecated huggingface-cli, redirect to hf command."""
    command = data.get("tool_input", {}).get("command", "")
    if "huggingface-cli" in command:
        return HookResult.deny(
            "**BLOCKED**: `huggingface-cli` is deprecated.\n"
            "Use `hf` instead (e.g., `hf auth login`, `hf auth whoami`).\n"
            "The `hf` command is installed at `~/.local/bin/hf`."
        )
    return HookResult.approve()


@register_hook("sunk_cost_detector", None, priority=80)
def check_sunk_cost(data: dict, state: SessionState) -> HookResult:
    """Detect sunk cost trap."""
    from session_state import check_sunk_cost as _check

    is_trapped, message = _check(state)
    if is_trapped:
        return HookResult.approve(message)
    return HookResult.approve()


@register_hook("thinking_coach", None, priority=90)
def check_thinking_coach(data: dict, state: SessionState) -> HookResult:
    """Analyze thinking blocks for reasoning flaws."""
    from synapse_core import extract_thinking_blocks

    tool_name = data.get("tool_name", "")
    transcript_path = data.get("transcript_path", "")

    # Skip for read-only tools
    if tool_name in {"Read", "Glob", "Grep", "TodoWrite", "BashOutput"}:
        return HookResult.approve()

    if not transcript_path:
        return HookResult.approve()

    thinking_blocks = extract_thinking_blocks(transcript_path)
    if not thinking_blocks:
        return HookResult.approve()

    # Quick pattern check
    combined = " ".join(thinking_blocks[-2:])[-1000:]

    # Use pre-compiled patterns from module level
    for pattern, flaw_type in _FLAW_PATTERNS:
        if pattern.search(combined):
            return HookResult.approve(
                f" THINKING COACH: Detected `{flaw_type}` pattern. Verify before proceeding."
            )
    return HookResult.approve()


# =============================================================================
# READ CACHE (Priority 2) - Memoize file reads
# =============================================================================


@register_hook("read_cache", "Read", priority=2)
def check_read_cache(data: dict, state: SessionState) -> HookResult:
    """
    Return cached file content if file hasn't changed.

    Uses mtime-based validation for fast checks.
    Invalidated by Write/Edit hooks in post_tool_use_runner.
    """
    tool_input = data.get("tool_input", {})
    file_path = tool_input.get("file_path", "")

    if not file_path:
        return HookResult.approve()

    # Check for partial reads - don't cache those
    if tool_input.get("offset") or tool_input.get("limit"):
        return HookResult.approve()

    try:
        from cache.read_cache import check_read_cache as get_cached

        cached_content = get_cached(file_path)
        if cached_content:
            # Return cached content as context
            from pathlib import Path

            filename = Path(file_path).name
            return HookResult.approve_with_context(
                f" **CACHED READ** ({filename})\n"
                f"File unchanged since last read. Cached content:\n\n"
                f"```\n{cached_content[:50000]}\n```\n"
                f"_(Use `fresh` in prompt to force re-read)_"
            )
    except Exception as e:
        log_debug("pre_tool_use_runner", f"read cache lookup failed: {e}")
    return HookResult.approve()


# =============================================================================
# SELF-HEAL ENFORCER (Priority 2) - Framework must fix itself first
# =============================================================================


@register_hook("self_heal_enforcer", None, priority=2)
def check_self_heal_enforcer(data: dict, state: SessionState) -> HookResult:
    """
    Block unrelated work when framework self-heal is required.

    TRIGGER: When a tool fails on .claude/ paths, self_heal_required is set.
    BEHAVIOR:
      - Attempts 1-2: Nudge toward fixing the framework error
      - Attempt 3: Hard block with escalation to user
    ALLOWED: Read, Grep, Glob (investigation), and operations on .claude/ paths
    BYPASS: SUDO clears self-heal requirement
    """
    if not getattr(state, "self_heal_required", False):
        return HookResult.approve()

    # SUDO bypass - clear self-heal and continue
    if data.get("_sudo_bypass"):
        state.self_heal_required = False
        state.self_heal_target = ""
        state.self_heal_error = ""
        state.self_heal_attempts = 0
        return HookResult.approve()

    tool_name = data.get("tool_name", "")
    tool_input = data.get("tool_input", {})

    # Always allow investigation tools
    if tool_name in ("Read", "Grep", "Glob", "LS"):
        return HookResult.approve()

    # Always allow operations targeting .claude/ (self-heal attempts)
    target_path = ""
    if tool_name == "Edit":
        target_path = tool_input.get("file_path", "")
    elif tool_name == "Write":
        target_path = tool_input.get("file_path", "")
    elif tool_name == "Bash":
        target_path = tool_input.get("command", "")

    if ".claude/" in target_path or ".claude\\" in target_path:
        # Track attempt
        state.self_heal_attempts = getattr(state, "self_heal_attempts", 0) + 1
        return HookResult.approve()

    # Unrelated work - escalate based on attempts
    attempts = getattr(state, "self_heal_attempts", 0)
    target = getattr(state, "self_heal_target", "unknown")
    error = getattr(state, "self_heal_error", "unknown error")
    max_attempts = getattr(state, "self_heal_max_attempts", 3)

    if attempts >= max_attempts:
        # Hard block - escalate to user
        return HookResult.deny(
            f" **SELF-HEAL BLOCKED** ({attempts}/{max_attempts}): `{target}` - {error[:80]}. Fix or SUDO."
        )

    # Soft nudge - remind but allow
    return HookResult.approve(
        f" Self-heal ({attempts + 1}/{max_attempts}): `{target}` - {error[:60]}"
    )


# =============================================================================
# EXPLORATION CACHE (Priority 3) - Memoize Explore agent calls
# =============================================================================


_CACHE_BYPASS_KEYWORDS = frozenset(["force", "fresh", "re-explore", "bypass cache"])
_GROUNDING_KEYWORDS = (
    "tech stack",
    "framework",
    "what is this project",
    "project structure",
    "dependencies",
    "entry point",
    "how is this project",
    "what does this project use",
)


def _check_grounding_cache(prompt_lower: str, project_path: str) -> str | None:
    """Check grounding cache for common grounding queries."""
    if not any(kw in prompt_lower for kw in _GROUNDING_KEYWORDS):
        return None
    try:
        from cache.grounding_analyzer import get_or_create_grounding

        grounding = get_or_create_grounding(Path(project_path))
        return grounding.to_markdown() if grounding else None
    except Exception:
        return None


@register_hook("exploration_cache", "Task", priority=3)
def check_exploration_cache(data: dict, state: SessionState) -> HookResult:
    """Return cached exploration results for Explore agents."""
    tool_input = data.get("tool_input", {})
    if tool_input.get("subagent_type", "").lower() != "explore":
        return HookResult.approve()

    prompt = tool_input.get("prompt", "")
    if not prompt:
        return HookResult.approve()

    prompt_lower = prompt.lower()
    if any(kw in prompt_lower for kw in _CACHE_BYPASS_KEYWORDS):
        return HookResult.approve()

    try:
        from project_detector import detect_project

        project_info = detect_project()
        if not project_info or not project_info.get("path"):
            return HookResult.approve()
        project_path = project_info["path"]
    except Exception:
        return HookResult.approve()

    # Check exploration cache
    try:
        from cache.exploration_cache import check_exploration_cache as get_cached

        if cached := get_cached(project_path, prompt):
            return HookResult.approve(cached)
    except Exception as e:
        log_debug("pre_tool_use_runner", f"exploration cache lookup failed: {e}")

    # Check grounding cache
    if grounding := _check_grounding_cache(prompt_lower, project_path):
        return HookResult.approve(grounding)

    return HookResult.approve()


# Agent types that benefit from background execution
_LONG_RUNNING_AGENTS = {
    "explore": "exploring large codebases",
    "plan": "generating detailed plans",
    "code-reviewer": "comprehensive code review",
    "deep-security": "security audits",
    "scout": "codebase exploration",
}


def _track_background_task(
    state: SessionState, subagent_type: str, prompt: str
) -> None:
    """Record background task for later check-in reminder."""
    if not hasattr(state, "background_tasks"):
        state.background_tasks = []
    state.background_tasks = (
        state.background_tasks
        + [{"type": subagent_type, "prompt": prompt[:50], "turn": state.turn_count}]
    )[-5:]


def _update_task_counters(state: SessionState, prompt: str) -> None:
    """Update sequential task detection counters."""
    current_turn = state.turn_count
    if state.last_task_turn != current_turn:
        if state.last_task_turn > 0 and state.task_spawns_this_turn == 1:
            state.consecutive_single_tasks += 1
        elif state.task_spawns_this_turn > 1:
            state.consecutive_single_tasks = 0
        state.task_spawns_this_turn = 0
        state.last_task_turn = current_turn
    state.task_spawns_this_turn += 1
    if prompt:
        state.task_prompts_recent = (state.task_prompts_recent + [prompt[:100]])[-5:]


@register_hook("parallel_nudge", "Task", priority=4)
def check_parallel_nudge(data: dict, state: SessionState) -> HookResult:
    """Nudge sequential Task spawns toward parallel execution + background promotion."""
    tool_input = data.get("tool_input", {})
    prompt = tool_input.get("prompt", "")
    subagent_type = tool_input.get("subagent_type", "").lower()

    if tool_input.get("resume"):
        return HookResult.approve()

    if tool_input.get("run_in_background"):
        _track_background_task(state, subagent_type, prompt)
        return HookResult.approve()

    messages = []
    if subagent_type in _LONG_RUNNING_AGENTS:
        messages.append(
            f" **Background opportunity**: {subagent_type} agents can run with "
            f"`run_in_background: true` - continue working while it runs, check with TaskOutput later."
        )

    _update_task_counters(state, prompt)

    # Multiple tasks this turn = good parallel behavior
    if state.task_spawns_this_turn > 1:
        state.consecutive_single_tasks = 0
        return (
            HookResult.approve("\n".join(messages))
            if messages
            else HookResult.approve()
        )

    # Sequential single-Task pattern
    if state.consecutive_single_tasks >= 3:
        state.parallel_nudge_count += 1
        messages.insert(
            0,
            " **PARALLEL AGENTS**: 3+ sequential Tasks detected. "
            "Spawn ALL independent Tasks in ONE message for concurrent execution.",
        )
    elif state.consecutive_single_tasks >= 2:
        state.parallel_nudge_count += 1
        messages.insert(
            0,
            " **Parallel opportunity**: Multiple independent Tasks? Spawn them all in one message.",
        )

    return HookResult.approve("\n".join(messages)) if messages else HookResult.approve()


@register_hook("beads_parallel", "Bash", priority=4)
def check_beads_parallel(data: dict, state: SessionState) -> HookResult:
    """
    Nudge sequential beads (bd) commands toward parallel execution.

    PATTERN: Multiple bd create/update/close commands should be batched or parallelized.
    """
    global _BD_CACHE, _BD_CACHE_TURN

    tool_input = data.get("tool_input", {})
    command = tool_input.get("command", "")

    # Only care about beads commands
    if not re.search(r"\bbd\s+(create|update|close|dep)", command):
        return HookResult.approve()

    # Invalidate cache - bd state is changing
    _BD_CACHE = {}
    _BD_CACHE_TURN = 0

    # Track beads commands
    if not hasattr(state, "recent_beads_commands"):
        state.recent_beads_commands = []

    current_turn = state.turn_count

    # Clean old entries (older than 3 turns)
    state.recent_beads_commands = [
        cmd
        for cmd in state.recent_beads_commands
        if current_turn - cmd.get("turn", 0) <= 3
    ]

    # Check for sequential beads pattern
    recent_count = len(state.recent_beads_commands)

    # Record this command
    state.recent_beads_commands.append({"cmd": command[:50], "turn": current_turn})

    # Nudge after 2+ recent beads commands
    if recent_count >= 2:
        # Check if these could be batched
        if "bd close" in command:
            return HookResult.approve(
                " **BEADS BATCH**: Multiple bd commands detected. "
                "`bd close` supports multiple IDs: `bd close id1 id2 id3`. "
                "Batch operations are faster than sequential."
            )
        elif "bd create" in command:
            return HookResult.approve(
                " **BEADS PARALLEL**: Multiple bd create commands? "
                "Run them in parallel Bash calls in one message, or use Task agents with run_in_background."
            )

    return HookResult.approve()


# =============================================================================
# BEAD-ENFORCED PARALLEL WORKFLOW
# =============================================================================


@register_hook("bead_enforcement", "Edit|Write", priority=4)
def check_bead_enforcement(data: dict, state: SessionState) -> HookResult:
    """
    Enforce bead tracking for substantive work.

    HARD BLOCKS Edit/Write on project files without an in_progress bead.

    SAFEGUARDS:
    - Grace period: First 2 turns of session get nudge, not block
    - Trivial files: README, CHANGELOG, docs skip blocking
    - Cascade protection: If bd binary fails, degrade to nudge
    - Small edits: Single-line changes get nudge, not block
    - SUDO bypass always available
    """
    # SUDO bypass
    if data.get("_sudo_bypass"):
        return HookResult.approve()

    tool_name = data.get("tool_name", "")
    tool_input = data.get("tool_input", {})
    file_path = tool_input.get("file_path", "")

    if not file_path:
        return HookResult.approve()

    # === SKIP PATTERNS (always allowed) ===
    skip_patterns = [
        r"\.claude/",
        r"\.git/",
        r"/tmp/",
        r"\.env",
        r"package-lock\.json",
        r"\.lock$",
        r"node_modules/",
        r"__pycache__/",
    ]
    if any(re.search(p, file_path) for p in skip_patterns):
        return HookResult.approve()

    # === TRIVIAL FILE PATTERNS (nudge only, no block) ===
    trivial_patterns = [
        r"README",
        r"CHANGELOG",
        r"LICENSE",
        r"\.md$",  # Markdown docs
        r"\.txt$",  # Plain text
        r"\.json$",  # Config files
        r"\.ya?ml$",  # YAML config
        r"\.toml$",  # TOML config
    ]
    is_trivial = any(re.search(p, file_path, re.IGNORECASE) for p in trivial_patterns)

    # === SMALL EDIT CHECK (for Edit tool) ===
    is_small_edit = False
    if tool_name == "Edit":
        old_string = tool_input.get("old_string", "")
        new_string = tool_input.get("new_string", "")
        # Small edit = less than 5 lines changed
        old_lines = len(old_string.split("\n"))
        new_lines = len(new_string.split("\n"))
        is_small_edit = max(old_lines, new_lines) <= 5

    # === GRACE PERIOD (first 2 turns) ===
    is_grace_period = state.turn_count <= 2

    # === CHECK FOR IN_PROGRESS BEADS ===
    in_progress = get_in_progress_beads(state)

    if in_progress:
        # Reset enforcement counter - user is tracking work properly
        if hasattr(state, "bead_enforcement_blocks"):
            state.bead_enforcement_blocks = 0
        return HookResult.approve()

    # No active bead - determine enforcement level
    # Track enforcement attempts for cascade detection
    if not hasattr(state, "bead_enforcement_blocks"):
        state.bead_enforcement_blocks = 0

    # === DEGRADED MODE (bd binary failed or cascade) ===
    open_beads = get_open_beads(state)
    bd_failed = open_beads == [] and state.bead_enforcement_blocks >= 3

    if bd_failed:
        # bd might be broken - degrade to nudge
        return HookResult.approve(
            " **BEAD TRACKING**: Consider `bd create` for tracking. "
            "(Degraded mode - bd may be unavailable)"
        )

    # === SOFT ENFORCEMENT (nudge only) ===
    if is_grace_period or is_trivial or is_small_edit:
        return HookResult.approve(
            " **BEAD RECOMMENDED**: No in_progress bead. Consider:\n"
            '`bd create --title="..." && bd update <id> --status=in_progress`'
        )

    # === HARD BLOCK ===
    state.bead_enforcement_blocks = state.bead_enforcement_blocks + 1

    return HookResult.deny(
        " **BEAD REQUIRED**: Run `bd create` + `bd update <id> --status=in_progress` first. SUDO to bypass."
    )


@register_hook("parallel_bead_delegation", "Task", priority=3)
def check_parallel_bead_delegation(data: dict, state: SessionState) -> HookResult:
    """
    Force parallel Task delegation when multiple beads are open.

    SAFEGUARDS:
    - Dependency check: Only suggests independent beads (no blockers)
    - Max 4 agents: Prevents overwhelming parallelism
    - Recency filter: Prioritizes recently updated beads
    - Generated structure: Provides copy-pasteable Task calls
    - Sequential detection: Uses shared counter with parallel_nudge

    NOTE: Does NOT update task_spawns_this_turn - parallel_nudge handles that.
    Uses consecutive_single_tasks for escalation (shared counter).
    """
    tool_input = data.get("tool_input", {})

    # Skip if already running in background or resuming
    if tool_input.get("run_in_background") or tool_input.get("resume"):
        return HookResult.approve()

    # Get independent beads (filtered for parallel work)
    independent_beads = get_independent_beads(state)
    bead_count = len(independent_beads)

    if bead_count < 2:
        return HookResult.approve()

    # Use shared counter - consecutive_single_tasks tracks sequential single-Task turns
    # This counter is managed by parallel_nudge (priority 4); we just read and escalate

    # Generate the parallel task structure
    task_structure = generate_parallel_task_calls(independent_beads)

    # Escalate based on shared sequential pattern counter
    # Note: parallel_nudge (priority 4) runs after us and updates the counter
    if state.consecutive_single_tasks >= 3:
        # HARD BLOCK after 3+ sequential singles with beads available
        return HookResult.deny(
            f" **PARALLEL REQUIRED**: {bead_count} beads ready. Spawn multiple Tasks in ONE message. SUDO to bypass.\n{task_structure}"
        )
    elif state.consecutive_single_tasks >= 2:
        # Strong nudge at 2
        return HookResult.approve(
            f" {bead_count} beads ready for parallel:\n{task_structure}"
        )
    elif bead_count >= 2:
        # Soft nudge when beads available
        bead_list = ", ".join(f"`{b.get('id', '?')[:12]}`" for b in independent_beads)
        return HookResult.approve(f" Parallel: {bead_list}")

    return HookResult.approve()


@register_hook("recursion_guard", "Edit|Write|Bash", priority=5)
def check_recursion_guard(data: dict, state: SessionState) -> HookResult:
    """Block catastrophic folder duplication."""

    tool_name = data.get("tool_name", "")
    tool_input = data.get("tool_input", {})

    RECURSIVE_PATTERNS = [
        r"\.claude/.*\.claude/",
        r"projects/[^/]+/projects/",
        r"\.claude/tmp/.*\.claude/tmp/",
    ]

    paths_to_check = []

    if tool_name in ("Write", "Edit"):
        file_path = tool_input.get("file_path", "")
        if file_path:
            paths_to_check.append(file_path)
    elif tool_name == "Bash":
        command = tool_input.get("command", "")
        # Strip heredoc content to avoid matching paths in heredoc body
        cmd_to_check = strip_heredoc_content(command)
        # Extract paths from mkdir, touch, cp, mv
        paths_to_check.extend(
            re.findall(r'mkdir\s+(?:-p\s+)?["\']?([^"\';\s&|]+)', cmd_to_check)
        )
        paths_to_check.extend(
            re.findall(r'["\']?(/[^"\';\s&|]+|\.claude/[^"\';\s&|]+)', cmd_to_check)
        )

    for path in paths_to_check:
        for pattern in RECURSIVE_PATTERNS:
            if re.search(pattern, path):
                return HookResult.deny(
                    f" **RECURSION CATASTROPHE BLOCKED**\n"
                    f"Path: {path}\n"
                    f"Use flat paths instead of nested duplicates."
                )
    return HookResult.approve()


# =============================================================================
# CONFIDENCE SYSTEM GATES
# =============================================================================


@register_hook("confidence_tool_gate", None, priority=18)
def check_confidence_tool_gate(data: dict, state: SessionState) -> HookResult:
    """Gate tool usage based on confidence level."""
    # SUDO bypass
    if data.get("_sudo_bypass"):
        return HookResult.approve()

    tool_name = data.get("tool_name", "")
    tool_input = data.get("tool_input", {})

    # Framework maintenance bypass - can't fix confidence system if it blocks itself
    file_path = tool_input.get("file_path", "")
    if ".claude/" in file_path:
        return HookResult.approve()

    # Skip if confidence not initialized
    if state.confidence == 0:
        return HookResult.approve()

    # Check tool permission
    is_permitted, block_message = check_tool_permission(
        state.confidence, tool_name, tool_input
    )

    if not is_permitted:
        track_block(state, "confidence_tool_gate")
        return HookResult.deny(block_message)

    # Clear blocks on successful passage
    clear_blocks(state, "confidence_tool_gate")
    return HookResult.approve()


@register_hook("oracle_gate", "Edit|Write|Bash", priority=30)
def check_oracle_gate(data: dict, state: SessionState) -> HookResult:
    """Enforce oracle consultation after repeated failures."""
    from session_state import get_turns_since_op

    tool_name = data.get("tool_name", "")
    tool_input = data.get("tool_input", {})
    # SUDO bypass
    if data.get("_sudo_bypass"):
        return HookResult.approve()

    # Skip diagnostic bash commands
    if tool_name == "Bash":
        command = tool_input.get("command", "")
        diagnostic = ["ls", "cat", "grep", "find", "echo", "pwd", "which"]
        if any(command.strip().startswith(p) for p in diagnostic):
            return HookResult.approve()
        if any(r in command for r in ["oracle", "think", "council"]):
            return HookResult.approve()

    failures = state.consecutive_failures

    # Check if oracle/think was run recently
    min_turns = min(
        get_turns_since_op(state, "oracle"),
        get_turns_since_op(state, "think"),
        get_turns_since_op(state, "council"),
    )
    if min_turns <= 5:
        return HookResult.approve()

    if failures == 2:
        return HookResult.approve(
            " **ORACLE NUDGE** (2 consecutive failures)\n"
            'Consider: `think "Why is this failing?"` before attempt #3.'
        )

    if failures >= 3:
        return HookResult.deny(
            f"**ORACLE GATE BLOCKED** (Three-Strike Rule)\n"
            f"**{failures} failures** without oracle/think consultation.\n"
            f'Run `think "Debug: <problem>"` or user says "SUDO CONTINUE".'
        )
    return HookResult.approve()


@register_hook("confidence_external_suggestion", None, priority=32)
def check_confidence_external_suggestion(data: dict, state: SessionState) -> HookResult:
    """Suggest external consultation and alternatives at low confidence."""
    # Skip if confidence not initialized or high enough
    if state.confidence == 0 or state.confidence >= 50:
        return HookResult.approve()

    tool_name = data.get("tool_name", "")
    tool_input = data.get("tool_input", {})

    # Don't suggest for diagnostic/read-only tools
    read_only_tools = {"Read", "Grep", "Glob", "WebSearch", "WebFetch", "TodoRead"}
    if tool_name in read_only_tools:
        return HookResult.approve()

    # Don't suggest for external consultation tools (that's what we're suggesting!)
    if tool_name.startswith("mcp__pal__"):
        return HookResult.approve()

    parts = []

    # Check if external consultation is mandatory
    mandatory, mandatory_msg = should_mandate_external(state.confidence)
    if mandatory:
        parts.append(mandatory_msg)

    # Suggest alternatives based on confidence
    task_desc = tool_input.get("description", "") or tool_input.get("prompt", "")[:50]
    alternatives = suggest_alternatives(state.confidence, task_desc)
    if alternatives:
        parts.append(alternatives)

    if parts:
        tier_name, emoji, _ = get_tier_info(state.confidence)
        header = (
            f"{emoji} **Low Confidence Warning: {state.confidence}% ({tier_name})**\n"
        )
        return HookResult.approve(header + "\n\n".join(parts))

    return HookResult.approve()


@register_hook("integration_gate", "Edit|Write|Task", priority=35)
def check_integration_gate(data: dict, state: SessionState) -> HookResult:
    """Enforce grep after function edits."""
    from session_state import check_integration_blindness

    tool_name = data.get("tool_name", "")
    tool_input = data.get("tool_input", {})

    # Auto-expire old pending greps (> 5 turns old)
    current_turn = state.turn_count
    state.pending_integration_greps = [
        g
        for g in state.pending_integration_greps
        if current_turn - g.get("turn", 0) <= 5
    ]

    should_block, message = check_integration_blindness(state, tool_name, tool_input)
    if should_block:
        return HookResult.deny(message)
    return HookResult.approve()


@register_hook("error_suppression_gate", "Edit|Write|MultiEdit|Task", priority=40)
def check_error_suppression(data: dict, state: SessionState) -> HookResult:
    """Block non-diagnostic tools until errors are resolved."""
    import time as time_mod

    tool_name = data.get("tool_name", "")

    # Always allow diagnostic tools
    DIAGNOSTIC_TOOLS = {
        "Read",
        "Grep",
        "Glob",
        "Bash",
        "BashOutput",
        "WebFetch",
        "WebSearch",
        "TodoWrite",
    }
    if tool_name in DIAGNOSTIC_TOOLS:
        return HookResult.approve()

    # Check for recent unresolved errors (within 5 min)
    ERROR_TTL = 300
    cutoff = time_mod.time() - ERROR_TTL
    recent_errors = [
        e for e in state.errors_unresolved if e.get("timestamp", 0) > cutoff
    ]

    if not recent_errors:
        return HookResult.approve()

    latest = recent_errors[-1]
    error_type = latest.get("type", "Unknown")[:60]

    return HookResult.deny(
        f"**ERROR SUPPRESSION BLOCKED**\n"
        f"Unresolved: {error_type}\n"
        f"Fix the error before continuing. Use Bash/Read/Grep to debug."
    )


_CRITICAL_PATTERNS = [
    (re.compile(r"\b(eval|exec)\s*\(", re.I), "Code injection (eval/exec)"),
    (re.compile(r'f["\']SELECT\s+', re.I), "SQL injection risk"),
]
_BLOCK_PATTERNS = [
    (re.compile(r"subprocess\.[^(]+\([^)]*shell\s*=\s*True", re.M), "shell=True risk"),
    (re.compile(r"except\s*:\s*$", re.M), "Bare except"),
    (re.compile(r"from\s+\w+\s+import\s+\*", re.M), "Wildcard import"),
]


def _is_content_exempt_path(file_path: str) -> bool:
    """Check if path is exempt from content checks."""
    return any(
        p in file_path for p in (".claude/lib/", ".claude/hooks/", ".claude/tmp/")
    )


def _check_python_ast(content: str) -> HookResult | None:
    """Check Python content with AST analysis. Returns deny result or None."""
    try:
        from ast_analysis import has_critical_violations

        is_critical, violations = has_critical_violations(content)
        if is_critical:
            msgs = [f"- {v.message} (line {v.line})" for v in violations[:3]]
            return HookResult.deny(
                "**CONTENT BLOCKED** (AST analysis):\n"
                + "\n".join(msgs)
                + "\nFix the vulnerabilities."
            )
    except Exception as e:
        log_debug("pre_tool_use_runner", f"AST analysis failed: {e}")
    return None


@register_hook("content_gate", "Edit|Write", priority=45)
def check_content_gate(data: dict, state: SessionState) -> HookResult:
    """Block dangerous code patterns (eval, SQL injection, etc.)."""
    tool_input = data.get("tool_input", {})
    content = tool_input.get("content", "") or tool_input.get("new_string", "")
    file_path = tool_input.get("file_path", "")

    if not content or not file_path or _is_content_exempt_path(file_path):
        return HookResult.approve()

    if file_path.endswith(".py"):
        if result := _check_python_ast(content):
            return result

    for pattern, message in _CRITICAL_PATTERNS:
        if pattern.search(content):
            return HookResult.deny(
                f"**CONTENT BLOCKED**: {message}\nFix the vulnerability."
            )

    if not data.get("_sudo_bypass") and "__init__.py" not in file_path:
        for pattern, message in _BLOCK_PATTERNS:
            if pattern.search(content):
                return HookResult.deny(
                    f"**CONTENT BLOCKED**: {message}\nSay SUDO to bypass."
                )

    return HookResult.approve()


# =============================================================================
# GOD COMPONENT GATE (Priority 48) - Prevent monolithic files
# =============================================================================


def _get_projected_content(
    tool_name: str, tool_input: dict, file_path: str
) -> str | None:
    """Get content that will exist after edit. Returns None if can't determine."""
    from pathlib import Path

    path = Path(file_path)
    if tool_name == "Write":
        return tool_input.get("content", "")
    elif tool_name == "Edit":
        if not path.exists():
            return None
        existing = path.read_text()
        old_str = tool_input.get("old_string", "")
        if old_str not in existing:
            return None
        return existing.replace(old_str, tool_input.get("new_string", ""), 1)
    return None


@register_hook("god_component_gate", "Edit|Write", priority=48)
def check_god_component_gate(data: dict, state: SessionState) -> HookResult:
    """Block edits that would create God components."""
    tool_input = data.get("tool_input", {})
    file_path = tool_input.get("file_path", "")

    if not file_path or ".claude/tmp/" in file_path or "/.claude/" in file_path:
        return HookResult.approve()
    if data.get("_sudo_bypass"):
        return HookResult.approve()

    try:
        content = _get_projected_content(
            data.get("tool_name", ""), tool_input, file_path
        )
        if not content:
            return HookResult.approve()
    except Exception:
        return HookResult.approve()

    edit_count = (
        state.get_file_edit_count(file_path)
        if hasattr(state, "get_file_edit_count")
        else 0
    )

    try:
        from analysis.god_component_detector import (
            detect_god_component,
            format_detection_message,
        )

        result = detect_god_component(file_path, content, edit_count)
        if result.severity == "block":
            msg = format_detection_message(result)
            return HookResult.deny(
                f"{msg}\nBypass: `# LARGE_FILE_OK: reason` as first line, SUDO, or use .claude/tmp/"
            )
        elif result.severity == "warn":
            return HookResult.approve_with_context(format_detection_message(result))
    except Exception as e:
        log_debug("pre_tool_use_runner", f"large file detection failed: {e}")
    return HookResult.approve()


@register_hook("gap_detector", "Edit|Write", priority=50)
def check_gap_detector(data: dict, state: SessionState) -> HookResult:
    """Block editing file without reading it first + verify old_string is current."""
    from session_state import was_file_read
    from pathlib import Path

    tool_name = data.get("tool_name", "")
    tool_input = data.get("tool_input", {})

    if tool_name != "Edit":
        return HookResult.approve()

    file_path = tool_input.get("file_path", "")
    if not file_path:
        return HookResult.approve()

    # Exceptions - scratch files skip all checks
    is_scratch = ".claude/tmp/" in file_path
    if is_scratch:
        return HookResult.approve()

    file_exists = Path(file_path).exists() if file_path else False
    if not file_exists:
        return HookResult.approve()

    old_string = tool_input.get("old_string", "")

    # ALWAYS verify old_string matches current file (prevents silent corruption)
    # This is the critical safety check - even if file was "read", context may be stale
    if old_string and len(old_string) > 10:
        try:
            with open(file_path, "r", encoding="utf-8", errors="replace") as f:
                current_content = f.read()
            if old_string not in current_content:
                filename = Path(file_path).name
                # Show a snippet of what we're looking for
                snippet = old_string[:60].replace("\n", "\\n")
                return HookResult.deny(
                    f"**STALE EDIT BLOCKED**: `old_string` not found in current `{filename}`.\n"
                    f"Looking for: `{snippet}...`\n"
                    f"Re-read the file - content may have changed."
                )
            # old_string verified - approve (implicit proof of context)
            return HookResult.approve()
        except (OSError, IOError, UnicodeDecodeError):
            pass  # Fall through to standard checks

    # Check if file was read OR already edited
    file_seen = was_file_read(state, file_path) or file_path in state.files_edited
    if file_seen:
        return HookResult.approve()

    filename = Path(file_path).name
    return HookResult.deny(
        f"**GAP DETECTED**: Editing `{filename}` without reading first.\n"
        f"Use Read tool first to understand the file structure."
    )


@register_hook("production_gate", "Write|Edit", priority=55)
def check_production_gate(data: dict, state: SessionState) -> HookResult:
    """Block stubs in production code (.claude/ops/ or .claude/lib/).

    Removed: audit+void verification requirement (failed on legacy issues).
    Kept: Stub detection (prevents incomplete code in production).
    """
    from pathlib import Path

    tool_input = data.get("tool_input", {})
    file_path = tool_input.get("file_path", "")

    if not file_path:
        return HookResult.approve()

    # SUDO bypass
    if data.get("_sudo_bypass"):
        return HookResult.approve()

    # Only check protected paths
    PROTECTED = [".claude/ops/", ".claude/lib/"]
    is_protected = any(p in file_path for p in PROTECTED)
    if not is_protected:
        return HookResult.approve()

    # Check content for stubs - these should never be in production
    content = tool_input.get("content", "") or tool_input.get("new_string", "")
    if content:
        STUB_PATTERNS = ["# TODO", "# FIXME", "raise NotImplementedError", "pass  #"]
        for pattern in STUB_PATTERNS:
            if pattern in content:
                return HookResult.deny(
                    f"**STUB BLOCKED**: `{pattern}` detected in production code.\n"
                    f"Complete implementation before writing to .claude/ops/ or .claude/lib/"
                )

    # New files: just a reminder
    if not Path(file_path).exists():
        return HookResult.approve(" New production file - lint after creation")

    return HookResult.approve()


@register_hook("deferral_gate", "Edit|Write|MultiEdit", priority=60)
def check_deferral_gate(data: dict, state: SessionState) -> HookResult:
    """Block deferral theater language."""

    tool_name = data.get("tool_name", "")
    tool_input = data.get("tool_input", {})
    # Get content
    content = ""
    if tool_name == "Write":
        content = tool_input.get("content", "")
    elif tool_name == "Edit":
        content = tool_input.get("new_string", "")

    if not content:
        return HookResult.approve()

    # Bypass
    if "SUDO DEFER" in content.upper() or data.get("_sudo_bypass"):
        return HookResult.approve()

    DEFERRAL_PATTERNS = [
        (r"#\s*(TODO|FIXME):\s*(implement\s+)?later", "TODO later"),
        (r"#\s*low\s+priority", "low priority"),
        (r"#\s*nice\s+to\s+have", "nice to have"),
        (r"#\s*could\s+(do|add)\s+later", "could do later"),
        (r"#\s*worth\s+investigating", "worth investigating"),
        (r"#\s*consider\s+adding", "consider adding"),
    ]

    for pattern, name in DEFERRAL_PATTERNS:
        if re.search(pattern, content, re.IGNORECASE):
            return HookResult.deny(
                f"**DEFERRAL THEATER BLOCKED** (Principle #19)\n"
                f"Detected: {name}\n"
                f"Either do it NOW or delete the thought. Add 'SUDO DEFER' to bypass."
            )
    return HookResult.approve()


@register_hook("doc_theater_gate", "Write", priority=65)
def check_doc_theater_gate(data: dict, state: SessionState) -> HookResult:
    """Block creation of standalone documentation files."""
    from pathlib import Path

    tool_input = data.get("tool_input", {})
    file_path = tool_input.get("file_path", "")

    if not file_path or not file_path.endswith(".md"):
        return HookResult.approve()

    if data.get("_sudo_bypass"):
        return HookResult.approve()

    # Allowed locations
    ALLOWED = [
        r"/CLAUDE\.md$",
        r"\.claude/agents/.*\.md$",  # Custom agent definitions
        r"\.claude/commands/.*\.md$",
        r"\.claude/memory/.*\.md$",
        r"\.claude/reminders/.*\.md$",
        r"\.claude/plans/.*\.md$",
        r"\.claude/rules/.*\.md$",  # Claude Code rules directory
        r"\.claude/skills/.*\.md$",  # Claude Code skills directory
        r"projects/.*/.*\.md$",
    ]
    for pattern in ALLOWED:
        if re.search(pattern, file_path):
            return HookResult.approve()

    # Doc theater patterns
    DOC_PATTERNS = ["README.md", "GUIDE.md", "SCHEMA", "DOCS.md", "ARCHITECTURE.md"]
    filename = Path(file_path).name.upper()
    for pattern in DOC_PATTERNS:
        if pattern.upper() in filename:
            return HookResult.deny(
                f"**DOC THEATER BLOCKED**\n"
                f"File: {Path(file_path).name}\n"
                f"Put docs INLINE (docstrings, comments). Say SUDO to bypass."
            )

    # Generic .md outside allowed locations
    return HookResult.deny(
        "**DOC THEATER BLOCKED**: Standalone .md outside allowed locations.\n"
        "Use .claude/memory/*.md or inline docs. Say SUDO to bypass."
    )


@register_hook("root_pollution_gate", "Edit|Write", priority=70)
def check_root_pollution_gate(data: dict, state: SessionState) -> HookResult:
    """Block files that would clutter home directory."""
    from pathlib import Path

    tool_input = data.get("tool_input", {})
    file_path = tool_input.get("file_path", "")

    if not file_path:
        return HookResult.approve()

    HOME = Path.home()
    try:
        abs_path = Path(file_path).resolve()
        if not abs_path.is_relative_to(HOME):
            return HookResult.approve()
        rel_path = abs_path.relative_to(HOME)
    except (ValueError, OSError):
        return HookResult.approve()

    parts = rel_path.parts
    if not parts:
        return HookResult.approve()

    # Allowed directories
    ALLOWED_DIRS = {"projects", ".claude", ".vscode", ".beads", ".git", "ai"}
    first = parts[0]

    if first in ALLOWED_DIRS or first.startswith("."):
        return HookResult.approve()

    # Single file at home root
    if len(parts) == 1:
        ALLOWED_FILES = {"CLAUDE.md", ".gitignore", ".claudeignore"}
        if first in ALLOWED_FILES or first.startswith("."):
            return HookResult.approve()
        return HookResult.deny(
            f"**HOME CLEANLINESS**: '{first}' would clutter home.\n"
            f"Use ~/projects/<name>/, ~/ai/<name>/, or ~/.claude/tmp/"
        )
    return HookResult.approve()


@register_hook("recommendation_gate", "Write", priority=75)
def check_recommendation_gate(data: dict, state: SessionState) -> HookResult:
    """Block duplicate functionality creation."""
    from pathlib import Path

    tool_input = data.get("tool_input", {})
    file_path = tool_input.get("file_path", "")

    if not file_path:
        return HookResult.approve()

    # Infrastructure patterns
    INFRA_PATTERNS = [
        r"setup[_-]?\w*\.sh$",
        r"bootstrap[_-]?\w*\.sh$",
        r"\.claude/hooks/\w+_gate\.py$",
        r"\.claude/ops/\w+\.py$",
    ]

    is_infra = any(re.search(p, file_path, re.IGNORECASE) for p in INFRA_PATTERNS)
    if not is_infra:
        return HookResult.approve()

    # Check if file already exists (editing vs creating)
    if Path(file_path).exists():
        return HookResult.approve()

    # For new infra files, just warn
    return HookResult.approve(
        f" Creating new infrastructure: {Path(file_path).name}\n"
        f"Read `.claude/memory/__capabilities.md` first to avoid duplication."
    )


@register_hook("security_claim_gate", "Edit|Write", priority=80)
def check_security_claim_gate(data: dict, state: SessionState) -> HookResult:
    """Require audit for security-sensitive code."""
    from pathlib import Path

    tool_name = data.get("tool_name", "")
    tool_input = data.get("tool_input", {})
    file_path = tool_input.get("file_path", "")

    content = ""
    if tool_name == "Write":
        content = tool_input.get("content", "")
    elif tool_name == "Edit":
        content = tool_input.get("new_string", "")

    # Bypass
    if "SUDO SECURITY" in content.upper() or data.get("_sudo_bypass"):
        return HookResult.approve()

    # Skip trusted paths
    EXCLUDED = [".claude/hooks/", ".claude/tmp/", ".claude/ops/"]
    if any(ex in file_path for ex in EXCLUDED):
        return HookResult.approve()

    # Security patterns in filename
    SECURITY_PATTERNS = [
        "auth",
        "login",
        "password",
        "credential",
        "token",
        "secret",
        "jwt",
        "oauth",
    ]
    path_lower = file_path.lower()
    is_security_file = any(p in path_lower for p in SECURITY_PATTERNS)

    # Security patterns in content
    CONTENT_PATTERNS = [r"password\s*=", r"secret\s*=", r"\.encrypt\(", r"\.decrypt\("]
    has_security_content = any(
        re.search(p, content, re.IGNORECASE) for p in CONTENT_PATTERNS
    )

    if is_security_file or has_security_content:
        audited = getattr(state, "audited_files", [])
        if file_path not in audited:
            return HookResult.approve(
                f" SECURITY-SENSITIVE: Consider `audit {Path(file_path).name}` before editing."
            )
    return HookResult.approve()


@register_hook("epistemic_boundary", "Edit|Write", priority=85)
def check_epistemic_boundary(data: dict, state: SessionState) -> HookResult:
    """Catch claims not backed by session evidence (AST-based)."""

    tool_input = data.get("tool_input", {})
    file_path = tool_input.get("file_path", "")

    if ".claude/tmp/" in file_path or ".claude/memory" in file_path:
        return HookResult.approve()

    # Only use AST for Python files
    if not file_path.endswith(".py"):
        return HookResult.approve()

    code = tool_input.get("new_string", "") or tool_input.get("content", "")
    if not code or len(code) < 50:
        return HookResult.approve()

    files_read = state.files_read or []

    # AST-based call extraction (ignores strings/comments, more accurate)
    from _ast_utils import extract_non_builtin_calls

    calls = extract_non_builtin_calls(code)

    if not calls:
        return HookResult.approve()

    # Check if likely sources were read
    unverified = []
    for call in list(calls)[:5]:
        found = any(call.lower() in f.lower() for f in files_read if f)
        if not found and not any(call.lower() in file_path.lower() for _ in [1]):
            unverified.append(call)

    if unverified and len(unverified) >= 2:
        return HookResult.approve(
            f" EPISTEMIC: Using {', '.join(unverified[:3])} - source files not read this session."
        )
    return HookResult.approve()


@register_hook("research_gate", "Edit|Write", priority=88)
def check_research_gate(data: dict, state: SessionState) -> HookResult:
    """Block writes using unverified external libraries."""
    # SUDO bypass
    if data.get("_sudo_bypass"):
        return HookResult.approve()

    from session_state import RESEARCH_REQUIRED_LIBS, extract_libraries_from_code

    tool_input = data.get("tool_input", {})
    file_path = tool_input.get("file_path", "")

    # Skip non-Python or scratch
    if not file_path.endswith(".py") or ".claude/tmp/" in file_path:
        return HookResult.approve()

    code = tool_input.get("new_string", "") or tool_input.get("content", "")
    if not code or len(code) < 30:
        return HookResult.approve()

    libs = extract_libraries_from_code(code)
    researched = state.libraries_researched or []

    STABLE = {
        "os",
        "sys",
        "json",
        "re",
        "pathlib",
        "typing",
        "requests",
        "pytest",
        "pydantic",
    }

    unresearched = []
    for lib in libs:
        lib_lower = lib.lower()
        if lib_lower in STABLE:
            continue
        if lib_lower in [r.lower() for r in researched]:
            continue
        if any(req.lower() in lib_lower for req in RESEARCH_REQUIRED_LIBS):
            unresearched.append(lib)

    if unresearched:
        # Store blocked libs so VERIFIED can unlock them
        state.set("research_gate_blocked_libs", unresearched[:3])
        return HookResult.deny(
            f"**RESEARCH GATE BLOCKED**\n"
            f"Unverified: {', '.join(unresearched[:3])}\n"
            f'Run `research "{unresearched[0]} API"` or say VERIFIED.'
        )
    return HookResult.approve()


@register_hook("import_gate", "Write", priority=92)
def check_import_gate(data: dict, state: SessionState) -> HookResult:
    """Warn about potentially missing imports (AST-based)."""
    tool_input = data.get("tool_input", {})
    file_path = tool_input.get("file_path", "")
    content = tool_input.get("content", "")

    if not file_path.endswith(".py") or not content:
        return HookResult.approve()

    # AST-based import extraction (handles all import forms, ignores strings/comments)
    from _ast_utils import extract_non_stdlib_imports

    third_party = extract_non_stdlib_imports(content)
    if third_party:
        return HookResult.approve(
            f" Third-party imports: {', '.join(sorted(third_party)[:5])} - ensure installed."
        )
    return HookResult.approve()


@register_hook("modularization_nudge", "Edit|Write", priority=95)
def check_modularization(data: dict, state: SessionState) -> HookResult:
    """Remind to modularize before creating code."""

    tool_input = data.get("tool_input", {})
    file_path = tool_input.get("file_path", "")

    if not file_path:
        return HookResult.approve()

    # Skip non-code files
    SKIP_EXT = {".md", ".txt", ".json", ".yaml", ".yml", ".sh", ".env"}
    ext = os.path.splitext(file_path)[1].lower()
    if ext in SKIP_EXT:
        return HookResult.approve()

    # Skip scratch
    if ".claude/tmp/" in file_path:
        return HookResult.approve()

    # Only show occasionally (every 10 edits)
    if state.turn_count % 10 != 0:
        return HookResult.approve()

    return HookResult.approve(
        " MODULARIZATION: Search first, separate concerns, use descriptive filenames."
    )


# =============================================================================
# CRAWL4AI PREFERENCE (Priority 47) - Suggest crawl4ai over WebFetch
# =============================================================================


@register_hook("crawl4ai_preference", "WebFetch", priority=47)
def suggest_crawl4ai(data: dict, state: SessionState) -> HookResult:
    """
    Proactively suggest crawl4ai MCP before WebFetch executes.

    Crawl4ai is superior for web content retrieval:
    - Full JavaScript rendering (SPAs, dynamic content)
    - Bypasses Cloudflare, bot detection, anti-scraping
    - Returns clean LLM-friendly markdown
    """
    tool_input = data.get("tool_input", {})
    url = tool_input.get("url", "")

    if not url:
        return HookResult.approve()

    # Don't spam - use session tracking
    crawl4ai_suggestions = getattr(state, "crawl4ai_suggestions", 0)
    if crawl4ai_suggestions >= 2:  # Max 2 suggestions per session
        return HookResult.approve()

    state.crawl4ai_suggestions = crawl4ai_suggestions + 1

    return HookResult.approve(
        " **Consider crawl4ai instead** - Superior for web content:\n"
        "   `mcp__crawl4ai__crawl` - JS rendering + bot bypass\n"
        "   `mcp__crawl4ai__search` - Discover related URLs\n"
        "  WebFetch proceeding, but crawl4ai handles protected sites better."
    )


# =============================================================================
# MAIN RUNNER
# =============================================================================


def matches_tool(matcher: Optional[str], tool_name: str) -> bool:
    """Check if tool matches the hook's matcher pattern."""
    if matcher is None:
        return True
    return bool(re.match(f"^({matcher})$", tool_name))


def run_hooks(data: dict, state: SessionState) -> dict:
    """Run all applicable hooks and return aggregated result."""
    tool_name = data.get("tool_name", "")

    # Pre-compute SUDO bypass once for all hooks (avoids 18 redundant transcript reads)
    transcript_path = data.get("transcript_path", "")
    if transcript_path:
        from synapse_core import check_sudo_in_transcript

        data["_sudo_bypass"] = check_sudo_in_transcript(transcript_path)
    else:
        data["_sudo_bypass"] = False

    # Hooks pre-sorted at module load

    # Collect results
    contexts = []

    for name, matcher, check_func, priority in HOOKS:
        if not matches_tool(matcher, tool_name):
            continue

        try:
            result = check_func(data, state)

            # First deny wins - but check for cascade failure first
            if result.decision == "deny":
                # Track this block for cascade detection
                track_block(state, name)

                # Check if we're in a cascade failure state
                is_cascade, escalation_msg = check_cascade_failure(state, name)
                if is_cascade:
                    # Allow with escalation instead of hard block
                    contexts.append(
                        f" **CASCADE DETECTED** ({name} blocked 3+ times):\n"
                        f"{result.reason}\n\n{escalation_msg}"
                    )
                    # Don't return deny - let the operation through with warning
                    continue

                return {
                    "hookSpecificOutput": {
                        "hookEventName": "PreToolUse",
                        "permissionDecision": "deny",
                        "permissionDecisionReason": result.reason,
                    }
                }

            # Clear cascade tracking on successful hook pass
            clear_blocks(state, name)

            # Collect contexts
            if result.context:
                contexts.append(result.context)

        except Exception as e:
            # Log error but don't block
            print(f"[runner] Hook {name} error: {e}", file=sys.stderr)

    # Build output
    output = {"hookSpecificOutput": {"hookEventName": "PreToolUse"}}
    if contexts:
        output["hookSpecificOutput"]["additionalContext"] = "\n\n".join(contexts[:3])

    return output


# Pre-sort hooks by priority at module load (avoid re-sorting on every call)
HOOKS.sort(key=lambda x: x[3])


def main():
    """Main entry point."""
    start = time.time()

    try:
        data = json.load(sys.stdin)
    except (json.JSONDecodeError, ValueError):
        print(json.dumps({"hookSpecificOutput": {"hookEventName": "PreToolUse"}}))
        sys.exit(0)

    # Single state load
    state = load_state()

    # Run all hooks
    result = run_hooks(data, state)

    # Single state save
    save_state(state)

    # Output result
    print(json.dumps(result))

    # Debug timing (to stderr)
    elapsed = (time.time() - start) * 1000
    if elapsed > 50:
        print(f"[runner] Slow: {elapsed:.1f}ms", file=sys.stderr)

    sys.exit(0)


if __name__ == "__main__":
    main()
</file>

<file path="py">
#!/bin/sh
# Python environment detector - works in both local (venv) and web (system python) environments
# Priority: 1) Local venv  2) python3  3) python

set -e

# Resolve script directory (handles symlinks)
SCRIPT_DIR="$(cd "$(dirname "$0")" 2>/dev/null && pwd)" || SCRIPT_DIR=""

# Check venv first (only if SCRIPT_DIR resolved)
if [ -n "$SCRIPT_DIR" ]; then
    VENV_PYTHON="$SCRIPT_DIR/../.venv/bin/python"
    if [ -x "$VENV_PYTHON" ]; then
        exec "$VENV_PYTHON" "$@"
    fi
fi

# Fallback to system Python
if command -v python3 >/dev/null 2>&1; then
    exec python3 "$@"
elif command -v python >/dev/null 2>&1; then
    exec python "$@"
fi

echo "ERROR: No Python interpreter found (checked: venv, python3, python)" >&2
exit 1
</file>

<file path="session_cleanup.py">
#!/usr/bin/env python3
"""
Session Cleanup Hook v3: SessionEnd hook for cleanup and persistence.

This hook fires when Claude Code session ends and:
- Persists learned patterns to long-term memory
- Updates lessons.md with session insights
- Cleans up .claude/tmp/ temporary files
- Generates session summary for telemetry
- Saves final state snapshot

Silent by default - performs cleanup in background.
"""

import _lib_path  # noqa: F401
from _logging import log_debug
import sys
import json
import time
import os
import fcntl
import tempfile
from pathlib import Path
from datetime import datetime

# Import the state machine
from session_state import (
    load_state,
    save_state,
    get_session_summary,
    MEMORY_DIR,
    prepare_handoff,
    complete_feature,
    extract_work_from_errors,
)

# Import project-aware state management
try:
    from project_detector import get_current_project
    from project_state import get_project_memory_dir

    PROJECT_AWARE = True
except ImportError:
    PROJECT_AWARE = False

# =============================================================================
# CONFIGURATION
# =============================================================================

SCRATCH_DIR = (
    Path(__file__).resolve().parent.parent / "tmp"
)  # .claude/hooks -> .claude -> .claude/tmp
LESSONS_FILE = MEMORY_DIR / "__lessons.md"
SESSION_LOG_FILE = MEMORY_DIR / "session_log.jsonl"

# Legacy paths (used as fallback when not project-aware)
PROGRESS_FILE = MEMORY_DIR / "progress.json"  # Autonomous agent progress tracking
HANDOFF_FILE = MEMORY_DIR / "handoff.json"  # Session handoff data


def _get_project_progress_file() -> Path:
    """Get progress file path (project-scoped if available)."""
    if PROJECT_AWARE:
        try:
            context = get_current_project()
            return get_project_memory_dir(context.project_id) / "progress.json"
        except Exception as e:
            log_debug("session_cleanup", f"project progress path failed: {e}")
    return PROGRESS_FILE


def _get_project_handoff_file() -> Path:
    """Get handoff file path (project-scoped if available)."""
    if PROJECT_AWARE:
        try:
            context = get_current_project()
            return get_project_memory_dir(context.project_id) / "handoff.json"
        except Exception as e:
            log_debug("session_cleanup", f"project handoff path failed: {e}")
    return HANDOFF_FILE


# Files in .claude/tmp/ older than this get cleaned (in seconds)
SCRATCH_CLEANUP_AGE = 86400  # 24 hours

# Minimum edits to a file before generating a lesson
LESSON_EDIT_THRESHOLD = 3

# =============================================================================
# PATTERN EXTRACTION
# =============================================================================


def check_abandoned_creations(state) -> list[dict]:
    """Check for files created this session that may have stubs/TODOs."""
    warnings = []

    if not state.files_created:
        return warnings

    # Import centralized patterns
    from _patterns import STUB_BYTE_PATTERNS

    for filepath in state.files_created:
        path = Path(filepath)
        if not path.exists():
            continue

        # Skip non-code files
        if path.suffix not in {".py", ".js", ".ts", ".rs", ".go", ".java"}:
            continue

        try:
            content = path.read_bytes()
            found_stubs = []
            for pattern in STUB_BYTE_PATTERNS:
                if pattern in content:
                    found_stubs.append(pattern.decode())

            if found_stubs:
                warnings.append(
                    {
                        "file": filepath,
                        "name": path.name,
                        "stubs": found_stubs[:3],  # Limit to 3
                    }
                )
        except (OSError, PermissionError):
            pass

    return warnings


def extract_lessons(state) -> list[dict]:
    """Extract lessons from session patterns.

    NOTE: Only extract HIGH-VALUE lessons worth persisting to lessons.md.
    Telemetry/stats go to session_log.jsonl, not lessons.md.

    Removed (low value, polluted lessons.md):
    - file_complexity: "Edited X 5x" - noise, not actionable
    - unresearched_libs: Lists stdlib modules - garbage
    - domain_focus: "Session focused on X" - trivia
    - recurring_error: Rarely actionable without context

    Keep only:
    - abandoned_stubs: Actual incomplete work needing attention
    """
    lessons = []

    # LESSON: Files created with stubs (abandoned work warning)
    # This is actionable - user should know about incomplete work
    abandoned = check_abandoned_creations(state)
    if abandoned:
        files = [a["name"] for a in abandoned]
        lessons.append(
            {
                "type": "abandoned_stubs",
                "files": files,
                "insight": f" ABANDONED WORK: {', '.join(files)} contain stubs/TODOs",
            }
        )

    return lessons


def _extract_recent_insights(existing: str) -> set[str]:
    """Extract recent insight texts for deduplication."""
    recent_insights = set()
    for line in existing.split("\n")[-50:]:
        if line.startswith("- ["):
            parts = line.split("] ", 1)
            if len(parts) > 1:
                recent_insights.add(parts[1].strip().lower())
    return recent_insights


def _deduplicate_lessons(lessons: list[dict], recent_insights: set[str]) -> list[dict]:
    """Filter out lessons that already exist in recent insights."""
    new_lessons = []
    for lesson in lessons:
        insight_lower = lesson["insight"].lower()
        if insight_lower not in recent_insights:
            new_lessons.append(lesson)
            recent_insights.add(insight_lower)
    return new_lessons


def persist_lessons(lessons: list[dict]):
    """Append lessons to lessons.md file with deduplication.

    Uses atomic read-modify-write with file locking to avoid TOCTOU race.
    """
    if not lessons:
        return

    MEMORY_DIR.mkdir(parents=True, exist_ok=True)
    lock_file = MEMORY_DIR / ".lessons.lock"
    lock_fd = os.open(str(lock_file), os.O_CREAT | os.O_RDWR)

    try:
        fcntl.flock(lock_fd, fcntl.LOCK_EX)

        existing = ""
        try:
            existing = LESSONS_FILE.read_text()
        except FileNotFoundError:
            pass

        new_lessons = _deduplicate_lessons(lessons, _extract_recent_insights(existing))
        if not new_lessons:
            return

        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M")
        new_content = f"\n### {timestamp}\n"
        new_content += "".join(f"- [{lesson['type']}] {lesson['insight']}\n" for lesson in new_lessons)

        with open(LESSONS_FILE, "a") as f:
            if "## Session Lessons" not in existing:
                f.write("\n\n## Session Lessons\n")
            f.write(new_content)
    finally:
        fcntl.flock(lock_fd, fcntl.LOCK_UN)
        os.close(lock_fd)


# =============================================================================
# SCRATCH CLEANUP
# =============================================================================

SESSION_ENV_DIR = Path(__file__).resolve().parent.parent / "session-env"
SESSION_ENV_KEEP = 20  # Keep this many most recent session-env dirs


def cleanup_scratch():
    """Clean up old files in .claude/tmp/ directory."""
    if not SCRATCH_DIR.exists():
        return []

    cleaned = []
    cutoff = time.time() - SCRATCH_CLEANUP_AGE

    for filepath in SCRATCH_DIR.iterdir():
        # Skip .gitkeep and directories
        if filepath.name == ".gitkeep" or filepath.is_dir():
            continue

        try:
            mtime = filepath.stat().st_mtime
            if mtime < cutoff:
                filepath.unlink()
                cleaned.append(filepath.name)
        except (OSError, PermissionError):
            pass

    return cleaned


def cleanup_session_env() -> int:
    """Clean up old session-env directories, keeping most recent N.

    Returns count of directories removed.
    """
    if not SESSION_ENV_DIR.exists():
        return 0

    import shutil

    # Get all session dirs with their mtime
    session_dirs = []
    for d in SESSION_ENV_DIR.iterdir():
        if d.is_dir():
            try:
                mtime = d.stat().st_mtime
                session_dirs.append((mtime, d))
            except OSError:
                pass

    # Sort by mtime descending (newest first)
    session_dirs.sort(key=lambda x: x[0], reverse=True)

    # Remove old ones beyond the keep threshold
    removed = 0
    for mtime, dirpath in session_dirs[SESSION_ENV_KEEP:]:
        try:
            shutil.rmtree(dirpath)
            removed += 1
        except (OSError, PermissionError):
            pass

    return removed


# =============================================================================
# SESSION LOG
# =============================================================================


def log_session(state, lessons: list[dict]):
    """Append session summary to log file."""
    MEMORY_DIR.mkdir(parents=True, exist_ok=True)

    summary = get_session_summary(state)
    summary["ended_at"] = time.time()
    summary["lessons_count"] = len(lessons)
    summary["timestamp"] = datetime.now().isoformat()

    with open(SESSION_LOG_FILE, "a") as f:
        f.write(json.dumps(summary) + "\n")


# =============================================================================
# AUTONOMOUS AGENT: PROGRESS & HANDOFF PERSISTENCE
# =============================================================================


def _atomic_json_write(filepath: Path, data: dict):
    """Write JSON atomically with file locking to prevent corruption.

    Uses fcntl.flock for exclusive access and temp file + rename for atomicity.
    """
    filepath.parent.mkdir(parents=True, exist_ok=True)
    lock_file = filepath.parent / f".{filepath.name}.lock"

    # Acquire exclusive lock
    lock_fd = os.open(str(lock_file), os.O_CREAT | os.O_RDWR)
    try:
        fcntl.flock(lock_fd, fcntl.LOCK_EX)

        # Write to temp file first
        fd, tmp_path = tempfile.mkstemp(dir=filepath.parent, suffix=".json")
        try:
            with os.fdopen(fd, "w") as f:
                json.dump(data, f, indent=2, default=str)
            os.replace(tmp_path, filepath)  # Atomic on POSIX
        except Exception:
            if os.path.exists(tmp_path):
                os.unlink(tmp_path)
            raise
    finally:
        fcntl.flock(lock_fd, fcntl.LOCK_UN)
        os.close(lock_fd)


def save_progress(state):
    """Save progress log to JSON file for cross-session persistence.

    This implements the Anthropic "progress tracking" pattern:
    https://www.anthropic.com/engineering/effective-harnesses-for-long-running-agents

    Using JSON instead of Markdown because "the model is less likely to
    inappropriately change or overwrite JSON files compared to Markdown files."

    NOTE: Progress is now project-scoped to avoid cross-project pollution.
    """
    progress_file = _get_project_progress_file()
    progress_file.parent.mkdir(parents=True, exist_ok=True)

    # Load existing progress
    existing = []
    if progress_file.exists():
        try:
            with open(progress_file) as f:
                data = json.load(f)
                existing = data.get("entries", [])
        except (json.JSONDecodeError, KeyError):
            pass

    # Merge new progress (dedupe by feature_id)
    existing_ids = {e.get("feature_id") for e in existing}
    for entry in state.progress_log:
        if entry.get("feature_id") not in existing_ids:
            existing.append(entry)

    # Trim to last 50 entries
    existing = existing[-50:]

    # Save atomically with locking
    progress_data = {
        "last_updated": datetime.now().isoformat(),
        "session_id": state.session_id,
        "entries": existing,
        "work_queue": [w for w in state.work_queue if w.get("status") == "pending"][
            :20
        ],
    }

    _atomic_json_write(progress_file, progress_data)


def save_handoff(state):
    """Save session handoff data for next session.

    This is the key insight from Anthropic's agent harness:
    "agents need a way to bridge the gap between coding sessions"
    through structured artifacts.

    NOTE: Handoff is now project-scoped to avoid cross-project pollution.
    """
    handoff_file = _get_project_handoff_file()
    handoff_file.parent.mkdir(parents=True, exist_ok=True)

    # Prepare handoff data
    handoff = prepare_handoff(state)

    # Add session metadata and save atomically with locking
    handoff_data = {
        "prepared_at": datetime.now().isoformat(),
        "session_id": state.session_id,
        "summary": handoff["summary"],
        "next_steps": handoff["next_steps"],
        "blockers": handoff["blockers"],
        # Include recent file context for onboarding
        "recent_files": state.files_edited[-5:],
        "recent_commits": [],  # Could be populated from git log
        # Include checkpoint for recovery
        "last_checkpoint": state.checkpoints[-1] if state.checkpoints else None,
    }

    _atomic_json_write(handoff_file, handoff_data)


# =============================================================================
# MAIN
# =============================================================================


def main():
    """SessionEnd hook entry point."""
    try:
        json.load(sys.stdin)  # Consume stdin
    except (json.JSONDecodeError, ValueError):
        pass

    # Load current state
    state = load_state()

    # === AUTONOMOUS AGENT: Finalize current work ===

    # Complete any in-progress feature (mark as interrupted if session ending)
    if state.current_feature:
        complete_feature(state, "interrupted")

    # Auto-extract work items from unresolved errors
    extract_work_from_errors(state)

    # Extract lessons from session patterns
    lessons = extract_lessons(state)

    # Persist lessons to long-term memory
    persist_lessons(lessons)

    # === AUTONOMOUS AGENT: Save progress & handoff ===

    # Save progress log (JSON, survives sessions)
    save_progress(state)

    # Save handoff data for next session onboarding
    save_handoff(state)

    # Clean up old scratch files
    cleaned_files = cleanup_scratch()

    # Clean up old session-env directories (keep last 20)
    removed_sessions = cleanup_session_env()

    # Log session summary
    log_session(state, lessons)

    # Save final state
    save_state(state)

    # Output result (silent unless debugging)
    output = {}

    # Optionally surface cleanup info
    cleanup_parts = []
    if cleaned_files:
        cleanup_parts.append(f"{len(cleaned_files)} scratch files")
    if removed_sessions:
        cleanup_parts.append(f"{removed_sessions} old sessions")
    if cleanup_parts:
        output["message"] = f" Cleaned {', '.join(cleanup_parts)}"

    print(json.dumps(output))
    sys.exit(0)


if __name__ == "__main__":
    main()
</file>

<file path="session_init.py">
#!/usr/bin/env python3
"""
Session Init Hook v3: SessionStart hook for initialization.

SYSTEM CONTEXT: Global WSL2 assistant at /home/jinx
- Full system access, not project-scoped
- Can help with any task across the system
- Projects live in ~/projects/, AI projects in ~/ai/

This hook fires when Claude Code starts a new session and:
- Detects stale state from previous sessions
- Initializes fresh state with proper session_id
- Refreshes ops script discovery
- Clears accumulated errors/gaps from dead sessions
- Sets up session metadata
- Surfaces actionable context on resume (files, tasks, errors)

Silent by default - outputs brief status only if resuming work or issues detected.
"""

import _lib_path  # noqa: F401
from _logging import log_debug
import sys
import json
import os
import time
from pathlib import Path

# Import the state machine
from session_state import (
    load_state,
    save_state,
    reset_state,
    MEMORY_DIR,
    _discover_ops_scripts,
    get_next_work_item,
    start_feature,
)

# Import project-aware state management
# Note: Some imports reserved for future features or API consistency
try:
    from project_detector import get_current_project, ProjectContext  # noqa: F401 (docstring type)
    from project_state import (
        get_active_project_state,  # noqa: F401 (reserved: project switching)
        save_active_state,  # noqa: F401 (reserved: project switching)
        run_maintenance,
        get_contextual_lessons,
        is_same_project,  # noqa: F401 (reserved: project switching)
    )

    PROJECT_AWARE = True
except ImportError:
    PROJECT_AWARE = False

# Import spark_core for pre-warming (lazy load synapse map)
try:
    from spark_core import _load_synapses, fire_synapses  # noqa: F401 (commented code line 177)

    SPARK_AVAILABLE = True
except ImportError:
    SPARK_AVAILABLE = False

# Import dependency checker (v3.10)
try:
    from dependency_check import run_dependency_check

    DEPENDENCY_CHECK_AVAILABLE = True
except ImportError:
    DEPENDENCY_CHECK_AVAILABLE = False

# Scope's punch list file
PUNCH_LIST_FILE = MEMORY_DIR / "punch_list.json"

# Infrastructure manifest (prevents "create X" when X exists)
INFRASTRUCTURE_FILE = MEMORY_DIR / "__infrastructure.md"

# Capabilities index (prevents functional duplication)
CAPABILITIES_FILE = MEMORY_DIR / "__capabilities.md"

# Autonomous agent files (legacy - now project-scoped)
HANDOFF_FILE = MEMORY_DIR / "handoff.json"
PROGRESS_FILE = MEMORY_DIR / "progress.json"


def _get_project_handoff_file(project_context=None) -> Path:
    """Get handoff file path (project-scoped if available)."""
    if PROJECT_AWARE and project_context:
        try:
            from project_state import get_project_memory_dir

            return get_project_memory_dir(project_context.project_id) / "handoff.json"
        except Exception as e:
            log_debug("session_init", f"project context loading failed: {e}")
    return HANDOFF_FILE


def _get_project_progress_file(project_context=None) -> Path:
    """Get progress file path (project-scoped if available)."""
    if PROJECT_AWARE and project_context:
        try:
            from project_state import get_project_memory_dir

            return get_project_memory_dir(project_context.project_id) / "progress.json"
        except Exception as e:
            log_debug("session_init", f"project context loading failed: {e}")
    return PROGRESS_FILE


# =============================================================================
# CONFIGURATION
# =============================================================================

# Sessions older than this are considered stale (in seconds)
STALE_SESSION_THRESHOLD = 3600  # 1 hour

# Maximum age for errors to carry over (in seconds)
ERROR_CARRY_OVER_MAX = 600  # 10 minutes

# =============================================================================
# SYSTEM HEALTH CHECK (v3.9)
# =============================================================================


def check_system_health() -> str | None:
    """Quick system health check at session start.

    Returns warning message if resources are constrained, None otherwise.
    """
    import subprocess

    try:
        result = subprocess.run(
            [
                str(Path.home() / ".claude" / "hooks" / "py"),
                str(Path.home() / ".claude" / "ops" / "sysinfo.py"),
                "--quick",
            ],
            capture_output=True,
            text=True,
            timeout=3,
        )
        if result.returncode != 0:
            return None

        output = result.stdout.strip()
        # Parse: "CPU: 2.26 2.02 2.02 | Mem: 22% | Disk: 48%"
        warnings = []

        # Check memory
        if "Mem:" in output:
            import re

            mem_match = re.search(r"Mem:\s*(\d+)%", output)
            if mem_match and int(mem_match.group(1)) > 85:
                warnings.append(f" Memory: {mem_match.group(1)}% used")

        # Check disk
        if "Disk:" in output:
            import re

            disk_match = re.search(r"Disk:\s*(\d+)%", output)
            if disk_match and int(disk_match.group(1)) > 90:
                warnings.append(f" Disk: {disk_match.group(1)}% used")

        # Check CPU load (first value is 1-min avg)
        if "CPU:" in output:
            import re

            cpu_match = re.search(r"CPU:\s*([\d.]+)", output)
            if cpu_match and float(cpu_match.group(1)) > 4.0:
                warnings.append(f" CPU Load: {cpu_match.group(1)}")

        return " | ".join(warnings) if warnings else None

    except Exception:
        return None  # Non-critical, don't fail session start


# =============================================================================
# MEMORY PRE-WARMING
# =============================================================================


def prewarm_memory_cache():
    """Pre-load synapse map and warm cache with common patterns.

    This runs at session start to eliminate cold-start latency on first prompt.
    Target: <50ms total.
    """
    if not SPARK_AVAILABLE:
        return

    try:
        # 1. Load synapse map into memory (cached for session)
        _load_synapses()

        # 2. Pre-warm spark cache with common terms
        # Reduces first-query latency by ~100-500ms
        common_prompts = ["error", "fix", "implement", "test", "refactor"]
        for prompt in common_prompts:
            fire_synapses(
                prompt, include_constraints=False, include_session_history=False
            )

    except Exception as e:
        log_debug("session_init", f"recent context preload failed: {e}")


def sync_beads_on_start():
    """Sync beads at session start (non-blocking background process)."""
    import subprocess
    import shutil

    # Check if bd command exists
    bd_path = shutil.which("bd")
    if not bd_path:
        return

    # Check if .beads directory exists
    beads_dir = Path.cwd() / ".beads"
    if not beads_dir.exists():
        beads_dir = Path.home() / ".claude" / ".beads"
        if not beads_dir.exists():
            return

    # Run bd sync in background (non-blocking)
    try:
        subprocess.Popen(
            [bd_path, "sync"],
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL,
            start_new_session=True,
        )
    except (OSError, IOError):
        pass  # Non-critical


# =============================================================================
# STALE DETECTION
# =============================================================================


def is_session_stale(state) -> tuple[bool, str]:
    """Check if the existing session state is stale."""
    if not state.started_at:
        return True, "no_timestamp"

    age = time.time() - state.started_at

    if age > STALE_SESSION_THRESHOLD:
        return True, f"age_{int(age)}s"

    # Check if session_id changed (new Claude session)
    current_session_id = os.environ.get("CLAUDE_SESSION_ID", "")[:16]
    if (
        current_session_id
        and state.session_id
        and current_session_id != state.session_id
    ):
        return True, "session_id_changed"

    return False, "fresh"


def prune_old_errors(state):
    """Remove errors older than carry-over threshold."""
    cutoff = time.time() - ERROR_CARRY_OVER_MAX

    state.errors_recent = [
        e for e in state.errors_recent if e.get("timestamp", 0) > cutoff
    ]
    state.errors_unresolved = [
        e for e in state.errors_unresolved if e.get("timestamp", 0) > cutoff
    ]


def prune_old_gaps(state):
    """Clear gaps from previous sessions."""
    # Gaps don't have timestamps, so clear all on new session
    state.gaps_detected = []
    state.gaps_surfaced = []


# =============================================================================
# AUTONOMOUS AGENT: HANDOFF & ONBOARDING
# =============================================================================


def load_handoff_data(project_context=None) -> dict | None:
    """Load handoff data from previous session.

    This implements the Anthropic pattern of bridging context across sessions:
    https://www.anthropic.com/engineering/effective-harnesses-for-long-running-agents

    NOTE: Now project-scoped to load context for the specific project.
    """
    handoff_file = _get_project_handoff_file(project_context)
    if not handoff_file.exists():
        return None
    try:
        with open(handoff_file) as f:
            data = json.load(f)
        # Check if handoff is stale (>24h old)
        from datetime import datetime, timezone

        prepared = data.get("prepared_at", "")
        if prepared:
            try:
                # Parse ISO format, normalize to UTC for consistent comparison
                prepared_dt = datetime.fromisoformat(prepared.replace("Z", "+00:00"))
                if prepared_dt.tzinfo is not None:
                    # Convert to UTC then to naive for comparison
                    prepared_dt = prepared_dt.astimezone(timezone.utc).replace(
                        tzinfo=None
                    )
                    now = datetime.now(timezone.utc).replace(tzinfo=None)
                else:
                    now = datetime.now()
                age_hours = (now - prepared_dt).total_seconds() / 3600
                if age_hours > 24:
                    return None  # Stale handoff
            except (ValueError, TypeError):
                pass
        return data
    except (json.JSONDecodeError, KeyError):
        return None


def load_work_queue(project_context=None) -> list:
    """Load pending work items from progress file.

    NOTE: Now project-scoped.
    """
    progress_file = _get_project_progress_file(project_context)
    if not progress_file.exists():
        return []
    try:
        with open(progress_file) as f:
            data = json.load(f)
        return data.get("work_queue", [])
    except (json.JSONDecodeError, KeyError):
        return []


def load_infrastructure_summary() -> str:
    """Load infrastructure manifest summary for session context.

    This prevents Claude from recommending "create X" when X already exists.
    Injects key infrastructure awareness at session start.
    """
    if not INFRASTRUCTURE_FILE.exists():
        return ""

    try:
        content = INFRASTRUCTURE_FILE.read_text()
        # Extract just the "Setup Scripts" and "Key Directories" sections
        lines = content.split("\n")
        summary_lines = []
        in_section = False

        for line in lines:
            if line.startswith("## Setup Scripts") or line.startswith(
                "## Key Directories"
            ):
                in_section = True
                summary_lines.append(line)
            elif line.startswith("## ") and in_section:
                in_section = False
            elif in_section:
                summary_lines.append(line)

        return "\n".join(summary_lines).strip()
    except (IOError, OSError):
        return ""


def load_capabilities_summary() -> str:
    """Load capabilities index summary for session context.

    This prevents Claude from creating duplicate functionality by surfacing
    what already exists, grouped by PURPOSE not just filename.

    Critical for template projects where the same functionality gets
    proposed session after session.
    """
    if not CAPABILITIES_FILE.exists():
        return ""

    try:
        content = CAPABILITIES_FILE.read_text()
        # Extract category headers and counts
        lines = content.split("\n")
        categories = []

        for line in lines:
            if line.startswith("## ") and not line.startswith("## Before"):
                # Extract emoji + category name
                cat = line[3:].strip()
                categories.append(cat)

        if categories:
            # Compact format: just list the categories
            return "Categories: " + " | ".join(categories[:8])
        return ""
    except (IOError, OSError):
        return ""


def get_confidence_fp_history(state) -> list[str]:
    """Get false positive history for confidence reducers.

    Since LLMs can't learn, we must inject FP history as explicit context
    so the same false triggers don't frustrate users session after session.

    Returns list of reducer warnings based on FP counts.
    """
    if not hasattr(state, "nudge_history"):
        return []

    fp_warnings = []
    for key, data in state.nudge_history.items():
        if key.startswith("reducer_fp_") and isinstance(data, dict):
            reducer_name = key.replace("reducer_fp_", "")
            fp_count = data.get("count", 0)
            if fp_count >= 2:
                # Calculate adaptive cooldown
                base_cooldown = 5  # default
                multiplier = min(3.0, 1.0 + (fp_count * 0.5))
                cooldown = int(base_cooldown * multiplier)
                fp_warnings.append(
                    f" {reducer_name}: {fp_count} FPs  cooldown {cooldown} turns"
                )

    return fp_warnings[:5]  # Limit to 5 most relevant


def get_recent_block_lessons(limit: int = 3) -> list[str]:
    """Get recent block-reflection lessons for session injection.

    These are lessons learned from hook blocks in previous sessions.
    Surfacing them prevents the same mistakes from recurring.
    """
    if not PROJECT_AWARE:
        return []

    try:
        from project_state import load_global_memory
        import time

        memory = load_global_memory()
        block_lessons = []

        # Filter to block-reflection lessons from last 7 days
        cutoff = time.time() - (7 * 24 * 3600)

        for lesson in memory.lessons:
            category = lesson.get("category", "")
            added_at = lesson.get("added_at", 0)

            if "block-reflection" in category and added_at > cutoff:
                content = lesson.get("content", "")
                # Extract hook name from category (e.g., "block-reflection:python_path_injector")
                hook = category.replace("block-reflection:", "").split(",")[0].strip()
                if hook and content:
                    block_lessons.append(f"{hook}: {content[:80]}")

        # Return most recent
        return block_lessons[-limit:]
    except (ImportError, Exception):
        return []


def _build_project_context(project_context) -> str | None:
    """Build project context string."""
    if not project_context or not PROJECT_AWARE:
        return None

    proj_name = project_context.project_name
    proj_type = project_context.project_type

    if proj_type == "ephemeral":
        return " **MODE**: Ephemeral (no project context)"

    lang = project_context.language or "unknown"
    framework = project_context.framework
    ctx_str = f" **PROJECT**: {proj_name}"
    if framework:
        ctx_str += f" ({framework}/{lang})"
    elif lang:
        ctx_str += f" ({lang})"
    return ctx_str


def _build_session_summary(handoff: dict | None) -> list[str]:
    """Build previous session summary parts."""
    if not handoff:
        return []

    parts = []
    summary = handoff.get("summary", "")
    if summary:
        parts.append(f" **PREVIOUS SESSION**: {summary}")

    blockers = handoff.get("blockers", [])
    if blockers:
        blocker_list = ", ".join(b.get("type", "unknown")[:20] for b in blockers[:2])
        parts.append(f" **BLOCKERS**: {blocker_list}")

    recent = handoff.get("recent_files", [])
    if recent:
        names = [Path(f).name for f in recent[:3]]
        parts.append(f" **RECENT FILES**: {', '.join(names)}")

    return parts


def _build_next_work_item(state, handoff: dict | None) -> str | None:
    """Build next work item context."""
    next_item = get_next_work_item(state)
    if next_item:
        item_type = next_item.get("type", "task")
        desc = next_item.get("description", "")[:60]
        priority = next_item.get("priority", 50)
        start_feature(state, desc)
        return f" **NEXT PRIORITY** [{item_type}|P{priority}]: {desc}"

    # Fallback to handoff next_steps
    if handoff:
        next_steps = handoff.get("next_steps", [])
        if next_steps:
            desc = next_steps[0].get("description", "")[:60]
            return f" **SUGGESTED**: {desc}"

    return None


def _build_recovery_point(handoff: dict | None) -> str | None:
    """Build recovery point context."""
    if not handoff:
        return None

    checkpoint = handoff.get("last_checkpoint")
    if not checkpoint:
        return None

    cp_id = checkpoint.get("checkpoint_id", "")
    commit = checkpoint.get("commit_hash", "")[:7]
    if commit:
        return f" **RECOVERY POINT**: {cp_id} (commit: {commit})"
    return None


def _build_lessons_context(state, project_context) -> list[str]:
    """Build lessons and calibration context."""
    parts = []

    # Block lessons (cross-session learning)
    block_lessons = get_recent_block_lessons(limit=3)
    if block_lessons:
        parts.append(" **RECENT LESSONS**:")
        parts.extend(f"   {lesson}" for lesson in block_lessons)

    # Confidence FP history
    fp_warnings = get_confidence_fp_history(state)
    if fp_warnings:
        parts.append(" **CONFIDENCE CALIBRATION** (reducers with high FP rates):")
        parts.extend(f"  {warning}" for warning in fp_warnings)

    # Contextual lessons
    if PROJECT_AWARE and project_context and project_context.project_type != "ephemeral":
        keywords = [k for k in [
            project_context.language,
            project_context.framework,
            project_context.project_name,
        ] if k]
        if keywords:
            lessons = get_contextual_lessons(keywords)
            if lessons:
                lesson_preview = lessons[0].get("content", "")[:50]
                parts.append(f" **WISDOM**: {lesson_preview}...")

    return parts


def build_onboarding_context(state, handoff: dict | None, project_context=None) -> str:
    """Build the session onboarding protocol context.

    Implements the Anthropic pattern:
    1. Read progress files and git logs to understand recent work
    2. Select the highest-priority incomplete feature
    3. Verify baseline before implementing

    For autonomous agents, this is AUTOMATIC - no human input needed.
    """
    parts = [
        " **SYSTEM**: WSL2 global assistant @ /home/jinx | Full access | ~/projects/ for work | ~/ai/ for AI projects"
    ]

    if ctx := _build_project_context(project_context):
        parts.append(ctx)

    parts.extend(_build_session_summary(handoff))

    if item := _build_next_work_item(state, handoff):
        parts.append(item)

    if recovery := _build_recovery_point(handoff):
        parts.append(recovery)

    parts.extend(_build_lessons_context(state, project_context))

    return "\n".join(parts) if parts else ""


# =============================================================================
# CONTEXT GENERATION (for resume)
# =============================================================================


def get_active_scope_task() -> dict | None:
    """Check if there's an active scope task from punch_list.json."""
    if not PUNCH_LIST_FILE.exists():
        return None
    try:
        with open(PUNCH_LIST_FILE) as f:
            data = json.load(f)
        # Only return if not 100% complete
        if data.get("percent", 100) < 100:
            return {
                "description": data.get("description", "")[:60],
                "percent": data.get("percent", 0),
                "items_done": sum(1 for i in data.get("items", []) if i.get("done")),
                "items_total": len(data.get("items", [])),
            }
    except (json.JSONDecodeError, KeyError):
        pass
    return None


def build_resume_context(state, result: dict) -> str:
    """Build actionable context string for session resume."""
    parts = []

    # 1. Active scope task (highest priority)
    scope_task = get_active_scope_task()
    if scope_task:
        desc = scope_task["description"]
        pct = scope_task["percent"]
        done = scope_task["items_done"]
        total = scope_task["items_total"]
        parts.append(f' Active task: "{desc}" ({done}/{total} items, {pct}%)')

    # 2. Recently edited files (from previous session state)
    if state.files_edited:
        recent = []
        for f in state.files_edited[-3:]:
            try:
                recent.append(Path(f).name)
            except (ValueError, OSError):
                recent.append(str(f).split("/")[-1] if "/" in str(f) else str(f))
        parts.append(f" Last edited: {', '.join(recent)}")

    # 3. Unresolved errors (warn, don't block)
    if state.errors_unresolved:
        count = len(state.errors_unresolved)
        latest = state.errors_unresolved[-1].get("type", "error")[:40]
        parts.append(f" {count} unresolved: {latest}")

    return " | ".join(parts) if parts else ""


# =============================================================================
# INITIALIZATION
# =============================================================================


def initialize_session(project_context=None) -> dict:
    """Initialize or refresh session state.

    Args:
        project_context: Optional ProjectContext for project-scoped operations.
    """
    result = {
        "action": "none",
        "message": "",
        "session_id": "",
        "handoff": None,  # For onboarding context
    }

    # Try to load existing state
    existing_state = load_state()

    # Check staleness
    is_stale, reason = is_session_stale(existing_state)

    if is_stale:
        # Reset to fresh state
        state = reset_state()
        result["action"] = "reset"
        result["message"] = f"Fresh session (reason: {reason})"

        # === AUTONOMOUS AGENT: Restore work queue from progress file ===
        # Now project-scoped to load correct project's work queue
        work_queue = load_work_queue(project_context)
        if work_queue:
            state.work_queue = work_queue
    else:
        # Refresh existing state
        state = existing_state

        # Prune old data
        prune_old_errors(state)
        prune_old_gaps(state)

        # Clear stale integration greps (prevents cross-session blocking)
        state.pending_integration_greps = []

        # Refresh ops scripts (might have changed)
        state.ops_scripts = _discover_ops_scripts()

        result["action"] = "refresh"
        result["message"] = "Session resumed"

    # Ensure session_id is set
    if not state.session_id:
        state.session_id = (
            os.environ.get("CLAUDE_SESSION_ID", "")[:16] or f"ses_{int(time.time())}"
        )

    result["session_id"] = state.session_id

    # === AUTONOMOUS AGENT: Load handoff data ===
    # Now project-scoped to load correct project's handoff
    handoff = load_handoff_data(project_context)
    result["handoff"] = handoff

    # Save updated state
    save_state(state)

    # Pre-warm memory cache (synapse map, lessons index)
    prewarm_memory_cache()

    # Sync beads at session start (non-blocking)
    sync_beads_on_start()

    return result


# =============================================================================
# MAIN
# =============================================================================


def main():
    """SessionStart hook entry point."""
    try:
        json.load(sys.stdin)  # Consume stdin
    except (json.JSONDecodeError, ValueError):
        pass

    # === DEPENDENCY CHECK (v3.10) ===
    dep_warning = None
    if DEPENDENCY_CHECK_AVAILABLE:
        try:
            dep_result = run_dependency_check()
            if not dep_result["ok"] or dep_result["warnings"]:
                dep_warning = dep_result["summary"]
        except Exception:
            pass  # Non-critical, don't fail session start

    # === SYSTEM HEALTH CHECK (v3.9) ===
    health_warning = check_system_health()

    # === PROJECT-AWARE INITIALIZATION ===
    project_context = None
    if PROJECT_AWARE:
        try:
            project_context = get_current_project()
            # Run maintenance (cleanup stale projects, ephemeral state)
            run_maintenance()
        except (ImportError, FileNotFoundError, PermissionError):
            # Expected errors: module not available, git not found, permission issues
            pass  # Fall back to legacy behavior
        except Exception as e:
            # Unexpected errors: log for debugging but don't block
            print(
                f"Warning: project detection failed: {type(e).__name__}: {e}",
                file=sys.stderr,
            )

    # Load state BEFORE initialize (to capture previous session's context)
    previous_state = load_state()

    # Initialize session (pass project_context for project-scoped operations)
    result = initialize_session(project_context)

    # SUDO SECURITY: Audit passed - clear stop hook flags for this session
    session_id = os.environ.get("CLAUDE_SESSION_ID", "default")[:16]
    dismissal_flag = MEMORY_DIR / f"dismissal_shown_{session_id}.flag"
    if dismissal_flag.exists():
        try:
            dismissal_flag.unlink()
        except (IOError, OSError):
            pass

    # Output result
    output = {}

    # === AUTONOMOUS AGENT: Session Onboarding Protocol ===
    # This implements the Anthropic pattern for agent session starts:
    # https://www.anthropic.com/engineering/effective-harnesses-for-long-running-agents
    #
    # ENHANCED: Project-aware onboarding for multi-project swiss army knife

    if result["action"] == "reset":
        # Fresh session - load state for onboarding context
        state = load_state()
        handoff = result.get("handoff")

        # Build onboarding context (auto-selects next work item)
        # Pass project_context for multi-project awareness
        onboarding = build_onboarding_context(state, handoff, project_context)

        if onboarding:
            output["message"] = f" **SESSION START**\n{onboarding}"
            # Save state (may have started a feature)
            save_state(state)
        else:
            # Even without handoff, show project context if available
            if project_context and project_context.project_type != "ephemeral":
                output["message"] = (
                    f" **SESSION START**\n **PROJECT**: {project_context.project_name}"
                )
            else:
                output["message"] = f" {result['message']}"

    elif result["action"] == "refresh":
        # Resuming within same session - surface context from previous state
        context = build_resume_context(previous_state, result)

        # Check for project switching (user changed directories mid-session)
        if PROJECT_AWARE and project_context:
            if not is_same_project(getattr(previous_state, "_project_context", None)):
                # Project changed! Save old state, load new
                try:
                    save_active_state()
                    new_ctx, new_state = get_active_project_state()
                    output["message"] = (
                        f" **PROJECT SWITCH**\n"
                        f" Now in: {new_ctx.project_name}\n"
                        f"Previous context saved."
                    )
                except Exception as e:
                    log_debug("session_init", f"project switch failed: {e}")

        if context and "message" not in output:
            output["message"] = f" Resuming: {context}"

    # Note: Duplication prevention removed - this is a system assistant, not a template project

    # Append dependency warning if deps are missing (v3.10)
    if dep_warning:
        if output.get("message"):
            output["message"] += f"\n\n **DEPENDENCIES**:\n{dep_warning}"
        else:
            output["message"] = f" **DEPENDENCIES**:\n{dep_warning}"

    # Append health warning if resources are constrained (v3.9)
    if health_warning and output.get("message"):
        output["message"] += f"\n\n **SYSTEM**: {health_warning}"
    elif health_warning:
        output["message"] = f" **SYSTEM**: {health_warning}"

    print(json.dumps(output))
    sys.exit(0)


if __name__ == "__main__":
    main()
</file>

<file path="statusline.py">
#!/usr/bin/env python3
"""
System Assistant Statusline - Full WSL2 system status at a glance

Shows: Model | Context% | CPU | RAM | Disk | Services | Network
Line 2: Session | Folder | Confidence | Git
Designed for personalized WSL2 system assistant use.
"""

import json
import os
import subprocess
import sys
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path

# Add lib path for imports
sys.path.insert(0, str(Path(__file__).parent.parent / "lib"))
sys.path.insert(0, str(Path(__file__).parent))  # For _config

from _config import get_magic_number
from _logging import log_debug

# =============================================================================
# CACHE LAYER - subprocess results don't change rapidly
# =============================================================================

CACHE_FILE = Path("/tmp/.claude_statusline_cache.json")

# TTL per metric (seconds) - tuned for typical change frequency
CACHE_TTL = {
    "gpu": 2,  # VRAM can change during inference
    "services": 5,  # Docker/node/python processes stable
    "comfyui": 10,  # Service status very stable
    "net": 10,  # Connectivity rarely changes
    "git": 3,  # Changes with edits but not rapidly
    "ports": 3,  # Dev servers start/stop occasionally
}

# Dev ports worth monitoring (port -> short label)
DEV_PORTS = {
    3000: "3k",  # React, Next.js, Create React App
    3001: "3k1",  # Next.js alt
    4200: "ng",  # Angular
    5000: "5k",  # Flask, various
    5173: "vite",  # Vite dev server
    5174: "vite",  # Vite alt
    8000: "8k",  # Django, FastAPI, uvicorn
    8080: "8080",  # Generic, Tomcat, etc
    8888: "jup",  # Jupyter
    9000: "9k",  # PHP-FPM, SonarQube
}


def load_cache() -> dict:
    """Load cache from file, return empty dict if missing/invalid."""
    try:
        if CACHE_FILE.exists():
            return json.loads(CACHE_FILE.read_text())
    except Exception as e:
        log_debug("statusline", f"confidence state read failed: {e}")
    return {}


def save_cache(cache: dict):
    """Save cache to file (best effort)."""
    try:
        CACHE_FILE.write_text(json.dumps(cache))
    except Exception as e:
        log_debug("statusline", f"git data read failed: {e}")


def get_cached(cache: dict, key: str) -> tuple[bool, str]:
    """Return (hit, value) - hit is True if cache is fresh."""
    entry = cache.get(key)
    if not entry:
        return False, ""
    ttl = CACHE_TTL.get(key, 5)
    if time.time() - entry.get("ts", 0) < ttl:
        return True, entry.get("val", "")
    return False, ""


def set_cached(cache: dict, key: str, value: str):
    """Store value in cache with current timestamp."""
    cache[key] = {"ts": time.time(), "val": value}


# ANSI colors
class C:
    RESET = "\033[0m"
    DIM = "\033[90m"
    RED = "\033[31m"
    GREEN = "\033[32m"
    YELLOW = "\033[33m"
    BLUE = "\033[34m"
    MAGENTA = "\033[35m"
    CYAN = "\033[36m"


def run_cmd(cmd_list, timeout=2):
    """Run command with list args, return stdout."""
    try:
        result = subprocess.run(
            cmd_list, capture_output=True, text=True, timeout=timeout
        )
        return result.stdout.strip() if result.returncode == 0 else ""
    except Exception:
        return ""


def get_cpu_load():
    """Get CPU load average (1 min)."""
    try:
        with open("/proc/loadavg") as f:
            load = float(f.read().split()[0])
        cores = os.cpu_count() or 1
        pct = (load / cores) * 100
        color = C.RED if pct > 80 else C.YELLOW if pct > 50 else C.GREEN
        return f"{color}{load:.1f}{C.RESET}"
    except Exception:
        return f"{C.DIM}--{C.RESET}"


def get_ram_usage():
    """Get RAM usage percentage."""
    try:
        with open("/proc/meminfo") as f:
            mem = {}
            for line in f:
                parts = line.split(":")
                if len(parts) == 2:
                    mem[parts[0].strip()] = int(parts[1].strip().split()[0])
        total = mem.get("MemTotal", 1)
        available = mem.get("MemAvailable", 0)
        pct = ((total - available) / total) * 100
        color = C.RED if pct > 85 else C.YELLOW if pct > 70 else C.GREEN
        return f"{color}{pct:.0f}%{C.RESET}"
    except Exception:
        return f"{C.DIM}--{C.RESET}"


def get_disk_usage():
    """Get disk free space for /home."""
    try:
        stat = os.statvfs("/home")
        total = stat.f_blocks * stat.f_frsize
        free = stat.f_bfree * stat.f_frsize
        pct = ((total - free) / total) * 100
        free_gb = free / (1024**3)
        color = C.RED if pct > 90 else C.YELLOW if pct > 75 else C.GREEN
        return f"{color}{free_gb:.0f}G{C.RESET}"
    except Exception:
        return f"{C.DIM}--{C.RESET}"


def get_services_status():
    """Get status of key services."""
    services = []

    # Docker containers
    try:
        result = subprocess.run(
            ["docker", "ps", "-q"], capture_output=True, text=True, timeout=1
        )
        if result.returncode == 0:
            count = (
                len(result.stdout.strip().split("\n")) if result.stdout.strip() else 0
            )
            if count > 0:
                services.append(f"{C.CYAN}D:{count}{C.RESET}")
    except Exception as e:
        log_debug("statusline", f"bead state read failed: {e}")

    # Node processes
    try:
        result = subprocess.run(
            ["pgrep", "-c", "node"], capture_output=True, text=True, timeout=1
        )
        if result.returncode == 0:
            count = int(result.stdout.strip())
            if count > 0:
                services.append(f"{C.GREEN}N:{count}{C.RESET}")
    except Exception as e:
        log_debug("statusline", f"bead state read failed: {e}")

    # Python processes
    try:
        result = subprocess.run(
            ["pgrep", "-c", "python"], capture_output=True, text=True, timeout=1
        )
        if result.returncode == 0:
            count = int(result.stdout.strip())
            if count > 1:
                services.append(f"{C.YELLOW}P:{count - 1}{C.RESET}")
    except Exception as e:
        log_debug("statusline", f"decay timer read failed: {e}")

    return " ".join(services) if services else ""


def get_network_status():
    """Check internet connectivity via DNS."""
    try:
        result = subprocess.run(
            ["getent", "hosts", "google.com"], capture_output=True, timeout=1
        )
        return (
            f"{C.GREEN}NET{C.RESET}"
            if result.returncode == 0
            else f"{C.RED}NET{C.RESET}"
        )
    except Exception:
        return f"{C.RED}NET{C.RESET}"


def get_gpu_vram():
    """Get GPU VRAM usage via nvidia-smi (WSL2)."""
    nvidia_smi = "/usr/lib/wsl/lib/nvidia-smi"
    try:
        if not Path(nvidia_smi).exists():
            return ""
        result = subprocess.run(
            [
                nvidia_smi,
                "--query-gpu=memory.used,memory.total",
                "--format=csv,noheader,nounits",
            ],
            capture_output=True,
            text=True,
            timeout=2,
        )
        if result.returncode != 0 or not result.stdout.strip():
            return ""
        used, total = map(int, result.stdout.strip().split(", "))
        pct = (used / total) * 100
        used_gb = used / 1024
        total_gb = total / 1024
        color = C.RED if pct > 90 else C.YELLOW if pct > 70 else C.GREEN
        return f"{color}{used_gb:.1f}/{total_gb:.0f}G{C.RESET}"
    except Exception:
        return ""


def get_dev_ports():
    """Check which dev ports are listening."""
    try:
        result = subprocess.run(
            ["ss", "-tlnH"], capture_output=True, text=True, timeout=1
        )
        if result.returncode != 0:
            return ""

        listening = set()
        for line in result.stdout.split("\n"):
            # Parse ss output: LISTEN 0 511 *:3000 *:*
            parts = line.split()
            if len(parts) >= 4:
                addr = parts[3]  # Local address like *:3000 or 127.0.0.1:8000
                if ":" in addr:
                    port_str = addr.rsplit(":", 1)[-1]
                    if port_str.isdigit():
                        port = int(port_str)
                        if port in DEV_PORTS:
                            listening.add(port)

        if not listening:
            return ""

        # Sort and format: "3k 8k vite"
        labels = [DEV_PORTS[p] for p in sorted(listening)]
        return f"{C.MAGENTA}{' '.join(labels)}{C.RESET}"
    except Exception:
        return ""


def get_comfyui_status():
    """Check if ComfyUI is running."""
    try:
        # Primary: check if port 8188 is listening (ComfyUI default)
        result = subprocess.run(
            ["ss", "-tlnp"], capture_output=True, text=True, timeout=1
        )
        if result.returncode == 0 and ":8188" in result.stdout:
            return f"{C.GREEN}ComfyUI{C.RESET}"

        # Fallback: check for ComfyUI main.py being executed
        # Must match the SCRIPT, not just the venv path
        result = subprocess.run(
            ["pgrep", "-af", "python"], capture_output=True, text=True, timeout=1
        )
        if result.returncode == 0:
            for line in result.stdout.split("\n"):
                # Look for actual ComfyUI execution patterns
                lower = line.lower()
                # Match: "comfyui/main.py" or "comfy/main.py" in the command args
                if ("comfyui" in lower or "comfy" in lower) and "main.py" in lower:
                    return f"{C.GREEN}ComfyUI{C.RESET}"

        return ""
    except Exception:
        return ""


def get_confidence_status():
    """Get confidence level from session state - reads directly from file."""
    try:
        # Read directly from JSON to avoid any module-level caching
        state_file = Path(__file__).parent.parent / "memory" / "session_state_v3.json"
        if not state_file.exists():
            return ""
        with open(state_file) as f:
            data = json.load(f)
        confidence = data.get("confidence", 70)

        # Import tier info (no caching issues here)
        from confidence import get_tier_info, STASIS_FLOOR

        tier_name, emoji, _ = get_tier_info(confidence)

        # Trajectory prediction (3 turns, decay only - can't predict edits/bash)
        projected = confidence - 3  # -1 decay per turn
        trajectory = ""
        if projected < STASIS_FLOOR and confidence >= STASIS_FLOOR:
            # Will drop below stasis floor - warn
            trajectory = f" {projected - confidence}"
        elif projected < confidence:
            # Simple decay indicator (compact)
            trajectory = f" {projected - confidence}"

        return f"{emoji}{confidence}% {tier_name}{trajectory}"
    except Exception:
        return ""


def get_git_info():
    """Get git branch and status."""
    try:
        result = subprocess.run(
            ["git", "branch", "--show-current"],
            capture_output=True,
            text=True,
            timeout=1,
        )
        if result.returncode != 0:
            return ""
        branch = result.stdout.strip()

        result = subprocess.run(
            ["git", "status", "--porcelain"], capture_output=True, text=True, timeout=1
        )
        status_str = ""
        if result.returncode == 0 and result.stdout.strip():
            lines = result.stdout.strip().split("\n")
            modified = sum(1 for ln in lines if len(ln) > 1 and ln[1] == "M")
            staged = sum(1 for ln in lines if ln[0] not in (" ", "?"))
            untracked = sum(1 for ln in lines if ln.startswith("??"))
            parts = []
            if staged:
                parts.append(f"{C.GREEN}+{staged}{C.RESET}")
            if modified:
                parts.append(f"{C.YELLOW}~{modified}{C.RESET}")
            if untracked:
                parts.append(f"{C.RED}?{untracked}{C.RESET}")
            if parts:
                status_str = f"[{' '.join(parts)}]"

        return f"{C.GREEN}{branch}{C.RESET}{status_str}"
    except Exception:
        return ""


def get_context_usage(transcript_path, context_window):
    """Calculate context window usage from transcript."""
    if not transcript_path or not Path(transcript_path).exists():
        return 0, 0
    try:
        with open(transcript_path, "r") as f:
            lines = f.readlines()
        for line in reversed(lines):
            try:
                data = json.loads(line.strip())
                if data.get("message", {}).get("role") != "assistant":
                    continue
                model = str(data.get("message", {}).get("model", "")).lower()
                if "synthetic" in model:
                    continue
                usage = data.get("message", {}).get("usage")
                if usage:
                    used = (
                        usage.get("input_tokens", 0)
                        + usage.get("output_tokens", 0)
                        + usage.get("cache_read_input_tokens", 0)
                        + usage.get("cache_creation_input_tokens", 0)
                    )
                    return used, context_window
            except Exception:
                continue
        return 0, 0
    except Exception:
        return 0, 0


def main():
    try:
        input_data = json.loads(sys.stdin.read())
    except Exception:
        input_data = {}

    # Model
    model = input_data.get("model", {})
    model_name = model.get("display_name", "Claude")
    if "Opus" in model_name:
        model_short = f"{C.MAGENTA}Opus{C.RESET}"
    elif "Sonnet" in model_name:
        model_short = f"{C.BLUE}Sonnet{C.RESET}"
    elif "Haiku" in model_name:
        model_short = f"{C.CYAN}Haiku{C.RESET}"
    else:
        model_short = f"{C.DIM}{model_name[:6]}{C.RESET}"

    # Context
    transcript = input_data.get("transcript_path", "")
    context_window = model.get("context_window", get_magic_number("default_context_window", 200000))
    used, total = get_context_usage(transcript, context_window)
    if used > 0 and total > 0:
        pct = (used / total) * 100
        ctx_color = C.RED if pct > 80 else C.YELLOW if pct > 60 else C.GREEN
        context_str = f"{ctx_color}{pct:.0f}%{C.RESET}"
    else:
        context_str = f"{C.DIM}0%{C.RESET}"

    # Fast system stats (no subprocess, just /proc reads)
    cpu = get_cpu_load()
    ram = get_ram_usage()
    disk = get_disk_usage()

    # Slow subprocess calls - cached + parallel
    # Cache eliminates redundant subprocess calls between rapid prompts
    slow_funcs = {
        "gpu": get_gpu_vram,
        "services": get_services_status,
        "ports": get_dev_ports,
        "comfyui": get_comfyui_status,
        "net": get_network_status,
        "git": get_git_info,
    }

    cache = load_cache()
    results = {}
    stale_funcs = {}

    # Check cache first
    for name, fn in slow_funcs.items():
        hit, val = get_cached(cache, name)
        if hit:
            results[name] = val
        else:
            stale_funcs[name] = fn

    # Only run subprocess calls for stale entries (parallel)
    if stale_funcs:
        with ThreadPoolExecutor(max_workers=len(stale_funcs)) as executor:
            futures = {executor.submit(fn): name for name, fn in stale_funcs.items()}
            for future in as_completed(futures, timeout=3):
                name = futures[future]
                try:
                    val = future.result()
                    results[name] = val
                    set_cached(cache, name, val)
                except Exception:
                    results[name] = ""
        save_cache(cache)

    gpu = results.get("gpu", "")
    services = results.get("services", "")
    ports = results.get("ports", "")
    comfyui = results.get("comfyui", "")
    net = results.get("net", f"{C.DIM}NET{C.RESET}")
    git = results.get("git", "")

    # Line 1: Model | Context | System
    line1_parts = [
        model_short,
        f"CTX:{context_str}",
        f"CPU:{cpu}",
        f"RAM:{ram}",
        f"DSK:{disk}",
    ]
    if gpu:
        line1_parts.append(f"GPU:{gpu}")
    if services:
        line1_parts.append(services)
    if ports:
        line1_parts.append(ports)
    if comfyui:
        line1_parts.append(comfyui)
    line1_parts.append(net)
    line1 = f" {C.DIM}|{C.RESET} ".join(line1_parts)

    # Line 2: Session + Folder + Confidence + Git
    session_id = input_data.get("session_id", "")[:8]
    folder = Path.cwd().name
    confidence = get_confidence_status()
    line2_parts = [f"{C.DIM}{session_id}{C.RESET}", f"{C.CYAN}{folder}{C.RESET}"]
    if confidence:
        line2_parts.append(confidence)
    if git:
        line2_parts.append(git)
    line2 = f" {C.DIM}|{C.RESET} ".join(line2_parts)

    print(f"{line1}\n{line2}")


if __name__ == "__main__":
    main()
</file>

<file path="stop_runner.py">
#!/usr/bin/env python3
"""
Composite Stop Runner: Runs all Stop hooks in a single process.

PERFORMANCE: ~100ms for all hooks vs ~300ms for individual processes

HOOKS INDEX (by priority):
  PERSISTENCE (0-20):
    10 auto_commit        - Commit all changes (semantic backup)

  VALIDATION (30-60):
    30 session_blocks     - Require reflection on blocks
    40 dismissal_check    - Catch false positive claims without fix
    45 completion_gate    - Block completion if confidence < 85%
    50 stub_detector      - Files created with stubs

  WARNINGS (70-90):
    70 pending_greps      - Unverified function edits
    80 unresolved_errors  - Lingering errors

ARCHITECTURE:
  - Hooks register via @register_hook(name, priority)
  - Lower priority = runs first
  - First BLOCK wins for decision
  - stopReasons and contexts are aggregated
  - Special output schema for Stop hooks:
    {"decision": "block", "reason": "..."} - Forces Claude to continue
    {"stopReason": "..."} - Warning message
"""

import _lib_path  # noqa: F401
import sys
import json
import re
import time
import subprocess
import os
from typing import Callable
from dataclasses import dataclass
from pathlib import Path

from session_state import load_state, save_state, SessionState
from _patterns import STUB_BYTE_PATTERNS, CODE_EXTENSIONS

# =============================================================================
# STOP HOOK RESULT TYPE (distinct from _hook_result.HookResult)
# =============================================================================


@dataclass
class StopHookResult:
    """Result from a Stop hook check.

    Note: This is intentionally different from _hook_result.StopHookResult.
    Stop hooks use "continue"/"block" semantics with stop_reason for warnings,
    while pre/post hooks use "approve"/"deny" with context injection.
    """

    decision: str = "continue"  # "continue" or "block"
    reason: str = ""  # Reason for block
    stop_reason: str = ""  # Warning message (non-blocking)

    @staticmethod
    def ok() -> "StopHookResult":
        return StopHookResult(decision="continue")

    @staticmethod
    def warn(message: str) -> "StopHookResult":
        return StopHookResult(decision="continue", stop_reason=message)

    @staticmethod
    def block(reason: str) -> "StopHookResult":
        return StopHookResult(decision="block", reason=reason)


# =============================================================================
# HOOK REGISTRY
# =============================================================================

# Format: (name, check_function, priority)
HOOKS: list[tuple[str, Callable, int]] = []


def register_hook(name: str, priority: int = 50):
    """Decorator to register a hook check function.

    Hooks can be disabled via environment variable:
        CLAUDE_HOOK_DISABLE_<NAME>=1

    Example:
        CLAUDE_HOOK_DISABLE_SESSION_CLEANUP=1 claude
    """

    def decorator(func: Callable[[dict, SessionState], StopHookResult]):
        # Check if hook is disabled via environment variable
        env_key = f"CLAUDE_HOOK_DISABLE_{name.upper()}"
        if os.environ.get(env_key, "0") == "1":
            return func  # Skip registration
        HOOKS.append((name, func, priority))
        return func

    return decorator


# =============================================================================
# CONFIGURATION
# =============================================================================

SCRIPT_DIR = Path(__file__).parent
CLAUDE_DIR = SCRIPT_DIR.parent
MEMORY_DIR = CLAUDE_DIR / "memory"

# Buffer sizes for transcript scanning
ACK_SCAN_BYTES = 20000
DISMISSAL_SCAN_BYTES = 20000

# Limits
MAX_CREATED_FILES_SCAN = 10

# Dismissal patterns
DISMISSAL_PATTERNS = [
    (r"(this|that|it)('s| is) a false positive", "false_positive"),
    (r"the (warning|hook|gate) is (a )?false positive", "false_positive"),
    (r"hook (is )?(wrong|incorrect|mistaken)", "hook_dismissal"),
    (r"ignore (this|the) (warning|hook|gate)", "ignore_warning"),
    (r"(that|this) warning (is )?(incorrect|wrong)", "false_positive"),
]

# Completion claim patterns - detect when Claude claims task is done
COMPLETION_PATTERNS = [
    r"\b(task|work|implementation|feature|fix|bug)\s+(is\s+)?(now\s+)?(complete|done|finished)\b",
    r"\b(that'?s?|this)\s+(should\s+)?(be\s+)?(all|everything|it)\b",
    r"\bsuccessfully\s+(implemented|completed|fixed|finished)\b",
    r"\b(all\s+)?(changes|work|tasks?)\s+(are\s+)?(complete|done)\b",
    r"\bnothing\s+(left|more|else)\s+to\s+do\b",
    r"^\*\*(?:session\s+)?summary\s+(?:of\s+)?(?:completed?\s+)?(?:work|changes|tasks?)",  # More specific
]

# Confidence threshold for completion claims
COMPLETION_CONFIDENCE_THRESHOLD = 70  # Lowered threshold
COMPLETION_TREND_THRESHOLD = 75  # Below this, must not be declining


# =============================================================================
# HELPER FUNCTIONS
# =============================================================================


def run_git(args: list[str], cwd: str | None = None) -> tuple[int, str, str]:
    """Run git command, return (returncode, stdout, stderr)."""
    try:
        result = subprocess.run(
            ["git"] + args, cwd=cwd, capture_output=True, text=True, timeout=30
        )
        return result.returncode, result.stdout.strip(), result.stderr.strip()
    except subprocess.TimeoutExpired:
        return 1, "", "timeout"
    except Exception as e:
        return 1, "", str(e)


def is_git_repo(cwd: str) -> bool:
    """Check if cwd is inside a git repository."""
    code, _, _ = run_git(["rev-parse", "--git-dir"], cwd)
    return code == 0


def get_changes(cwd: str) -> dict:
    """Get summary of uncommitted changes."""
    changes = {"modified": [], "added": [], "deleted": [], "renamed": []}

    code, stdout, _ = run_git(["status", "--porcelain"], cwd)
    if code != 0 or not stdout:
        return changes

    for line in stdout.split("\n"):
        if len(line) < 3:
            continue
        status = line[:2]
        filepath = line[3:].split(" -> ")[-1]

        if status in ("??", "A ", " A", "AM"):
            changes["added"].append(filepath)
        elif status in (" D", "D ", "AD"):
            changes["deleted"].append(filepath)
        elif status in ("R ", " R", "RM"):
            changes["renamed"].append(filepath)
        else:
            changes["modified"].append(filepath)

    return changes


def _categorize_files(files: list[str]) -> dict[str, list[str]]:
    """Categorize files by directory type."""
    categories = {
        "hooks": [f for f in files if "hooks/" in f],
        "ops": [f for f in files if "ops/" in f],
        "commands": [f for f in files if "commands/" in f],
        "lib": [f for f in files if "lib/" in f],
        "config": [f for f in files if any(c in f for c in ["settings.json", "config/", ".json", ".yaml", ".yml"])],
        "memory": [f for f in files if "memory/" in f],
        "projects": [f for f in files if "projects/" in f],
    }
    categorized = set().union(*categories.values())
    categories["other"] = [f for f in files if f not in categorized]
    return categories


def _build_summary_parts(categories: dict[str, list[str]]) -> list[str]:
    """Build summary parts from file categories."""
    parts = []
    for name in ["hooks", "ops", "commands", "lib", "config", "memory"]:
        if categories[name]:
            parts.append(f"{name} ({len(categories[name])})")
    if categories["projects"]:
        parts.append("projects")
    if categories["other"]:
        other_dirs = {Path(f).parts[0] for f in categories["other"][:5] if len(Path(f).parts) > 1}
        parts.append(", ".join(list(other_dirs)[:3]) if other_dirs else f"{len(categories['other'])} files")
    return parts


def _build_stats_line(changes: dict) -> str:
    """Build stats line from changes dict."""
    stats = []
    for key, label in [("modified", "modified"), ("added", "added"), ("deleted", "deleted"), ("renamed", "renamed")]:
        if changes[key]:
            stats.append(f"{len(changes[key])} {label}")
    return ", ".join(stats) if stats else "no changes"


def generate_commit_message(changes: dict) -> str:
    """Generate semantic commit message from changes."""
    all_files = changes["modified"] + changes["added"] + changes["deleted"] + changes["renamed"]
    if not all_files:
        return ""
    categories = _categorize_files(all_files)
    summary = ", ".join(_build_summary_parts(categories))
    return f"[auto] {summary}\n\nFiles: {_build_stats_line(changes)}"


def check_acknowledgments_in_transcript(
    transcript_path: str,
) -> tuple[bool, bool, list[str]]:
    """Check for acknowledgments in transcript."""
    if not transcript_path or not Path(transcript_path).exists():
        return False, False, []

    try:
        with open(transcript_path, "r") as f:
            f.seek(0, 2)
            size = f.tell()
            f.seek(max(0, size - ACK_SCAN_BYTES))
            content = f.read()

        substantive_matches = re.findall(
            r"[Bb]lock valid:\s*(.{10,200}?)(?:\n|$)", content
        )
        lessons = [m.strip() for m in substantive_matches if m.strip()]
        any_ack = re.search(r"[Bb]lock valid", content)

        return bool(lessons), bool(any_ack), lessons

    except (IOError, OSError):
        return False, False, []


def persist_lessons_to_memory(lessons: list[str], blocks: list[dict]) -> None:
    """Write block lessons to memory."""
    from datetime import datetime

    if not lessons:
        return

    hook_names = list(set(b.get("hook", "unknown") for b in blocks))
    hooks_str = ", ".join(hook_names[:3])

    lessons_file = MEMORY_DIR / "__lessons.md"
    if lessons_file.exists():
        try:
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M")
            entries = []
            for lesson in lessons:
                lesson = lesson.strip().rstrip(".")
                entries.append(
                    f"\n### {timestamp}\n[block-reflection:{hooks_str}] {lesson}\n"
                )
            with open(lessons_file, "a") as f:
                f.writelines(entries)
        except (IOError, OSError):
            pass

    try:
        from project_state import add_global_lesson

        for lesson in lessons:
            lesson = lesson.strip().rstrip(".")
            add_global_lesson(lesson, category=f"block-reflection:{hooks_str}")
    except ImportError:
        pass


def check_dismissals_in_transcript(transcript_path: str) -> list[str]:
    """Check if Claude claimed any false positives without fixing them."""
    if not transcript_path or not Path(transcript_path).exists():
        return []

    warnings = []
    try:
        with open(transcript_path, "r") as f:
            f.seek(0, 2)
            size = f.tell()
            f.seek(max(0, size - DISMISSAL_SCAN_BYTES))
            content = f.read()

        content_lower = content.lower()
        fix_evidence = re.search(r"\.claude/(hooks|lib)/\w+\.py", content)

        if fix_evidence:
            return []

        for pattern, dismissal_type in DISMISSAL_PATTERNS:
            if re.search(pattern, content_lower, re.IGNORECASE):
                warnings.append(
                    f"   `{dismissal_type}`: Claude claimed hook feedback was wrong"
                )

    except (IOError, OSError):
        pass

    return warnings


# =============================================================================
# HOOK IMPLEMENTATIONS
# =============================================================================


@register_hook("auto_commit", priority=10)
def check_auto_commit(data: dict, state: SessionState) -> StopHookResult:
    """Commit all changes (semantic backup)."""
    cwd = data.get("cwd") or os.environ.get("CLAUDE_PROJECT_DIR") or os.getcwd()

    if not is_git_repo(cwd):
        return StopHookResult.ok()

    changes = get_changes(cwd)
    total = sum(len(v) for v in changes.values())

    if total == 0:
        return StopHookResult.ok()

    message = generate_commit_message(changes)
    if not message:
        return StopHookResult.ok()

    # Stage all changes
    code, _, stderr = run_git(["add", "-A"], cwd)
    if code != 0:
        return StopHookResult.warn(f" Auto-commit: git add failed: {stderr}")

    # Commit
    code, _, stderr = run_git(["commit", "-m", message], cwd)
    if code != 0:
        if "nothing to commit" not in stderr.lower():
            return StopHookResult.warn(f" Auto-commit failed: {stderr}")
        return StopHookResult.ok()

    # Report success in state (not blocking)
    summary = message.split("\n")[0]
    return StopHookResult.warn(f" Auto-committed: {summary} ({total} files)")


@register_hook("session_blocks", priority=30)
def check_session_blocks(data: dict, state: SessionState) -> StopHookResult:
    """Require reflection on session blocks."""
    from synapse_core import get_session_blocks, clear_session_blocks

    transcript_path = data.get("transcript_path", "")
    blocks = get_session_blocks()

    if not blocks:
        return StopHookResult.ok()

    # Check for acknowledgments
    substantive_ack, any_ack, lessons = check_acknowledgments_in_transcript(
        transcript_path
    )

    if substantive_ack:
        persist_lessons_to_memory(lessons, blocks)
        clear_session_blocks()
        return StopHookResult.ok()

    # Group by hook and function
    hook_details = {}
    for b in blocks:
        hook = b.get("hook", "unknown")
        func = b.get("function", "")
        key = f"{hook}" + (f" ({func})" if func else "")
        hook_details[key] = hook_details.get(key, 0) + 1

    if any_ack and not substantive_ack:
        # Mechanical ack - soft warning
        lines = [" **BLOCKS ACKNOWLEDGED** - but no lesson captured:"]
        for detail, count in sorted(hook_details.items(), key=lambda x: -x[1])[:3]:
            lines.append(f"   `{detail}`: {count}x")
        lines.append("\n**TIP:** 'Block valid: [lesson]' captures why it happened.")
        clear_session_blocks()
        return StopHookResult.warn("\n".join(lines))

    # No acknowledgment - require reflection
    lines = [" **SESSION BLOCKS DETECTED** - Reflection required:"]
    for detail, count in sorted(hook_details.items(), key=lambda x: -x[1])[:5]:
        lines.append(f"   `{detail}`: {count}x")

    last_block = blocks[-1]
    reason_preview = last_block.get("reason", "")[:100]
    if reason_preview:
        lines.append(f"\n  Last block: {reason_preview}...")

    lines.append("\n**REFLECT:** Why did these blocks fire? How to avoid next time?")
    clear_session_blocks()

    return StopHookResult.block("\n".join(lines))


@register_hook("dismissal_check", priority=40)
def check_dismissal(data: dict, state: SessionState) -> StopHookResult:
    """Catch false positive claims without fix."""
    transcript_path = data.get("transcript_path", "")
    dismissals = check_dismissals_in_transcript(transcript_path)

    if not dismissals:
        return StopHookResult.ok()

    lines = [" **FALSE POSITIVE CLAIMED** - Fix required:"]
    lines.extend(dismissals)
    lines.append(
        "\n**REQUIRED:** Fix the hook that fired incorrectly. This block repeats until fixed."
    )

    return StopHookResult.block("\n".join(lines))


@register_hook("completion_gate", priority=45)
def check_completion_confidence(data: dict, state: SessionState) -> StopHookResult:
    """Block completion claims if confidence < 70%, or < 75% with negative trend.

    This prevents lazy completion and reward hacking - Claude must earn
    confidence through actual verification (test pass, build success, user OK)
    before claiming a task is complete.
    """
    # Import confidence utilities
    from confidence import get_tier_info, INCREASERS

    # Check current confidence and trend
    confidence = getattr(state, "confidence", 70)
    prev_confidence = getattr(state, "completion_gate_prev_confidence", confidence)
    state.completion_gate_prev_confidence = confidence  # Track for next check

    is_declining = confidence < prev_confidence

    # Pass if above threshold
    if confidence >= COMPLETION_CONFIDENCE_THRESHOLD:
        # But block if in danger zone (< 75%) AND declining
        if confidence < COMPLETION_TREND_THRESHOLD and is_declining:
            pass  # Fall through to block
        else:
            return StopHookResult.ok()

    # Scan recent assistant output for completion claims
    transcript_path = data.get("transcript_path", "")
    if not transcript_path or not Path(transcript_path).exists():
        return StopHookResult.ok()

    try:
        with open(transcript_path, "rb") as f:
            f.seek(0, 2)  # End
            size = f.tell()
            f.seek(max(0, size - 15000))  # Last 15KB
            content = f.read().decode("utf-8", errors="ignore").lower()
    except (OSError, PermissionError):
        return StopHookResult.ok()

    # Check for completion patterns
    for pattern in COMPLETION_PATTERNS:
        if re.search(pattern, content, re.IGNORECASE | re.MULTILINE):
            tier_name, emoji, _ = get_tier_info(confidence)

            # Build guidance on how to raise confidence
            boost_options = []
            for inc in INCREASERS:
                if not inc.requires_approval:
                    boost_options.append(
                        f"   {inc.name}: {inc.description} (+{inc.delta})"
                    )

            # Determine block reason
            if confidence < COMPLETION_CONFIDENCE_THRESHOLD:
                reason = f"below {COMPLETION_CONFIDENCE_THRESHOLD}%"
            else:
                reason = f"declining in danger zone (<{COMPLETION_TREND_THRESHOLD}%)"

            return StopHookResult.block(
                f" **COMPLETION BLOCKED** - Confidence {reason}\n\n"
                f"Current: {emoji} {confidence}% ({tier_name})"
                + (f"  (was {prev_confidence}%)" if is_declining else "")
                + "\n\n**How to raise confidence:**\n"
                + "\n".join(boost_options[:5])
                + "\n\nOr: 'CONFIDENCE_BOOST_APPROVED'"
            )

    return StopHookResult.ok()


# Language patterns for bad behavior detection
BAD_LANGUAGE_PATTERNS = {
    "overconfident_completion": {
        "delta": -15,
        "patterns": [
            r"\b100%\s*(done|complete|finished|ready)\b",
            r"\bcompletely\s+(done|finished|ready)\b",
            r"\bperfectly\s+(done|finished|working)\b",
            r"\bfully\s+complete[d]?\b",
        ],
    },
    "deferral": {
        "delta": -12,
        "patterns": [
            r"\bskip\s+(this\s+)?(for\s+)?now\b",
            r"\bcome\s+back\s+(to\s+(this|it)\s+)?later\b",
            r"\bdo\s+(this|it)\s+later\b",
            r"\bleave\s+(this|it)\s+for\s+(now|later)\b",
            r"\bwe\s+can\s+(do|address|handle)\s+(this|it)\s+later\b",
            r"\bpostpone\b",
            r"\bdefer\s+(this|it)\b",
            # "investigate later" variants - absolute cancer
            r"\b(bug|issue|problem|this)\s+to\s+investigate\s+later\b",
            r"\binvestigate\s+(this\s+)?(later|another\s+time)\b",
            r"\blook\s+into\s+(this\s+)?(later|another\s+time)\b",
            r"\bfix\s+(this\s+)?(later|another\s+time)\b",
            r"\baddress\s+(this\s+)?(later|another\s+time)\b",
            r"\btable\s+(this|it)\s+for\s+(now|later)\b",
            r"\bpunt\s+(on\s+)?(this|it)\b",
            r"\bshelve\s+(this|it)\b",
            r"\bbacklog\s+(this|it)\b",
        ],
    },
    "apologetic": {
        "delta": -5,
        "patterns": [
            r"\b(i'?m\s+)?sorry\b",
            r"\bmy\s+(mistake|bad|apologies|fault)\b",
            r"\bi\s+apologize\b",
            r"\bapologies\s+for\b",
        ],
    },
    "sycophancy": {
        "delta": -8,
        "patterns": [
            r"\byou'?re\s+(absolutely|totally|completely|entirely)\s+right\b",
            r"\babsolutely\s+right\b",
            r"\byou'?re\s+right,?\s+(i|my)\b",
            r"\bthat'?s\s+(absolutely|totally|completely)\s+(correct|true|right)\b",
            r"\bgreat\s+(point|observation|catch)\b",
            r"\bexcellent\s+(point|observation|catch)\b",
        ],
    },
    # Theater patterns - look busy without substance
    "filler_preamble": {
        "delta": -5,
        "patterns": [
            r"\bgreat\s+question\b",
            r"\bgood\s+question\b",
            r"\bi\s+understand\s+(your|the|what)\b",
            r"\bi'?d\s+be\s+happy\s+to\b",
            r"\bi'?ll\s+be\s+happy\s+to\b",
            r"^certainly[!.,]",
            r"^absolutely[!.,]",
            r"^of\s+course[!.,]",
            r"\blet\s+me\s+help\s+you\s+with\b",
        ],
    },
    "confirmation_theater": {
        "delta": -5,
        "patterns": [
            r"\bwould\s+you\s+like\s+me\s+to\b",
            r"\bshould\s+i\s+proceed\b",
            r"\bdo\s+you\s+want\s+me\s+to\b",
            r"\bshall\s+i\s+(start|begin|proceed|continue)\b",
            r"\bwant\s+me\s+to\s+(go\s+ahead|proceed)\b",
        ],
    },
    "announcement_theater": {
        "delta": -3,
        "patterns": [
            r"\bnow\s+i\s+will\b",
            r"\bnow\s+i'?m\s+going\s+to\b",
            r"\bi'?m\s+now\s+going\s+to\b",
            r"\blet\s+me\s+now\b",
            r"\bi'?ll\s+now\b",
            r"\bnext,?\s+i\s+will\b",
            r"\bnext,?\s+i'?ll\b",
        ],
    },
    "excessive_affirmation": {
        "delta": -3,
        "patterns": [
            r"^sure[!.,]\s",
            r"^yes[!.,]\s+i\s+(can|will)\b",
            r"\bhappy\s+to\s+help\b",
            r"\bglad\s+to\s+help\b",
            r"\bno\s+problem[!.,]",
        ],
    },
    "bikeshedding": {
        "delta": -8,
        "patterns": [
            # Naming deliberation
            r"\bwe\s+could\s+(call|name)\s+it\s+\w+\s+or\s+\w+\b",
            r"\b(name|call)\s+it\s+(either\s+)?\w+\s+or\s+\w+\b",
            r"\boption\s+(a|1)[:\s].*\boption\s+(b|2)\b",
            # Excessive deliberation on trivial matters
            r"\bon\s+(the\s+)?one\s+hand\b.*\bon\s+the\s+other\s+hand\b",
            r"\bpros\s+and\s+cons\b.{0,50}\b(naming|style|format)",
            r"\b(tabs?\s+vs\.?\s+spaces?|spaces?\s+vs\.?\s+tabs?)\b",
            r"\b(single|double)\s+quotes?\s+vs\.?\s+(single|double)\b",
        ],
    },
    "greenfield_impulse": {
        "delta": -10,
        "patterns": [
            # "Start fresh" when modification is likely better
            r"\bstart\s+(from\s+)?scratch\b",
            r"\bbuild\s+(it\s+)?fresh\b",
            r"\brewrite\s+(it\s+)?from\s+(the\s+)?ground\s+up\b",
            r"\bscrap\s+(it|this|the)\s+and\s+(start|build)\b",
            r"\bthrow\s+(it|this)\s+away\s+and\b",
            # Creating new when existing should be modified
            r"\bcreate\s+a\s+new\s+\w+\s+(instead|rather)\b",
            r"\bwrite\s+a\s+new\s+\w+\s+(instead|rather)\b",
            r"\bbuild\s+a\s+new\s+\w+\s+(instead|rather)\b",
        ],
    },
    "passive_deflection": {
        "delta": -8,
        "patterns": [
            # Deflecting to user
            r"\b(up\s+to\s+you|your\s+(choice|call|decision))\b",
            r"\blet\s+me\s+know\s+(what\s+you\s+prefer|your\s+preference)\b",
            r"\bwhatever\s+you\s+(think|prefer|want)\b",
            r"\bi'?ll\s+leave\s+(it|that)\s+(up\s+)?to\s+you\b",
            # Apathetic hedging
            r"\bit\s+depends\b(?!\s+on\s+(the|whether))",  # allow "it depends on X"
            r"\bthere\s+are\s+many\s+(ways|approaches|options)\b(?!\.\s+i\s+recommend)",
            r"\bi'?m\s+not\s+(sure|certain)\b(?!\s*(,\s*)?(but|so)\s+let\s+me)",  # allow "not sure, let me check"
            r"\bi\s+don'?t\s+know\b(?!\s*(,\s*)?(but|so)\s+(let\s+me|i'?ll))",  # allow "don't know, let me investigate"
            # Open-ended non-answers
            r"\byou\s+could\s+(try|do|use)\s+\w+\s+or\s+\w+\b(?!\.\s*(i\s+)?(recommend|suggest))",
            r"\beither\s+(way|option)\s+(works|is\s+fine)\b",
            r"\bboth\s+(approaches|options)\s+(are|have)\s+(valid|merit)\b",
            # Lazy deflection
            r"\bthat'?s\s+beyond\s+(my|the)\s+scope\b",
            r"\bi\s+can'?t\s+(help|assist)\s+with\s+that\b(?!\s+because)",
        ],
    },
    "obvious_next_steps": {
        "delta": -5,
        "patterns": [
            # Obvious testing suggestions
            r"\btest\s+(?:in\s+)?(?:real\s+)?usage\b",
            r"\btest\s+the\s+(?:new\s+)?(?:patterns?|changes?|implementation)\b",
            r"\bverify\s+(?:it\s+)?works\b",
            r"\bplay\s*test\b",
            r"\btry\s+it\s+out\b",
            r"\bsee\s+how\s+it\s+(?:works|performs)\b",
            # Obvious iteration suggestions
            r"\btune\s+(?:the\s+)?(?:values?|deltas?|parameters?)\b",
            r"\badjust\s+(?:as\s+)?needed\b",
            r"\bmonitor\s+(?:for\s+)?(?:issues?|problems?)\b",
            r"\bwatch\s+(?:for\s+)?(?:issues?|problems?|errors?)\b",
            # Generic obvious actions
            r"\b(?:run|do)\s+(?:the\s+)?(?:tests?|builds?)\s+(?:to\s+)?(?:verify|check|confirm)\b",
        ],
    },
    "surrender_pivot": {
        "delta": -20,  # Severe penalty - this is CANCER behavior
        "patterns": [
            # Invented time constraints (LLMs have no time limits)
            r"\b(given|due\s+to)\s+(the\s+)?time\s+constraints?\b",
            r"\btime\s+(is\s+)?limited\b",
            r"\bfor\s+(the\s+)?sake\s+of\s+time\b",
            r"\bto\s+save\s+time\b",
            r"\bquickly\s+switch\s+to\b",
            # Unilateral pivots without asking
            r"\blet\s+me\s+(switch|use|try)\s+\w+\s+instead\b",
            r"\bi'?ll\s+(switch|use)\s+\w+\s+instead\b",
            r"\bswitching\s+to\s+\w+\s+(instead|which)\b",
            # Abandoning because "incomplete" without fixing
            r"\b(is\s+)?incomplete[.,]?\s+(so\s+)?(let\s+me|i'?ll)\s+(switch|use)\b",
            r"\bdoesn'?t\s+work[.,]?\s+(so\s+)?(let\s+me|i'?ll)\s+(switch|use)\b",
            # "Proven/out-of-the-box" as excuse
            r"\bproven\s+(model|solution|approach)\s+that\s+works\b",
            r"\bout[- ]of[- ]the[- ]box\s+(solution|alternative)\b",
            r"\bworks\s+out[- ]of[- ]the[- ]box\b",
            # Goal abandonment language
            r"\bgiven\s+(the\s+)?(issues?|problems?|difficulties?)[.,]\s+(let\s+me|i'?ll)\s+(switch|use|try)\b",
            r"\beasier\s+(to\s+)?(just\s+)?use\s+\w+\s+instead\b",
        ],
    },
}


def _collect_bad_language_triggers(
    content: str, state: SessionState
) -> list[tuple[str, int]]:
    """Scan content for bad language patterns, respecting cooldowns."""
    triggered = []
    for name, config in BAD_LANGUAGE_PATTERNS.items():
        cooldown_key = f"bad_lang_{name}_turn"
        if state.turn_count - state.nudge_history.get(cooldown_key, 0) < 3:
            continue
        for pattern in config["patterns"]:
            if re.search(pattern, content, re.IGNORECASE):
                triggered.append((name, config["delta"]))
                state.nudge_history[cooldown_key] = state.turn_count
                break
    return triggered


def _get_violation_multiplier(num_violations: int) -> float:
    """Get compounding multiplier for multiple violations."""
    if num_violations >= 4:
        return 3.0
    if num_violations >= 3:
        return 2.0
    if num_violations >= 2:
        return 1.5
    return 1.0


@register_hook("bad_language_detector", priority=46)
def check_bad_language(data: dict, state: SessionState) -> StopHookResult:
    """Detect and penalize bad language patterns in assistant output."""
    from confidence import (
        apply_rate_limit, format_confidence_change,
        format_dispute_instructions, get_tier_info, set_confidence,
    )

    transcript_path = data.get("transcript_path", "")
    if not transcript_path or not Path(transcript_path).exists():
        return StopHookResult.ok()

    try:
        with open(transcript_path, "rb") as f:
            f.seek(0, 2)
            f.seek(max(0, f.tell() - 20000))
            content = f.read().decode("utf-8", errors="ignore")
    except (OSError, PermissionError):
        return StopHookResult.ok()

    triggered = _collect_bad_language_triggers(content, state)
    if not triggered:
        return StopHookResult.ok()

    old_confidence = state.confidence
    total_delta = int(sum(d for _, d in triggered) * _get_violation_multiplier(len(triggered)))

    has_surrender = any(name == "surrender_pivot" for name, _ in triggered)
    if not has_surrender:
        total_delta = apply_rate_limit(total_delta, state)

    new_confidence = max(0, min(100, old_confidence + total_delta))
    set_confidence(state, new_confidence, "bad language detected")

    reasons = [f"{name}: {delta}" for name, delta in triggered]
    change_msg = format_confidence_change(old_confidence, new_confidence, ", ".join(reasons))
    _, emoji, desc = get_tier_info(new_confidence)
    dispute_hint = format_dispute_instructions([n for n, _ in triggered])

    return StopHookResult.warn(
        f" **Bad Language Detected**\n{change_msg}\n\n"
        f"Current: {emoji} {new_confidence}% - {desc}{dispute_hint}"
    )


# Positive language patterns for verification behavior
GOOD_LANGUAGE_PATTERNS = {
    "verification_intent": {
        "delta": 3,
        "patterns": [
            r"\blet\s+me\s+(just\s+)?(check|verify|confirm|validate|inspect)\b",
            r"\bi'?ll\s+(just\s+)?(check|verify|confirm|validate|inspect)\b",
            r"\blet\s+me\s+(first\s+)?(read|look\s+at|examine|review)\b",
            r"\bbefore\s+(i|we)\s+(proceed|continue|start)\b.*\b(check|verify|confirm)\b",
            r"\bfirst,?\s+(let\s+me\s+)?(check|verify|read|confirm)\b",
        ],
    },
    "evidence_gathering": {
        "delta": 2,
        "patterns": [
            r"\bto\s+understand\s+(this|the|how)\b",
            r"\bto\s+see\s+(what|how|if|whether)\b",
            r"\bto\s+confirm\s+(that|this|the|whether)\b",
            r"\bto\s+verify\s+(that|this|the|whether)\b",
        ],
    },
    "proactive_contribution": {
        "delta": 5,
        "patterns": [
            # "I also" patterns (extra work done)
            r"\bi\s+also\s+(fixed|addressed|cleaned|updated|improved|noticed\s+and\s+fixed)\b",
            r"\bwhile\s+(i\s+was\s+)?(there|at\s+it|doing\s+this),?\s+i\s+(also\s+)?(fixed|cleaned|updated)\b",
            r"\badditionally,?\s+i\s+(went\s+ahead\s+and\s+)?(fixed|addressed|cleaned|improved)\b",
            r"\bi\s+went\s+ahead\s+and\s+(also\s+)?(fixed|cleaned|ran|added)\b",
            # Bonus/extra patterns
            r"\b(bonus|as\s+a\s+bonus)[:\s]+\s*i\b",
            r"\bextra[:\s]+i\s+(also\s+)?\b",
            # Proactive quality signals
            r"\bi\s+ran\s+(the\s+)?(tests?|lints?|checks?)\s+(to\s+make\s+sure|to\s+verify|proactively)\b",
            r"\bcaught\s+(and\s+fixed|this\s+while)\b",
        ],
    },
    "debt_removal": {
        "delta": 10,
        "patterns": [
            # Removing dead/unused code
            r"\b(removed|deleted|cleaned\s+up)\s+(dead|unused|obsolete|stale)\s+(code|imports?|files?|functions?)\b",
            r"\b(removed|deleted)\s+\d+\s+(unused|dead)\b",
            r"\bpaid\s+(down|off)\s+(tech(nical)?|org(anizational)?)\s+debt\b",
            # Resolving TODOs/FIXMEs
            r"\b(resolved|completed|addressed|fixed)\s+(the\s+)?(TODO|FIXME|HACK)\b",
            r"\b(removed|cleared)\s+(a\s+)?(TODO|FIXME)\b",
            # Cleanup actions
            r"\bcleaned\s+up\s+(the\s+)?(codebase|code|file|module)\b",
            r"\brefactored\s+(away|out)\s+(the\s+)?(tech(nical)?\s+)?debt\b",
            r"\beliminated\s+(the\s+)?(tech(nical)?\s+)?debt\b",
            # File/code removal
            r"\bdeleted\s+(the\s+)?(deprecated|legacy|old)\s+(code|file|module)\b",
            r"\bremoved\s+(commented|commented-out)\s+code\b",
        ],
    },
    "assertive_stance": {
        "delta": 5,
        "patterns": [
            # Direct recommendations
            r"\bi\s+recommend\b",
            r"\byou\s+should\b",
            r"\bthe\s+(best|right|correct)\s+(approach|way|solution)\s+is\b",
            r"\buse\s+this\b",
            r"\bdo\s+this\b",
            r"\bhere'?s\s+(the|my)\s+(fix|solution|recommendation)\b",
            # Taking ownership
            r"\bi'?ll\s+(do|handle|fix|implement)\s+(this|it|that)\b",
            r"\bdoing\s+(this|it)\s+now\b",
            r"\bfixing\s+(this|it)\s+now\b",
            # Direct assertions
            r"\bthis\s+is\s+(the|a)\s+(bug|issue|problem|cause)\b",
            r"\bthe\s+(issue|problem|bug)\s+is\b",
            r"\bi\s+disagree\b",
            r"\bthat'?s\s+(incorrect|wrong|not\s+right)\b",
        ],
    },
}


@register_hook("good_language_detector", priority=47)
def check_good_language(data: dict, state: SessionState) -> StopHookResult:
    """Detect and reward verification language patterns in assistant output.

    Rewards: "let me check", "let me verify", evidence-gathering statements.
    """
    from confidence import (
        apply_rate_limit,
        format_confidence_change,
        get_tier_info,
        set_confidence,
    )

    # Get recent transcript content
    transcript_path = data.get("transcript_path", "")
    if not transcript_path or not Path(transcript_path).exists():
        return StopHookResult.ok()

    try:
        with open(transcript_path, "rb") as f:
            f.seek(0, 2)  # End
            size = f.tell()
            f.seek(max(0, size - 20000))  # Last 20KB
            content = f.read().decode("utf-8", errors="ignore")
    except (OSError, PermissionError):
        return StopHookResult.ok()

    # Track which patterns triggered
    triggered = []

    for name, config in GOOD_LANGUAGE_PATTERNS.items():
        # Check cooldown (longer cooldown to prevent gaming)
        cooldown_key = f"good_lang_{name}_turn"
        last_turn = state.nudge_history.get(cooldown_key, 0)
        if state.turn_count - last_turn < 5:  # 5 turn cooldown
            continue

        for pattern in config["patterns"]:
            if re.search(pattern, content, re.IGNORECASE):
                triggered.append((name, config["delta"]))
                state.nudge_history[cooldown_key] = state.turn_count
                break  # Only trigger once per category

    if not triggered:
        return StopHookResult.ok()

    # Apply rewards with rate limiting
    old_confidence = state.confidence
    total_delta = sum(delta for _, delta in triggered)
    total_delta = apply_rate_limit(total_delta, state)
    new_confidence = max(0, min(100, old_confidence + total_delta))

    set_confidence(state, new_confidence, "verification language detected")

    # Format feedback
    reasons = [f"{name}: +{delta}" for name, delta in triggered]
    change_msg = format_confidence_change(
        old_confidence, new_confidence, ", ".join(reasons)
    )

    _, emoji, desc = get_tier_info(new_confidence)

    return StopHookResult.ok(
        f" **Verification Language**\n{change_msg}\n\n"
        f"Current: {emoji} {new_confidence}% - {desc}"
    )


# Verification theater patterns - claims that need tool evidence
VERIFICATION_CLAIMS = {
    "test_claim": {
        "patterns": [
            r"\btests?\s+(are\s+)?(pass(ing|ed)?|green|succeed(ed|ing)?)\b",
            r"\ball\s+tests?\s+(pass|green)\b",
            r"\bpytest\s+(pass|succeed)\b",
            r"\bi\s+ran\s+(the\s+)?tests?\b",
        ],
        "evidence_key": "tests_run",  # Check state.tests_run or recent test commands
    },
    "lint_claim": {
        "patterns": [
            r"\blint\s+(is\s+)?(clean|pass(ing|ed)?|green)\b",
            r"\bruff\s+(check\s+)?(pass|clean|green)\b",
            r"\bno\s+(lint(ing)?|ruff)\s+(errors?|issues?|warnings?)\b",
        ],
        "evidence_key": "lint_run",
    },
    "fixed_claim": {
        "patterns": [
            r"\b(fixed|resolved|solved)\s+(it|this|the\s+(bug|issue|problem))\b",
            r"\bthat\s+(should\s+)?(fix|resolve|solve)\s+(it|this|the)\b",
            r"\b(bug|issue|problem)\s+(is\s+)?(now\s+)?(fixed|resolved|solved)\b",
        ],
        "evidence_key": "recent_write",  # Need a recent file write
    },
}


def _read_tail_content(path: str, tail_bytes: int = 10000) -> str | None:
    """Read last N bytes of file as string, or None on error."""
    try:
        with open(path, "rb") as f:
            f.seek(0, 2)
            f.seek(max(0, f.tell() - tail_bytes))
            return f.read().decode("utf-8", errors="ignore").lower()
    except (OSError, PermissionError):
        return None


def _has_evidence(state: SessionState, evidence_key: str) -> bool:
    """Check if evidence exists for a verification claim."""
    if evidence_key == "tests_run":
        recent = state.commands_succeeded[-5:] + state.commands_failed[-5:]
        return any(t in cmd for cmd in recent for t in ["pytest", "npm test", "jest", "cargo test", "go test"])
    elif evidence_key == "lint_run":
        return any(lc in cmd for cmd in state.commands_succeeded[-5:] for lc in ["ruff check", "eslint", "clippy", "pylint"])
    elif evidence_key == "recent_write":
        return len(state.files_edited) > 0
    return False


@register_hook("verification_theater_detector", priority=48)
def check_verification_theater(data: dict, state: SessionState) -> StopHookResult:
    """Detect verification claims without tool evidence."""
    from confidence import apply_rate_limit, get_tier_info, set_confidence

    content = _read_tail_content(data.get("transcript_path", ""))
    if not content:
        return StopHookResult.ok()

    triggered = []
    for claim_type, config in VERIFICATION_CLAIMS.items():
        cooldown_key = f"verify_theater_{claim_type}_turn"
        if state.turn_count - state.nudge_history.get(cooldown_key, 0) < 3:
            continue
        if not any(re.search(p, content) for p in config["patterns"]):
            continue
        if not _has_evidence(state, config["evidence_key"]):
            delta = -8 if claim_type == "fixed_claim" else -15
            triggered.append((claim_type, delta))
            state.nudge_history[cooldown_key] = state.turn_count

    if not triggered:
        return StopHookResult.ok()

    total_delta = apply_rate_limit(sum(d for _, d in triggered), state)
    new_conf = max(0, min(100, state.confidence + total_delta))
    set_confidence(state, new_conf, "verification theater")
    _, emoji, desc = get_tier_info(new_conf)
    return StopHookResult.warn(f" VERIFICATION THEATER: {emoji} {new_conf}% | Claims without evidence")


@register_hook("stub_detector", priority=50)
def check_stubs(data: dict, state: SessionState) -> StopHookResult:
    """Check created files for stubs."""
    warnings = []

    for filepath in state.files_created[-MAX_CREATED_FILES_SCAN:]:
        path = Path(filepath)
        if not path.exists() or path.suffix not in CODE_EXTENSIONS:
            continue

        try:
            content = path.read_bytes()
            stubs = [p.decode() for p in STUB_BYTE_PATTERNS if p in content]
            if stubs:
                warnings.append(f"   `{path.name}`: {', '.join(stubs[:2])}")
        except (OSError, PermissionError):
            pass

    if not warnings:
        return StopHookResult.ok()

    lines = [" **ABANDONED WORK** - Files with stubs:"]
    lines.extend(warnings)
    return StopHookResult.warn("\n".join(lines))


@register_hook("pending_greps", priority=70)
def check_pending_greps(data: dict, state: SessionState) -> StopHookResult:
    """Check for unverified function edits."""
    pending = state.pending_integration_greps
    if not pending:
        return StopHookResult.ok()

    funcs = [p.get("function", "unknown") for p in pending[:3]]
    return StopHookResult.warn(
        f" **UNVERIFIED EDITS** - Functions need grep: {', '.join(funcs)}"
    )


@register_hook("unresolved_errors", priority=80)
def check_unresolved_errors(data: dict, state: SessionState) -> StopHookResult:
    """Check for lingering errors."""
    if not state.errors_unresolved:
        return StopHookResult.ok()

    error = state.errors_unresolved[-1]
    return StopHookResult.warn(
        f" **UNRESOLVED ERROR**: {error.get('type', 'unknown')[:50]}"
    )


_TODO_PATTERNS = [b"TODO", b"FIXME", b"HACK", b"XXX"]


def _scan_file_for_debt(filepath: str, check_todos: bool = False) -> tuple[list[str], int]:
    """Scan a file for stubs and optionally TODOs. Returns (items, score)."""
    path = Path(filepath)
    if not path.exists() or path.suffix not in CODE_EXTENSIONS:
        return [], 0
    try:
        content = path.read_bytes()
    except (OSError, PermissionError):
        return [], 0

    items, score = [], 0
    if any(p in content for p in STUB_BYTE_PATTERNS):
        items.append(f"stub in {path.name}")
        score += 5
    if check_todos:
        for pattern in _TODO_PATTERNS:
            if pattern in content:
                items.append(f"{pattern.decode()} in {path.name}")
                score += 2
                break
    return items, score


@register_hook("session_debt_penalty", priority=85)
def check_session_debt(data: dict, state: SessionState) -> StopHookResult:
    """Penalize ending session with technical/organizational debt."""
    from confidence import get_tier_info, set_confidence

    debt_items, debt_score = [], 0

    # Scan created files for stubs
    for fp in state.files_created[-20:]:
        items, score = _scan_file_for_debt(fp, check_todos=False)
        debt_items.extend(items)
        debt_score += score

    # Scan edited files for stubs and TODOs
    for fp in state.files_edited[-20:]:
        items, score = _scan_file_for_debt(fp, check_todos=True)
        debt_items.extend(items)
        debt_score += score

    # Unresolved errors and pending greps
    if state.errors_unresolved:
        debt_items.append(f"{len(state.errors_unresolved)} unresolved error(s)")
        debt_score += 10 * len(state.errors_unresolved)
    if state.pending_integration_greps:
        debt_items.append(f"{len(state.pending_integration_greps)} unverified edit(s)")
        debt_score += 5 * len(state.pending_integration_greps)

    if not debt_items or debt_score < 5:
        return StopHookResult.ok()

    penalty = min(debt_score, 20)
    new_confidence = max(0, state.confidence - penalty)
    set_confidence(state, new_confidence, "session debt penalty")
    _, emoji, _ = get_tier_info(new_confidence)
    debt_list = ", ".join(debt_items[:3])

    if debt_score >= 15 or new_confidence < 70:
        return StopHookResult.block(f" SESSION DEBT: {debt_list} | Fix or SUDO")
    return StopHookResult.warn(f" SESSION DEBT: {emoji} {new_confidence}% | {debt_list}")


# =============================================================================
# MAIN RUNNER
# =============================================================================


def run_hooks(data: dict, state: SessionState) -> dict:
    """Run all hooks and return aggregated result."""
    # Hooks pre-sorted at module load

    stop_reasons = []
    block_reason = None

    for name, check_func, priority in HOOKS:
        try:
            result = check_func(data, state)

            # First block wins
            if result.decision == "block" and not block_reason:
                block_reason = result.reason

            # Collect stop reasons
            if result.stop_reason:
                stop_reasons.append(result.stop_reason)

        except Exception as e:
            print(f"[stop-runner] Hook {name} error: {e}", file=sys.stderr)

    # Build output
    if block_reason:
        return {"decision": "block", "reason": block_reason}
    elif stop_reasons:
        return {"stopReason": "\n\n".join(stop_reasons)}
    else:
        return {"status": "pass", "message": "No cleanup issues detected"}


# Pre-sort hooks by priority at module load (avoid re-sorting on every call)
HOOKS.sort(key=lambda x: x[2])


def main():
    """Main entry point."""
    start = time.time()

    try:
        data = json.load(sys.stdin)
    except (json.JSONDecodeError, ValueError):
        data = {}

    # Single state load
    try:
        state = load_state()
    except Exception:
        from session_state import SessionState

        state = SessionState()

    # Run all hooks
    result = run_hooks(data, state)

    # Single state save
    save_state(state)

    # Output result
    print(json.dumps(result))

    # Debug timing
    elapsed = (time.time() - start) * 1000
    if elapsed > 200:
        print(f"[stop-runner] Slow: {elapsed:.1f}ms", file=sys.stderr)

    sys.exit(0)


if __name__ == "__main__":
    main()
</file>

<file path="subagent_stop.py">
#!/usr/bin/env python3
"""
SubagentStop Hook: Fires when Task tool agents finish.

Hook Type: SubagentStop
Latency Target: <100ms

Same quality checks as Stop hook - ensures subagents don't leave
abandoned work or unverified edits. Also checks for session blocks.

Input: session_id, transcript_path, permission_mode, hook_event_name, stop_hook_active
Output: { "decision": "block", "reason": string } or nothing
"""

import _lib_path  # noqa: F401
import sys
import json
from pathlib import Path

from session_state import load_state
from synapse_core import get_session_blocks, clear_session_blocks
from _patterns import STUB_BYTE_PATTERNS, CODE_EXTENSIONS


def check_stubs_in_created_files(state) -> list[str]:
    """Check created files for stubs."""
    warnings = []

    for filepath in state.files_created[-5:]:  # Last 5 for subagents
        path = Path(filepath)
        if not path.exists() or path.suffix not in CODE_EXTENSIONS:
            continue

        try:
            content = path.read_bytes()
            stubs = [p.decode() for p in STUB_BYTE_PATTERNS if p in content]
            if stubs:
                warnings.append(f"   `{path.name}`: {', '.join(stubs[:2])}")
        except (OSError, PermissionError):
            pass

    return warnings


def main():
    try:
        json.load(sys.stdin)
    except (json.JSONDecodeError, ValueError):
        pass

    state = load_state()
    messages = []
    must_reflect = False

    # Check for session blocks (subagent may have triggered some)
    blocks = get_session_blocks()
    if blocks:
        must_reflect = True
        hook_counts = {}
        for b in blocks:
            hook = b.get("hook", "unknown")
            hook_counts[hook] = hook_counts.get(hook, 0) + 1
        messages.append(" Subagent hit blocks:")
        for hook, count in sorted(hook_counts.items(), key=lambda x: -x[1])[:3]:
            messages.append(f"   `{hook}`: {count}x")

        # Clear blocks after showing - prevents repeated reflection demands
        clear_session_blocks()

    # Check for abandoned stubs
    stub_warnings = check_stubs_in_created_files(state)
    if stub_warnings:
        messages.append(" Subagent left stubs:")
        messages.extend(stub_warnings)

    # Check for pending integration greps
    pending = state.pending_integration_greps
    if pending:
        funcs = [p.get("function", "?") for p in pending[:2]]
        messages.append(f" Unverified edits: {', '.join(funcs)}")

    if must_reflect:
        output = {"decision": "block", "reason": "\n".join(messages)}
        print(json.dumps(output))
    elif messages:
        output = {"stopReason": "\n".join(messages)}
        print(json.dumps(output))

    sys.exit(0)


if __name__ == "__main__":
    main()
</file>

<file path="user_prompt_submit_runner.py">
#!/usr/bin/env python3
"""
Composite UserPromptSubmit Runner: Runs all UserPromptSubmit hooks in a single process.

PERFORMANCE: ~50ms for 29 hooks vs ~500ms for individual processes (10x faster)

HOOKS INDEX (by priority):
  GATING (0-10) - _prompt_gating.py:
    0  confidence_override      - SUDO bypass and CONFIDENCE_BOOST
    1  goal_anchor              - Block scope expansion, warn on drift
    2  user_sentiment           - Detect user frustration/correction
    3  rock_bottom_realignment  - Force realignment at 0% confidence
    4  confidence_initializer   - Assess confidence, mandate research/external
    5  intake_protocol          - Show complexity-tiered checklists
    6  build_vs_buy             - Challenge custom build proposals
    7  confidence_approval_gate - Handle trust restoration requests
    8  confidence_dispute       - Handle false positive reducer disputes
   10  verified_library_unlock  - Unlock verified libraries

  EXTRACTION/CONTEXT (15-70) - _prompt_context.py:
    2  beads_periodic_sync - Periodic background beads sync (in suggestions)
   15  intention_tracker   - Extract mentioned files/searches
   30  prompt_disclaimer   - System context + task checklist
   32  tech_version_risk   - Warn about outdated AI knowledge
   35  project_context     - Git state, project structure
   40  memory_injector     - Lessons, spark, decisions, scope
   45  context_injector    - Session state, command suggestions
   50  reminder_injector   - Custom trigger-based reminders

  SUGGESTIONS (70-95) - _prompt_suggestions.py:
   70  complexity_assessment - BMAD-style task complexity detection
   71  advisor_context     - Persona-flavored advisory (security, architecture, etc.)
   72  self_heal_diagnostic - Diagnostic commands when self-heal active
   75  proactive_nudge     - Actionable suggestions from state
   80  ops_nudge           - Tool suggestions (comprehensive)
   81  agent_suggestion    - Suggest Task agents based on prompt patterns
   82  skill_suggestion    - Suggest Skills based on prompt patterns
   85  ops_awareness       - Script awareness (fallback)
   86  ops_audit_reminder  - Periodic unused tool reminder
   88  intent_classifier   - ML-based intent classification
   89  expert_probe        - Force probing questions
   89  pal_mandate         - PAL tool mandates based on state
   90  resource_pointer    - Sparse pointers to resources
   91  work_patterns       - Assumptions, rollback, confidence, integration
   93  quality_signals     - Pattern smells, context decay alerts
   95  response_format     - Structured response sections

ARCHITECTURE:
  - Hooks register via @register_hook(name, priority)
  - Lower priority = runs first
  - First DENY wins (for gating hooks)
  - Contexts are aggregated and joined
  - Single state load/save per invocation
"""

import _lib_path  # noqa: F401
import sys
import json
import time

from session_state import load_state, save_state, SessionState  # noqa: F401

# =============================================================================
# HOOK REGISTRY (shared across modules)
# =============================================================================

from _prompt_registry import HOOKS

# Import hook modules (triggers registration via decorators)
import _prompt_gating  # noqa: F401 - Gating hooks (priority 0-10)
import _prompt_context  # noqa: F401 - Context hooks (priority 15-70)
import _prompt_suggestions  # noqa: F401 - Suggestion hooks (priority 72-95)


# =============================================================================
# MAIN RUNNER
# =============================================================================


def run_hooks(data: dict, state: SessionState) -> dict:
    """Run all hooks and return aggregated result."""
    contexts = []

    for name, check_func, priority in HOOKS:
        try:
            result = check_func(data, state)

            # First deny wins
            if result.decision == "deny":
                return {
                    "hookSpecificOutput": {
                        "hookEventName": "UserPromptSubmit",
                        "permissionDecision": "deny",
                        "permissionDecisionReason": result.reason,
                    }
                }

            # Collect contexts
            if result.context:
                contexts.append(result.context)

        except Exception as e:
            print(f"[ups-runner] Hook {name} error: {e}", file=sys.stderr)

    # Build output
    output = {"hookSpecificOutput": {"hookEventName": "UserPromptSubmit"}}
    if contexts:
        # Limit to avoid context explosion
        output["hookSpecificOutput"]["additionalContext"] = "\n\n".join(contexts[:8])

    return output


# Pre-sort hooks by priority at module load (avoid re-sorting on every call)
HOOKS.sort(key=lambda x: x[2])


def main():
    """Main entry point."""
    start = time.time()

    try:
        data = json.load(sys.stdin)
    except (json.JSONDecodeError, ValueError):
        print(json.dumps({"hookSpecificOutput": {"hookEventName": "UserPromptSubmit"}}))
        sys.exit(0)

    # Normalize prompt field
    prompt = data.get("prompt", "") or data.get("user_prompt", "")
    data["prompt"] = prompt

    # Single state load
    state = load_state()

    # Increment turn count
    state.turn_count += 1

    # Run all hooks
    result = run_hooks(data, state)

    # Single state save
    save_state(state)

    # Output result
    print(json.dumps(result))

    # Debug timing
    elapsed = (time.time() - start) * 1000
    if elapsed > 100:
        print(f"[ups-runner] Slow: {elapsed:.1f}ms", file=sys.stderr)

    sys.exit(0)


if __name__ == "__main__":
    main()
</file>

</files>
